{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from random import shuffle\n",
    "import cv2\n",
    "from skimage import color\n",
    "from bilinear_sampler import bilinear_sampler\n",
    "from stn import spatial_transformer_network as transformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Image path\n",
    "#INPUT_PATH = 'flower/Flowers_8bit/*.png'\n",
    "INPUT_PATH = 'Andre/*.png'\n",
    "TEST_PATH = 'Andre_test/*.png'\n",
    "\n",
    "#LF Parameter\n",
    "ANGULAR_RES_X = 14;\n",
    "ANGULAR_RES_Y = 14;\n",
    "ANGULAR_RES_TARGET = 8*8\n",
    "IMG_WIDTH = 3584\n",
    "IMG_HEIGHT = 2688\n",
    "SPATIAL_HEIGHT = int(IMG_HEIGHT / ANGULAR_RES_Y)\n",
    "SPATIAL_WIDTH = int(IMG_WIDTH / ANGULAR_RES_X)\n",
    "CH_INPUT = 3\n",
    "CH_OUTPUT = 3\n",
    "SHIFT_VALUE = 0.8\n",
    "\n",
    "#Training parameter\n",
    "BATCH_SIZE = 1\n",
    "TRAIN_SIZE = 1.0\n",
    "LR_G =  0.001 # 0.001 0.0005 0.00146 0.0002\n",
    "EPOCH = 150000\n",
    "DECAY_STEP = 5000\n",
    "DECAY_RATE = 0.90\n",
    "LAMBDA_L1 = 10.0\n",
    "LAMBDA_MV = 10.0\n",
    "LAMBDA_TV = 1e-7\n",
    "EPS = 1e-6\n",
    "\n",
    "\n",
    "#LF INDEX\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 0 | 8  | 16 | 24 | 32 | 40 | 48 | 56 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 1 | 9  | 17 | 25 | 33 | 41 | 49 | 57 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 2 | 10 | 18 | 26 | 34 | 42 | 50 | 58 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 3 | 11 | 19 | 27 | 35 | 43 | 51 | 59 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 4 | 12 | 20 | 28 | 36 | 44 | 52 | 60 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 5 | 13 | 21 | 29 | 37 | 45 | 53 | 61 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 6 | 14 | 22 | 30 | 38 | 46 | 54 | 62 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 7 | 15 | 23 | 31 | 39 | 47 | 55 | 63 |\n",
    "# +---+----+----+----+----+----+----+----+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift pixels\n",
    "def tf_image_translate(images, tx, ty, interpolation='BILINEAR'):\n",
    "    # got these parameters from solving the equations for pixel translations\n",
    "    # on https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform\n",
    "    \n",
    "    #+tx -> shift to left +ty ->shift up\n",
    "    transforms = [1, 0, tx, 0, 1, ty, 0, 0]\n",
    "    return tf.contrib.image.transform(images, transforms, interpolation)\n",
    "    \n",
    "    #+tx -> shift to right +ty ->shift down\n",
    "    #translate = [-tx, -ty]\n",
    "    #return tf.contrib.image.translate(images, translate, interpolation)\n",
    "\n",
    "def preprocess(image):\n",
    "    with tf.name_scope(\"preprocess\"):\n",
    "        # [0, 1] => [-1, 1]\n",
    "        return image * 2 - 1\n",
    "    \n",
    "def deprocess(image):\n",
    "    with tf.name_scope(\"deprocess\"):\n",
    "        # [-1, 1] => [0, 1]\n",
    "        return (image + 1) / 2\n",
    "    \n",
    "#Input raw png LF, output center LF, 8x8 grid LF, and stacked LF in channel axis\n",
    "def process_LF(lf):    \n",
    "    full_LF_crop = np.zeros((SPATIAL_HEIGHT, SPATIAL_WIDTH, 3, ANGULAR_RES_Y, ANGULAR_RES_X))\n",
    "    for ax in range(ANGULAR_RES_X):\n",
    "        for ay in range(ANGULAR_RES_Y):\n",
    "            resized = lf[ay::ANGULAR_RES_Y, ax::ANGULAR_RES_X, :]\n",
    "            resized2 = cv2.resize(resized, dsize=(SPATIAL_WIDTH, SPATIAL_HEIGHT), interpolation=cv2.INTER_LINEAR)\n",
    "            full_LF_crop[:, :, :, ay, ax] = resized2\n",
    "            \n",
    "    #Take 8x8 LF on the middle, since the side part suffer from vignetting\n",
    "    middle_LF = full_LF_crop[:, :, :, 3:11, 3:11] # Take 8x8 LF in 5D\n",
    "    \n",
    "    #To visualize the 8x8 LF\n",
    "    for ax in range(8):\n",
    "        for ay in range(8):\n",
    "            if ay == 0:\n",
    "                y_img = middle_LF[:,:,:,ay,ax]\n",
    "            else:\n",
    "                y_img = np.concatenate((y_img, middle_LF[:,:,:,ay,ax]), 0)\n",
    "            \n",
    "            if ax == 0 and ay ==0:\n",
    "                LF_stack = middle_LF[:,:,:,0,0]\n",
    "            else:\n",
    "                LF_stack = np.concatenate((LF_stack, middle_LF[:,:,:,ay,ax]), 2)\n",
    "        if ax == 0:\n",
    "            LF_grid = y_img\n",
    "        else:\n",
    "            LF_grid = np.concatenate((LF_grid, y_img), 1)\n",
    "        y_img = middle_LF[:,:,:,ay,ax]\n",
    "    \n",
    "    center_view = middle_LF[:,:,:,3,3]\n",
    "    return center_view, LF_stack, LF_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper function\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def load_image(addr):\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.imread(addr)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    center_view, GT, grid = process_LF(img)\n",
    "    \n",
    "    center_view = np.uint8(center_view)\n",
    "    grid = np.uint8(grid)\n",
    "    GT = np.uint8(GT)\n",
    "    \n",
    "    return center_view, GT, grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataRecord(out_filename, addrs):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(out_filename)\n",
    "    for i in range(len(addrs)):\n",
    "        # print how many images are loaded every # images\n",
    "        if not i % 10:\n",
    "            print('Train data: {}/{} images'.format(i, len(addrs)))\n",
    "            sys.stdout.flush()\n",
    "        # Load the image\n",
    "        img, label, grid = load_image(addrs[i]) \n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        if label is None:\n",
    "            continue\n",
    "            \n",
    "        if grid is None:\n",
    "            continue\n",
    "\n",
    "        # Create a feature\n",
    "        feature = {\n",
    "            'image_raw': _bytes_feature(img.tostring()),\n",
    "            'label': _bytes_feature(label.tostring()),\n",
    "            'grid': _bytes_feature(grid.tostring())\n",
    "        }\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with tf.name_scope('Data_Folder_Read'):\n",
    "#     input_path = INPUT_PATH\n",
    "#     addrs = sorted(glob.glob(input_path))\n",
    "    \n",
    "# with tf.name_scope('Shuffle_Data'):\n",
    "#     # to shuffle data\n",
    "#     c = list(addrs)\n",
    "#     shuffle(c)\n",
    "#     addrs = c\n",
    "\n",
    "# with tf.name_scope('Create_Datarecord_Train'):\n",
    "#     # Divide the data into % train and % test\n",
    "#     #train_addrs = addrs[0:int(TRAIN_SIZE*len(addrs))]\n",
    "#     #createDataRecord('train.tfrecords', train_addrs)\n",
    "    \n",
    "#     train_addrs = addrs[0:int(TRAIN_SIZE*len(addrs))]\n",
    "#     createDataRecord('train_andre.tfrecords', train_addrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Input_Pipeline'):\n",
    "    #Augment input\n",
    "    \n",
    "    #TRAIN CASE\n",
    "    #gamma_val = tf.random_uniform(shape=[], minval=0.4, maxval=1.0) \n",
    "    #TEST CASE\n",
    "    gamma_val = tf.random_uniform(shape=[], minval=0.4, maxval=0.5)  \n",
    "    #gamma_val = 0.01\n",
    "    \n",
    "    #X Single RGB image\n",
    "    tf_x = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT], name='Input')\n",
    "    tf_x = tf.image.adjust_gamma(tf_x*255, gamma_val)\n",
    "    view_image = tf.summary.image('input', tf.reshape(tf_x, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT]), 1)\n",
    "    image = tf.reshape(tf_x, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT], name='img_x')# (batch, height, width, channel)\n",
    "    image_min = preprocess(image) #-1..1\n",
    "    \n",
    "    #LF GT in grid style for visualization purpose only\n",
    "    tf_grid = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT], name='Grids')\n",
    "    tf_grid = tf.image.adjust_gamma(tf_grid*255, gamma_val)\n",
    "    label_image = tf.summary.image('GT', tf.reshape(tf_grid, [-1, SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT]), 1)\n",
    "    \n",
    "    #Y LF GT stacked in channel direction for loss\n",
    "    tf_y = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_OUTPUT*64], name='Target')\n",
    "    tf_y = tf.image.adjust_gamma(tf_y*255, gamma_val)\n",
    "    color_norm = tf.reshape(tf_y, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_OUTPUT*64], name='img_y')# (batch, height, width, channel)\n",
    "    color_norm_min = preprocess(color_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK STRUCTURE [SYNTHESIS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return shifting value based on the angular coordinate\n",
    "def shift_value(i):\n",
    "    if i<=7:\n",
    "        tx = 3*SHIFT_VALUE\n",
    "    elif i>7 and i<=15:\n",
    "        tx = 2*SHIFT_VALUE\n",
    "    elif i>15 and i<=23:\n",
    "        tx = 1*SHIFT_VALUE\n",
    "    elif i>23 and i<=31:\n",
    "        tx = 0\n",
    "    elif i>31 and i<=39:\n",
    "        tx = -1*SHIFT_VALUE\n",
    "    elif i>39 and i<=47:\n",
    "        tx = -2*SHIFT_VALUE\n",
    "    elif i>47 and i<=55:\n",
    "        tx = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        tx = -4*SHIFT_VALUE\n",
    "    \n",
    "    if i==0 or (i%8==0 and i>7):\n",
    "        ty = 3*SHIFT_VALUE\n",
    "    elif i == 1 or (i-1)%8==0:\n",
    "        ty = 2*SHIFT_VALUE\n",
    "    elif i == 2 or (i-2)%8==0:\n",
    "        ty = 1*SHIFT_VALUE\n",
    "    elif i == 3 or (i-3)%8==0:\n",
    "        ty = 0\n",
    "    elif i == 4 or (i-4)%8==0:\n",
    "        ty = -1*SHIFT_VALUE\n",
    "    elif i == 5 or (i-5)%8==0:\n",
    "        ty = -2*SHIFT_VALUE\n",
    "    elif i == 6 or (i-6)%8==0:\n",
    "        ty = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        ty = -4*SHIFT_VALUE\n",
    "        \n",
    "    return tx, ty\n",
    "\n",
    "def add_layer(input_=None, rate=1):\n",
    "    c = tf.nn.relu(input_)\n",
    "    c = tf.layers.conv2d(c, 12, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal(), dilation_rate=rate)\n",
    "    return tf.concat([input_, c], -1)\n",
    "\n",
    "def transition(input_=None):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    filters = shape[-1]\n",
    "    c = tf.nn.relu(input_)\n",
    "    c = tf.layers.conv2d(c, filters, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "    #No average pooling\n",
    "    return c\n",
    "\n",
    "def flow_layer(input_=None):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    filters = shape[-1]\n",
    "    c = tf.nn.relu(input_)\n",
    "    c = tf.layers.conv2d(c, filters, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "    c = tf.layers.conv2d(c, (ANGULAR_RES_TARGET)*2, 3, padding='SAME', activation=None, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "    return c\n",
    "    \n",
    "def LF_Synthesis(input_=None):\n",
    "    with tf.name_scope('Initial_Conv'):\n",
    "        conv = tf.layers.conv2d(input_, 14, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal(), name='INITIAL_CONV_1')\n",
    "        conv_prob = conv\n",
    "        \n",
    "    with tf.name_scope('Flow_Generator'): #Dense Net\n",
    "        with tf.name_scope('Block_1'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv, 2)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Block_2'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv, 4)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Block_3'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv, 8)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Block_4'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv,16)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Flow'):\n",
    "            flow_LF = flow_layer(conv)\n",
    "        \n",
    "    ###################################################################################################\n",
    "\n",
    "    #Synthesize LF by element wise multiplication with flow\n",
    "    with tf.name_scope('Estimation_Layer'):\n",
    "        yuv = tf.image.rgb_to_yuv(image)\n",
    "        y = yuv[:,:,:,0:1]\n",
    "        y = preprocess(y)\n",
    "        for i in range(ANGULAR_RES_TARGET):\n",
    "         \n",
    "            tx, ty = shift_value(i)\n",
    "            image_shift = tf_image_translate(image_min, tx, ty)\n",
    "            y_shift = tf_image_translate(y, tx, ty)\n",
    "            \n",
    "            if i==0:\n",
    "                pred_LF = bilinear_sampler(image_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "                \n",
    "                pred_LF_loss = bilinear_sampler(y_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "            elif i==27: #Input\n",
    "                pred_LF = tf.concat((pred_LF, image_min), -1)\n",
    "                \n",
    "                pred_LF_loss = tf.concat((pred_LF_loss, y), -1)\n",
    "            else:\n",
    "                trans_image = bilinear_sampler(image_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "                pred_LF = tf.concat((pred_LF, trans_image), -1)\n",
    "                \n",
    "                trans_image = bilinear_sampler(y_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "                pred_LF_loss = tf.concat((pred_LF_loss, trans_image), -1)  \n",
    "                \n",
    "    print('pred_LF',pred_LF.shape)           \n",
    "    print('pred_LF_loss',pred_LF_loss.shape) \n",
    "    return pred_LF, pred_LF_loss, flow_LF\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_LF (?, 192, 256, 192)\n",
      "pred_LF_loss (?, 192, 256, 64)\n",
      "pred_LF_loss_H (?, 192, 256, 64)\n",
      "y_GT_H (?, 192, 256, 64)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('View_Synthesis'):\n",
    "    with tf.name_scope('Main_Network'):\n",
    "        #image_norm = tf.divide(image, 255)\n",
    "        yuv = tf.image.rgb_to_yuv(image)\n",
    "        #Y = tf.summary.image('Y', tf.reshape(yuv[:,:,:,0:1], [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, 1]), 1)\n",
    "        y = preprocess(yuv[:,:,:,0:1])\n",
    "        pred_LF, pred_LF_loss, flow_LF = LF_Synthesis(y)\n",
    "        pred_LF_norm = deprocess(pred_LF)\n",
    "    #####################################################################################\n",
    "    with tf.name_scope('EPI_Slicing'):\n",
    "        \n",
    "        #Convert GT LF into Luma GT\n",
    "        for i in range(ANGULAR_RES_TARGET):  \n",
    "            temp = tf.image.rgb_to_yuv(color_norm[:,:,:,i*3:(i*3)+3])\n",
    "            if i == 0:\n",
    "                y_GT = temp[:,:,:,0:1]\n",
    "            else:\n",
    "                y_GT = tf.concat([y_GT, temp[:,:,:,0:1]], -1)\n",
    "        y_GT = preprocess(y_GT)    \n",
    "        \n",
    "        #Cross spatial EPI slice\n",
    "        center_width = int(SPATIAL_WIDTH/2)\n",
    "        center_height = int(SPATIAL_HEIGHT/2)\n",
    "\n",
    "        slice_epi_H = pred_LF_loss[:, center_height:center_height+1, :, :]\n",
    "        slice_epi_GT_H = y_GT[:, center_height:center_height+1, :, :]\n",
    "\n",
    "        slice_epi_V = pred_LF_loss[:, :, center_width:center_width+1, :]\n",
    "        slice_epi_GT_V = y_GT[:, :, center_width:center_width+1, :]\n",
    "\n",
    "        #Because of the stack is in row order for horizontal EPI it cannot be directly reshaped\n",
    "        for j in range(8):\n",
    "            for i in range(8):\n",
    "                temp = slice_epi_H[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                temp2 = slice_epi_GT_H[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                temp3 = pred_LF_loss[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                temp4 = y_GT[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    epi_synth_H = temp\n",
    "                    epi_GT_H = temp2\n",
    "                    pred_LF_loss_H = temp3\n",
    "                    y_GT_H = temp4\n",
    "\n",
    "                else:\n",
    "                    epi_synth_H = tf.concat([epi_synth_H,temp], 1)\n",
    "                    epi_GT_H = tf.concat([epi_GT_H,temp2], 1)\n",
    "                    pred_LF_loss_H = tf.concat([pred_LF_loss_H,temp3], -1)\n",
    "                    y_GT_H = tf.concat([y_GT_H,temp4], -1)\n",
    "\n",
    "        \n",
    "        #Vertical EPI fit the image stack row order and can be directly obtained with just reshape\n",
    "        epi_synth_V = tf.reshape(slice_epi_V, [-1,SPATIAL_HEIGHT, 64, 1])\n",
    "        epi_GT_V = tf.reshape(slice_epi_GT_V, [-1,SPATIAL_HEIGHT, 64, 1])\n",
    "        \n",
    "        print('pred_LF_loss_H', pred_LF_loss_H.shape)\n",
    "        print('y_GT_H', y_GT_H.shape)\n",
    "        #####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "def total_variation_flow(images, name=None):\n",
    "    ndims = images.get_shape().ndims\n",
    "\n",
    "    if ndims == 3:    \n",
    "        pixel_dif1 = (images[1:, :, :] - images[:-1, :, :])\n",
    "        pixel_dif2 = (images[:, 1:, :] - images[:, :-1, :])\n",
    "        pixel_dif1*=pixel_dif1\n",
    "        pixel_dif2*=pixel_dif2\n",
    "        # Sum for all axis. (None is an alias for all axis.)\n",
    "        sum_axis = None\n",
    "    elif ndims == 4:\n",
    "        pixel_dif1 = (images[:, 1:, :, :] - images[:, :-1, :, :])\n",
    "        pixel_dif2 = (images[:, :, 1:, :] - images[:, :, :-1, :])\n",
    "        pixel_dif1*=pixel_dif1\n",
    "        pixel_dif2*=pixel_dif2\n",
    "        # Only sum for the last 3 axis.\n",
    "        # This results in a 1-D tensor with the total variation for each image.\n",
    "        sum_axis = [1, 2, 3]\n",
    "\n",
    "    tot_var = (\n",
    "        math_ops.reduce_mean(math_ops.abs(pixel_dif1), axis=sum_axis) +\n",
    "        math_ops.reduce_mean(math_ops.abs(pixel_dif2), axis=sum_axis))\n",
    "\n",
    "    return tot_var\n",
    "\n",
    "def total_variation_pixel(images, name=None):\n",
    "    ndims = images.get_shape().ndims\n",
    "\n",
    "    if ndims == 3:    \n",
    "        pixel_dif1 = (images[1:, :, :] - images[:-1, :, :])\n",
    "        pixel_dif2 = (images[:, 1:, :] - images[:, :-1, :])\n",
    "        pixel_dif1*=pixel_dif1\n",
    "        pixel_dif2*=pixel_dif2\n",
    "        # Sum for all axis. (None is an alias for all axis.)\n",
    "        sum_axis = None\n",
    "    elif ndims == 4:\n",
    "        pixel_dif1 = (images[:, 1:, :, :] - images[:, :-1, :, :])\n",
    "        pixel_dif2 = (images[:, :, 1:, :] - images[:, :, :-1, :])\n",
    "        # Only sum for the last 3 axis.\n",
    "        # This results in a 1-D tensor with the total variation for each image.\n",
    "        sum_axis = [1, 2, 3]\n",
    "\n",
    "    tot_var = (\n",
    "        math_ops.reduce_mean(math_ops.abs(pixel_dif1), axis=sum_axis) +\n",
    "        math_ops.reduce_mean(math_ops.abs(pixel_dif2), axis=sum_axis))\n",
    "\n",
    "    return tot_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "with tf.name_scope('Pixel_Based_Loss'):\n",
    "    #EPI based loss in horizontal and vertical direction sampled every 8 angular images\n",
    "    with tf.name_scope('L_Loss'):\n",
    "        variance_loss = mean_loss = pixel_loss_V = pixel_loss_H = 0\n",
    "\n",
    "        for i in range(8):  \n",
    "            temp1 = tf.reduce_mean(y_GT[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            temp2 = tf.reduce_mean(pred_LF_loss[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            pixel_loss_V += tf.losses.absolute_difference(temp1, temp2)\n",
    "            \n",
    "            temp3 = tf.reduce_mean(y_GT_H[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            temp4 = tf.reduce_mean(pred_LF_loss_H[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            pixel_loss_H += tf.losses.absolute_difference(temp3, temp4)\n",
    "\n",
    "        tf.summary.scalar('pixel_loss_V', pixel_loss_V)\n",
    "        tf.summary.scalar('pixel_loss_H', pixel_loss_H)        \n",
    " \n",
    "    with tf.name_scope('MV_Loss'):  \n",
    "        mean, variance = tf.nn.moments(deprocess(y_GT), -1)\n",
    "        mean2, variance2 = tf.nn.moments(deprocess(pred_LF_loss), -1)\n",
    "        \n",
    "        mean = tf.where(tf.is_nan(mean), tf.zeros_like(mean), mean)\n",
    "        mean2 = tf.where(tf.is_nan(mean2), tf.zeros_like(mean2), mean2)\n",
    "        variance = tf.where(tf.is_nan(variance), tf.zeros_like(variance), variance)\n",
    "        variance2 = tf.where(tf.is_nan(variance2), tf.zeros_like(variance2), variance2)\n",
    "        \n",
    "        variance = tf.sqrt(variance+EPS)\n",
    "        variance2 = tf.sqrt(variance2+EPS)\n",
    "        \n",
    "        mean_loss = tf.losses.absolute_difference(mean, mean2)\n",
    "        variance_loss = tf.losses.absolute_difference(variance, variance2)\n",
    "        tf.summary.scalar('mean_loss', mean_loss)\n",
    "        tf.summary.scalar('variance_loss', variance_loss)\n",
    "        \n",
    "    # Total variation loss for flow to surpress amount of artifact and smooth flow\n",
    "    with tf.name_scope('Total_Variation_Loss_Flow'): \n",
    "        tv_loss_x = (total_variation_flow(flow_LF[:,:,:,0::2]))\n",
    "        tv_loss_y = (total_variation_flow(flow_LF[:,:,:,1::2]))\n",
    "        tv_loss = tf.reduce_mean(tv_loss_x) + tf.reduce_mean(tv_loss_y)\n",
    "        tf.summary.scalar('TV_loss', tv_loss)\n",
    "        \n",
    "    with tf.name_scope('Total_Variation_Loss_Pixel'): \n",
    "        tv_pixel_accum = 0\n",
    "        for i in range(ANGULAR_RES_TARGET):\n",
    "            tv_pixel_accum += total_variation_pixel(pred_LF_loss[:,:,:,i:i+1])\n",
    "        tv_pixel = tf.reduce_mean(tv_pixel_accum)\n",
    "        tf.summary.scalar('TV_loss_pixels', tv_pixel)\n",
    "    \n",
    "with tf.name_scope('Total_Loss'):\n",
    "    Total_Loss = (LAMBDA_L1 * pixel_loss_V) + (LAMBDA_L1 * pixel_loss_H) \\\n",
    "                + (LAMBDA_TV * tv_loss) + (LAMBDA_MV*mean_loss) + (LAMBDA_MV*variance_loss) \\\n",
    "                + (0.1 * tv_pixel)\n",
    "  \n",
    "    tf.summary.scalar('Total_Loss', Total_Loss)\n",
    "    y_img = pred_LF[:,:,:,0:3]\n",
    "    \n",
    "    \n",
    "    #Reshape the output into a grid LF\n",
    "    for i in range(1,ANGULAR_RES_TARGET):\n",
    "        if i==8:\n",
    "            grid_LF = y_img\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "                \n",
    "        elif i%8==0 and i>8:\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "\n",
    "        elif i == 63:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "\n",
    "        else:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "\n",
    "###################################################################################### \n",
    "\n",
    "with tf.name_scope('Evaluation'):\n",
    "    psnr = tf.image.psnr(color_norm, pred_LF_norm, max_val=1.0)\n",
    "    tf.summary.scalar('PSNR', psnr[0])\n",
    "    \n",
    "    ssim = tf.image.ssim(color_norm, pred_LF_norm, max_val=1.0)\n",
    "    tf.summary.scalar('SSIM', ssim[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Train'):\n",
    "    global_step_G = tf.Variable(0, dtype=tf.float32)\n",
    "    learning_rate_G = tf.train.exponential_decay(\n",
    "                      LR_G,                  # Base learning rate.\n",
    "                      global_step_G,         # Current index into the dataset.\n",
    "                      DECAY_STEP,            # Decay step.\n",
    "                      DECAY_RATE,            # Decay rate.\n",
    "                      staircase=True)\n",
    "    tf.summary.scalar('LR_G', learning_rate_G)\n",
    "    train_G = tf.train.AdamOptimizer(learning_rate=learning_rate_G, name='optimizer_G').minimize(Total_Loss, global_step=global_step_G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Visualization'):     \n",
    "    #Open the predicted LF into grid for EPI visualization\n",
    "    grid_LF = tf.zeros_like(image)\n",
    "    y_img = pred_LF[:,:,:,0:3]\n",
    "    \n",
    "    for i in range(1,ANGULAR_RES_TARGET):\n",
    "        if i==8:\n",
    "            grid_LF = y_img\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "\n",
    "                  \n",
    "        elif i%8==0 and i>8:\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "            \n",
    "        elif i == 63:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "        \n",
    "        else:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "            \n",
    "    ######################################################################################\n",
    "    \n",
    "    #TF Summary image\n",
    "    grid_LF_show = deprocess(grid_LF)\n",
    "    output_image = tf.summary.image('Synthesized_LF', tf.cast(tf.reshape(grid_LF_show*255, \n",
    "                            [-1, SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT]), tf.uint8) , 1)\n",
    "    \n",
    "    #EPI VISUALIZATION\n",
    "    with tf.name_scope('EPI'): \n",
    "        epi_synth_H = deprocess(epi_synth_H)\n",
    "        epi_GT_H = deprocess(epi_GT_H)\n",
    "        epi_synth_V = deprocess(epi_synth_V)\n",
    "        epi_GT_V = deprocess(epi_GT_V)\n",
    "        epi_horizontal = tf.summary.image('epi_horizontal', tf.cast(tf.reshape(epi_synth_H*255, \n",
    "                                [-1, 64, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        epi_horizontal_GT = tf.summary.image('epi_horizontal_GT', tf.cast(tf.reshape(epi_GT_H*255, \n",
    "                                [-1, 64, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        epi_vertical = tf.summary.image('epi_vertical', tf.cast(tf.reshape(epi_synth_V*255, \n",
    "                                [-1, SPATIAL_HEIGHT, 64, 1]), tf.uint8) , 1)\n",
    "        epi_vertical_GT = tf.summary.image('epi_vertical_GT', tf.cast(tf.reshape(epi_GT_V*255, \n",
    "                                [-1, SPATIAL_HEIGHT, 64, 1]), tf.uint8) , 1)  \n",
    "        \n",
    "with tf.name_scope('Mean_Variance'):         \n",
    "        mean_img = tf.summary.image('mean_GT', tf.cast(tf.reshape(mean*255, \n",
    "                            [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        var_img = tf.summary.image('var_GT', tf.cast(tf.reshape(variance*1000, \n",
    "                            [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        \n",
    "        mean_img2 = tf.summary.image('mean_output', tf.cast(tf.reshape(mean2*255, \n",
    "                            [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        var_img2 = tf.summary.image('var_output', tf.cast(tf.reshape(variance2*1000, \n",
    "                            [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, 1]), tf.uint8) , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLICE another EPI in the LF to make sure not only cross EPI is correct but all EPI is correct\n",
    "with tf.name_scope('VALIDATION'): \n",
    "    center_width = tf.random_uniform(shape=[], minval=10, maxval=SPATIAL_WIDTH-10, dtype=tf.int32)\n",
    "    center_height = tf.random_uniform(shape=[], minval=10, maxval=SPATIAL_HEIGHT-10, dtype=tf.int32)\n",
    "\n",
    "    slice_epi_H2 = pred_LF_norm[:, center_height:center_height+1, :, :]\n",
    "    slice_epi_V2 = pred_LF_norm[:, :, center_width:center_width+1, :]\n",
    "    \n",
    "    slice_epi_GT_H2 = color_norm[:, center_height:center_height+1, :, :]\n",
    "    slice_epi_GT_V2 = color_norm[:, :, center_width:center_width+1, :]\n",
    "        \n",
    "\n",
    "    #Because of the stack is in row order for horizontal EPI it cannot be directly reshaped\n",
    "    for j in range(8):\n",
    "        for i in range(8):\n",
    "            temp = slice_epi_H2[:, :, :, (i*8*3)+(j*3):(i*8*3)+(j*3)+3]\n",
    "            temp2 = slice_epi_GT_H2[:, :, :, (i*8*3)+(j*3):(i*8*3)+(j*3)+3]\n",
    "            if i==0 and j==0:\n",
    "                epi_synth_H2 = temp\n",
    "                epi_GT_H2 = temp2\n",
    "            else:\n",
    "                epi_synth_H2 = tf.concat([epi_synth_H2,temp], 1)\n",
    "                epi_GT_H2 = tf.concat([epi_GT_H2,temp2], 1)\n",
    "\n",
    "    epi_synth_V2 = tf.reshape(slice_epi_V2, [-1,SPATIAL_HEIGHT, 64, 3])\n",
    "    epi_GT_V2 = tf.reshape(slice_epi_GT_V2, [-1,SPATIAL_HEIGHT, 64, 3])\n",
    "\n",
    "    EPI_H2 = tf.summary.image('epi_horizontal2', tf.cast(tf.reshape(epi_synth_H2*255, \n",
    "                            [-1, 64, SPATIAL_WIDTH, 3]), tf.uint8) , 1)\n",
    "    epi_horizontal_GT2 = tf.summary.image('epi_horizontal_GT2', tf.cast(tf.reshape(epi_GT_H2*255, \n",
    "                                [-1, 64, SPATIAL_WIDTH, 3]), tf.uint8) , 1)\n",
    "    EPI_V2 = tf.summary.image('epi_vertical2', tf.cast(tf.reshape(epi_synth_V2*255, \n",
    "                            [-1, SPATIAL_HEIGHT, 64, 3]), tf.uint8) , 1)\n",
    "    epi_vertical_GT2 = tf.summary.image('epi_vertical_GT2', tf.cast(tf.reshape(epi_GT_V2*255, \n",
    "                                [-1, SPATIAL_HEIGHT, 64, 3]), tf.uint8) , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get one record and parse it to get the label and image out\n",
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\":     tf.FixedLenFeature([], tf.string),\n",
    "        \"grid\":     tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    #Read one record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    #Take the image and bytes\n",
    "    image = tf.decode_raw(parsed[\"image_raw\"], tf.uint8)\n",
    "    label = tf.decode_raw(parsed[\"label\"], tf.uint8)\n",
    "    grid = tf.decode_raw(parsed[\"grid\"], tf.uint8)\n",
    "    #Cast to float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    grid = tf.cast(grid, tf.float32)\n",
    "    \n",
    "    image = tf.reshape(image, shape=[SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT])\n",
    "    label = tf.reshape(label, shape=[SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_OUTPUT*64])\n",
    "    grid = tf.reshape(grid, shape=[SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT])\n",
    "    #Normalize the input and label into [0...1]\n",
    "    image = tf.divide(image, 255)\n",
    "    label = tf.divide(label, 255)\n",
    "\n",
    "    return {'image': image}, {'label': label}, {'grid': grid}\n",
    "\n",
    "def input_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=1)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=1)\n",
    "    dataset = dataset.shuffle(40).repeat().batch(BATCH_SIZE)\n",
    "    #dataset = dataset.prefetch(buffer_size=2)\n",
    "    return dataset\n",
    "\n",
    "def test_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=1)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=1)\n",
    "    dataset = dataset.batch(10)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(filenames=[\"train.tfrecords\"])\n",
    "\n",
    "def test_input_fn():\n",
    "    return test_fn(filenames=[\"test_k.tfrecords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Create_Training_Set'):\n",
    "    train_dataset = train_input_fn()\n",
    "    iterator = train_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(tf.group(tf.global_variables_initializer(), iterator.initializer))\n",
    "writer = tf.summary.FileWriter('log/Synthesis/LF',sess.graph)\n",
    "\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True, trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "for step in range(EPOCH+1):\n",
    "    train_x, train_y, train_grid = sess.run(next_batch)                       \n",
    "    \n",
    "    _, G_loss_, psnr_, ssim_ = sess.run([train_G, Total_Loss, psnr, ssim], \n",
    "    {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']})\n",
    "   \n",
    "    if step%300 == 0:\n",
    "        #writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "        summary_ = sess.run(merged, {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']}\n",
    "                           , options=run_options, run_metadata=run_metadata)\n",
    "        writer.add_summary(summary_, step)     \n",
    "        print('Step:', step, '| loss:%.5f' %G_loss_, '| PSNR:%.3f' %psnr_[0], '| SSIM:%.3f' %ssim_[0])\n",
    "        \n",
    "    if step%30000==0:\n",
    "        save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "        print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN RESTORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = tf.summary.merge_all()\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "# sess=tf.Session(config=config)\n",
    "# sess.run(tf.group(tf.global_variables_initializer(), iterator.initializer))\n",
    "# writer = tf.summary.FileWriter('log/Synthesis/Restore',sess.graph)\n",
    "\n",
    "# run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True, trace_level=tf.RunOptions.FULL_TRACE)\n",
    "# run_metadata = tf.RunMetadata()\n",
    "# saver.restore(sess, \"saver/Synthesis/model60000.ckpt\")\n",
    "\n",
    "# for step in range(60001,EPOCH+1):\n",
    "#     train_x, train_y, train_grid = sess.run(next_batch)                       \n",
    "    \n",
    "#     _, G_loss_, psnr_, ssim_ = sess.run([train_G, Total_Loss, psnr, ssim], \n",
    "#     {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']})\n",
    "   \n",
    "#     if step%500 == 0:\n",
    "#         #writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "#         summary_ = sess.run(merged, {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']}\n",
    "#                            , options=run_options, run_metadata=run_metadata)\n",
    "#         writer.add_summary(summary_, step)     \n",
    "#         print('Step:', step, '| loss:%.5f' %G_loss_, '| PSNR:%.3f' %psnr_[0], '| SSIM:%.3f' %ssim_[0])\n",
    "        \n",
    "#     if step%30000==0:\n",
    "#         save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "#         print(\"Model saved in path: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('Test_Folder_Read'):\n",
    "#     label_path = TEST_PATH\n",
    "#     addrs = sorted(glob.glob(label_path))\n",
    "    \n",
    "# with tf.name_scope('Create_Datarecord_Test'):\n",
    "#     test_addrs = addrs[:]\n",
    "#     createDataRecord('test_andre.tfrecords', test_addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "with tf.name_scope('Create_Test_Set'):\n",
    "    test_dataset = test_input_fn()\n",
    "    iterator = test_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saver/Synthesis/model90000.ckpt\n",
      "CPU times: user 839 ms, sys: 267 ms, total: 1.11 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess=tf.Session()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "sess.run(iterator.initializer)\n",
    "#writer = tf.summary.FileWriter('log/Synthesis/Test',sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "saver.restore(sess, \"saver/Synthesis/model90000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_x, test_y, test_grid = sess.run(next_batch)\n",
    "output_, grid_, epi_H_, epi_V_, epi_GT_H_, epi_GT_V_, summary_ = sess.run(\n",
    "    [pred_LF_norm, grid_LF_show, epi_synth_H2, epi_synth_V2, epi_GT_H2, epi_GT_V2, merged], \n",
    "      {tf_x:test_x['image'], tf_y:test_y['label'], tf_grid:test_grid['grid']}, options=run_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": false
   },
   "source": [
    "# FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.43 s, sys: 1.56 s, total: 6.99 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_x, test_y, test_grid = sess.run(next_batch)\n",
    "output_, flow_ = sess.run(\n",
    "    [pred_LF_norm, flow_LF], \n",
    "      {tf_x:test_x['image'], tf_y:test_y['label'], tf_grid:test_grid['grid']}, options=run_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=4\n",
    "flow_input = flow_[index,:]\n",
    "input_img = test_x['image'][index]\n",
    "\n",
    "#Bilater filter the flow\n",
    "flow_filtered =np.zeros_like(flow_input)\n",
    "for i in range(64*2):\n",
    "    #flow_filtered[:,:,i] = cv2.bilateralFilter(flow_input[:,:,i],5,75,20)\n",
    "    flow_filtered[:,:,i] = cv2.ximgproc.guidedFilter(input_img*255, flow_input[:,:,i], 7, 1.0)\n",
    "\n",
    "    \n",
    "flow_input = np.expand_dims(flow_input, axis=0)\n",
    "flow_filtered = np.expand_dims(flow_filtered, axis=0)\n",
    "input_img = np.expand_dims(input_img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_input = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT], name='a')\n",
    "image = tf.reshape(tf_input, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT], name='b')# (batch, height, width, channel)\n",
    "image_min = preprocess(image) #-1..1\n",
    "flow_LF = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT, SPATIAL_WIDTH, 128], name='c')\n",
    "\n",
    "for i in range(ANGULAR_RES_TARGET):\n",
    "    tx, ty = shift_value(i)\n",
    "    image_shift = tf_image_translate(image_min, tx, ty)\n",
    "\n",
    "    if i==0:\n",
    "        pred_LF_filtered = bilinear_sampler(image_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "\n",
    "    elif i==27: #Input\n",
    "        pred_LF_filtered = tf.concat((pred_LF_filtered, image_min), -1)\n",
    "\n",
    "    else:\n",
    "        trans_image = bilinear_sampler(image_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "        pred_LF_filtered = tf.concat((pred_LF_filtered, trans_image), -1)\n",
    "pred_LF_filtered = deprocess(pred_LF_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "output_= sess.run(\n",
    "    [pred_LF_filtered], \n",
    "      {tf_input:input_img, flow_LF:flow_filtered})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = output_[0]\n",
    "temp2 = temp2[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "gamma = 0.8\n",
    "Output=[]\n",
    "Error=[]\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    temp = temp2[:,:,(n*3):(n*3)+3]*255\n",
    "    temp = cv2.resize(temp, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "    temp = np.uint8(temp)\n",
    "    temp = exposure.adjust_gamma(temp, gamma)\n",
    "    Output.append(temp)\n",
    "    save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"LF_Synthesized/Filtered/output%i.png\" %(n), save)\n",
    "    \n",
    "c=0\n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        temp = temp2[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]*255\n",
    "        temp = cv2.resize(temp, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "        temp = np.uint8(temp)\n",
    "        temp = exposure.adjust_gamma(temp, gamma)\n",
    "        Output.append(temp)\n",
    "        c+=1\n",
    "        \n",
    "temp1 = test_y['label'][index]*255\n",
    "temp2 = temp2*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    save1 = cv2.cvtColor(temp1[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    save2 = cv2.cvtColor(temp2[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    save = np.absolute(save1-save2)*1.2\n",
    "    save = np.uint8(save)\n",
    "    save = cv2.applyColorMap(save, cv2.COLORMAP_JET)\n",
    "    save = cv2.resize(save, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(\"LF_Synthesized/Error/output%i.png\" %(n), save)\n",
    "    save = cv2.cvtColor(save, cv2.COLOR_RGB2BGR)\n",
    "    Error.append(save)\n",
    "    \n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        save1 = temp1[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save2 = temp2[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save = np.absolute(save1-save2)*1.2\n",
    "        save = np.uint8(save)\n",
    "        save = cv2.applyColorMap(save, cv2.COLORMAP_JET)\n",
    "        save = cv2.cvtColor(save, cv2.COLOR_RGB2BGR)\n",
    "        save = cv2.resize(save, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "        Error.append(save)\n",
    "        \n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "fps = 0.05\n",
    "imageio.mimsave('Output_Filtered.gif', Output, duration=fps)\n",
    "imageio.mimsave('Error_Filtered.gif', Error, duration=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/DeepLearning/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========0\n",
      "PSNR 28.652382904635516\n",
      "SSIM 0.9200544374248021\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "for i in range(1):\n",
    "    temp1 = test_y['label'][index]*255\n",
    "    temp2 = output_[0]\n",
    "    temp2 = temp2[0,:]*255\n",
    "    PSNR=0\n",
    "    SSIM=0\n",
    "    \n",
    "    for n in range(ANGULAR_RES_TARGET):\n",
    "        if n == 27:\n",
    "            continue;\n",
    "        else:\n",
    "            original = temp1[:,:,(n*3):(n*3)+3]\n",
    "            contrast = temp2[:,:,(n*3):(n*3)+3]\n",
    "            contrast = cv2.resize(contrast, dsize=(540, 372), interpolation=cv2.INTER_CUBIC)\n",
    "            original = cv2.resize(original, dsize=(540, 372), interpolation=cv2.INTER_CUBIC)\n",
    "            PSNR+=psnr(original,contrast)\n",
    "\n",
    "            SSIM+= ssim(original, contrast, multichannel=True,\n",
    "                      data_range=contrast.max() - contrast.min())\n",
    "            \n",
    "    print(\"===========%i\" %i)\n",
    "    f= open(\"PSNR.txt\",\"a\")\n",
    "    f.write(\"%f\\n\" % (PSNR/63))\n",
    "    f.close() \n",
    "    print(\"PSNR\", PSNR/63)\n",
    "    f= open(\"SSIM.txt\",\"a\")\n",
    "    f.write(\"%f\\n\" % (SSIM/63))\n",
    "    f.close() \n",
    "    print(\"SSIM\", SSIM/63)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_x, test_y, test_grid = sess.run(next_batch)\n",
    "# output_,= sess.run(\n",
    "#     [pred_LF_norm], \n",
    "#       {tf_x:test_x['image'], tf_y:test_y['label'], tf_grid:test_grid['grid']}, options=run_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def increase_brightness(img, value=20):\n",
    "#     hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#     h, s, v = cv2.split(hsv)\n",
    "\n",
    "#     lim = 255 - value\n",
    "#     v[v > lim] = 255\n",
    "#     v[v <= lim] += value\n",
    "\n",
    "#     final_hsv = cv2.merge((h, s, v))\n",
    "#     img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2RGB)\n",
    "#     return img\n",
    "\n",
    "from skimage import exposure\n",
    "gamma = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "temp = grid_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('Output.png', temp)\n",
    "\n",
    "save = cv2.cvtColor(test_grid['grid'][i], cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('GT.png', save)\n",
    "\n",
    "temp = epi_H_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_H.png', temp)\n",
    "temp = epi_V_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_V.png', temp)\n",
    "\n",
    "temp = epi_GT_H_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_GT_H.png', temp)\n",
    "temp = epi_GT_V_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_GT_V.png', temp)\n",
    "\n",
    "GT= []\n",
    "Output = []\n",
    "Error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test_y['label'][i]*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    temp = temp1[:,:,(n*3):(n*3)+3]\n",
    "    temp = cv2.resize(temp, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "    temp = np.uint8(temp)\n",
    "    temp = exposure.adjust_gamma(temp, gamma)\n",
    "    GT.append(temp)\n",
    "    save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"LF_Synthesized/GT/output%i.png\" %(n), save)\n",
    "\n",
    "temp2 = output_[i,:]*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    temp = temp2[:,:,(n*3):(n*3)+3]\n",
    "    temp = cv2.resize(temp, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "    temp = np.uint8(temp)\n",
    "    temp = exposure.adjust_gamma(temp, gamma)\n",
    "    Output.append(temp)\n",
    "    save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"LF_Synthesized/Output/output%i.png\" %(n), save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test_y['label'][i]*255\n",
    "temp2 = output_[i,:]*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    save1 = cv2.cvtColor(temp1[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    save2 = cv2.cvtColor(temp2[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    save = np.absolute(save1-save2)*1.2\n",
    "    save = np.uint8(save)\n",
    "    save = cv2.applyColorMap(save, cv2.COLORMAP_JET)\n",
    "    save = cv2.resize(save, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(\"LF_Synthesized/Error/output%i.png\" %(n), save)\n",
    "    save = cv2.cvtColor(save, cv2.COLOR_RGB2BGR)\n",
    "    Error.append(save)\n",
    "    \n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        save1 = temp1[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save2 = temp2[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save = np.absolute(save1-save2)*1.2\n",
    "        save = np.uint8(save)\n",
    "        save = cv2.applyColorMap(save, cv2.COLORMAP_JET)\n",
    "        save = cv2.cvtColor(save, cv2.COLOR_RGB2BGR)\n",
    "        save = cv2.resize(save, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "        Error.append(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        temp = temp1[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        temp = cv2.resize(temp, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "        temp = np.uint8(temp)\n",
    "        temp = exposure.adjust_gamma(temp, gamma)\n",
    "        GT.append(temp)\n",
    "        save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(\"LF_Synthesized/Horizontal_GT/output%i.png\" %(c), save)\n",
    "        \n",
    "        temp = temp2[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        temp = cv2.resize(temp, dsize=(540, 372), interpolation=cv2.INTER_LINEAR)\n",
    "        temp = np.uint8(temp)\n",
    "        temp = exposure.adjust_gamma(temp, gamma)\n",
    "        Output.append(temp)\n",
    "        save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(\"LF_Synthesized/Horizontal_Output/output%i.png\" %(c), save)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "fps = 0.05\n",
    "imageio.mimsave('GT.gif', GT, duration=fps)\n",
    "imageio.mimsave('Output.gif', Output, duration=fps)\n",
    "imageio.mimsave('Error.gif', Error, duration=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "# def psnr(img1, img2):\n",
    "#     mse = np.mean( (img1 - img2) ** 2 )\n",
    "#     if mse == 0:\n",
    "#         return 100\n",
    "#     PIXEL_MAX = 255.0\n",
    "#     return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "# original = cv2.imread(\"GT.png\")\n",
    "# contrast = cv2.imread(\"Output.png\")\n",
    "# PSNR=psnr(original,contrast)\n",
    "# print(PSNR)\n",
    "# print(\"#########################################\")\n",
    "\n",
    "# SSIM = ssim(original, contrast, multichannel=True,\n",
    "#               data_range=contrast.max() - contrast.min())\n",
    "# print(SSIM)\n",
    "# print(\"#########################################\")\n",
    "\n",
    "# f= open(\"eval.txt\",\"w+\")\n",
    " \n",
    "# f.write(\"PSNR: %f\\r\" % PSNR)\n",
    "# f.write(\"SSIM: %f\\r\\n\" % SSIM)\n",
    " \n",
    "# f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    temp1 = test_y['label'][i]*255\n",
    "    temp2 = output_[i,:]*255\n",
    "    PSNR=0\n",
    "    SSIM=0\n",
    "    \n",
    "    for n in range(ANGULAR_RES_TARGET):\n",
    "        if n == 27:\n",
    "            continue;\n",
    "        else:\n",
    "            original = temp1[:,:,(n*3):(n*3)+3]\n",
    "            contrast = temp2[:,:,(n*3):(n*3)+3]\n",
    "            contrast = cv2.resize(contrast, dsize=(540, 372), interpolation=cv2.INTER_CUBIC)\n",
    "            original = cv2.resize(original, dsize=(540, 372), interpolation=cv2.INTER_CUBIC)\n",
    "            PSNR+=psnr(original,contrast)\n",
    "\n",
    "            SSIM+= ssim(original, contrast, multichannel=True,\n",
    "                      data_range=contrast.max() - contrast.min())\n",
    "            \n",
    "    print(\"===========%i\" %i)\n",
    "    f= open(\"PSNR.txt\",\"a\")\n",
    "    f.write(\"%f\\n\" % (PSNR/63))\n",
    "    f.close() \n",
    "    print(\"PSNR\", PSNR/63)\n",
    "    f= open(\"SSIM.txt\",\"a\")\n",
    "    f.write(\"%f\\n\" % (SSIM/63))\n",
    "    f.close() \n",
    "    print(\"SSIM\", SSIM/63)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = cv2.imread(\"test.png\")\n",
    "temp = lf[:, :, :]\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "imgplots = plt.imshow((temp).astype('uint8'))\n",
    "plt.show()\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numImgsX = 14;\n",
    "numImgsY = 14;\n",
    "\n",
    "h,w,c = temp.shape\n",
    "h_angular = h / numImgsY; \n",
    "w_angular = w / numImgsX;\n",
    "fullLF = np.zeros((int(h_angular), int(w_angular), 3, numImgsY, numImgsX));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in range(numImgsX):\n",
    "    for ay in range(numImgsY):\n",
    "        fullLF[:, :, :, ay, ax] = temp[ay::numImgsY, ax::numImgsX, :]\n",
    "        \n",
    "padded_LF = np.pad(fullLF, ((1,0),(0,0),(0,0),(0,0),(0,0)), 'constant', constant_values=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middleLF = fullLF[:, :, :, 3:11, 3:11]\n",
    "middleLF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_img = []\n",
    "i = 1\n",
    "for ax in range(8):\n",
    "    for ay in range(8):\n",
    "        if ay == 0:\n",
    "            y_img = middleLF[:,:,:,ay,ax]\n",
    "        else:\n",
    "            y_img = np.concatenate((y_img, middleLF[:,:,:,ay,ax]), 0)\n",
    "        list_img.append(middleLF[:,:,:,ay,ax])     \n",
    "    if ax == 0:\n",
    "        full_img = y_img\n",
    "    else:\n",
    "        full_img = np.concatenate((full_img, y_img), 1)\n",
    "    y_img = fullLF[:,:,:,ay,ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fullLF[:,:,:,7,7]\n",
    "imgplots = plt.imshow((temp).astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplots = plt.imshow((full_img).astype('uint8'))\n",
    "plt.show()\n",
    "cv2.imwrite(\"Grid.png\", full_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(100):\n",
    "    plt.figure(d)\n",
    "    temp = list_img[d]\n",
    "    imgplot = plt.imshow((temp).astype('uint8'))\n",
    "    #plt.savefig(\"Stack%i.png\" %d, dpi=100, bbox_inches='tight', frameon=False)\n",
    "    plt.show()\n",
    "    temp = np.uint8(temp)\n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"Stack%i.png\" %d, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list_img[0]\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "original = cv2.imread(\"GT.png\")\n",
    "contrast = cv2.imread(\"Output.png\")\n",
    "d=psnr(original,contrast)\n",
    "print(d)\n",
    "print(\"#########################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "\n",
    "original = cv2.imread(\"GT.png\")\n",
    "contrast = cv2.imread(\"Output.png\")\n",
    "ssim_noise = ssim(original, contrast, multichannel=True,\n",
    "              data_range=contrast.max() - contrast.min())\n",
    "print(ssim_noise)\n",
    "print(\"#########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_3d = np.ones((5,5,5))\n",
    "weight_3d = np.ones((3,3,3))\n",
    "strides_3d = [1, 1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_3d = tf.constant(weight_3d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "in_depth = int(in_3d.shape[2])\n",
    "\n",
    "filter_width = int(filter_3d.shape[0])\n",
    "filter_height = int(filter_3d.shape[1])\n",
    "filter_depth = int(filter_3d.shape[2])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_depth, in_height, in_depth, 1])\n",
    "kernel_3d = tf.reshape(filter_3d, [filter_depth, filter_height, filter_width, 1, 1])\n",
    "\n",
    "temp = tf.nn.conv3d(input_3d, kernel_3d, strides=strides_3d, padding='SAME')\n",
    "output_3d = tf.squeeze(temp)\n",
    "sess=tf.Session()\n",
    "sess.run(output_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LF INDEX\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 0 | 8  | 16 | 24 | 32 | 40 | 48 | 56 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 1 | 9  | 17 | 25 | 33 | 41 | 49 | 57 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 2 | 10 | 18 | 26 | 34 | 42 | 50 | 58 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 3 | 11 | 19 | 27 | 35 | 43 | 51 | 59 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 4 | 12 | 20 | 28 | 36 | 44 | 52 | 60 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 5 | 13 | 21 | 29 | 37 | 45 | 53 | 61 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 6 | 14 | 22 | 30 | 38 | 46 | 54 | 62 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 7 | 15 | 23 | 31 | 39 | 47 | 55 | 63 |\n",
    "# +---+----+----+----+----+----+----+----+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_VALUE = 1\n",
    "for i in range(64):\n",
    "    if i==0 or (i%8==0 and i>7):\n",
    "        ty = 3*SHIFT_VALUE\n",
    "    elif i == 1 or (i-1)%8==0:\n",
    "        ty = 2*SHIFT_VALUE\n",
    "    elif i == 2 or (i-2)%8==0:\n",
    "        ty = 1*SHIFT_VALUE\n",
    "    elif i == 3 or (i-3)%8==0:\n",
    "        ty = 0\n",
    "    elif i == 4 or (i-4)%8==0:\n",
    "        ty = -1*SHIFT_VALUE\n",
    "    elif i == 5 or (i-5)%8==0:\n",
    "        ty = -2*SHIFT_VALUE\n",
    "    elif i == 6 or (i-6)%8==0:\n",
    "        ty = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        ty = -4*SHIFT_VALUE\n",
    "    print('i: ',i, 'ty: ',ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_VALUE = 1\n",
    "for i in range(64):\n",
    "    if i<=7:\n",
    "        tx = 3*SHIFT_VALUE\n",
    "    elif i>7 and i<=15:\n",
    "        tx = 2*SHIFT_VALUE\n",
    "    elif i>15 and i<=23:\n",
    "        tx = 1*SHIFT_VALUE\n",
    "    elif i>23 and i<=31:\n",
    "        tx = 0\n",
    "    elif i>31 and i<=39:\n",
    "        tx = -1*SHIFT_VALUE\n",
    "    elif i>39 and i<=47:\n",
    "        tx = -2*SHIFT_VALUE\n",
    "    elif i>47 and i<=55:\n",
    "        tx = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        tx = -4*SHIFT_VALUE\n",
    "    print('i: ',i, 'tx: ',tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "image_shift = tf_image_translate(c, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "result = sess.run(image_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(['test.png']) #  list of files to read\n",
    "\n",
    "reader = tf.WholeFileReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "my_img = tf.image.decode_png(value) # use png or jpg decoder based on your files.\n",
    "my_img = tf.to_float(my_img)\n",
    "my_img2 = tf.expand_dims(my_img, 0)\n",
    "print(my_img2.shape)\n",
    "sobel = tf.image.sobel_edges(my_img2)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Start populating the filename queue.\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(1): #length of your filename list\n",
    "        image = sobel.eval() #here is your image Tensor :) \n",
    "\n",
    "    print(image.shape)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = temp[:,:,:,0]\n",
    "temp2 = temp[:,:,:,1]\n",
    "edge = np.sqrt(temp1**2 + temp2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow((temp1).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow((temp2).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow((edge).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

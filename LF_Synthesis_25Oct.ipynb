{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from random import shuffle\n",
    "import cv2\n",
    "from skimage import color\n",
    "from bilinear_sampler import bilinear_sampler\n",
    "from stn import spatial_transformer_network as transformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Image path\n",
    "INPUT_PATH = 'flower/Flowers_8bit/*.png'\n",
    "TEST_PATH = 'flower_test/*.png'\n",
    "\n",
    "#LF Parameter\n",
    "ANGULAR_RES_X = 14;\n",
    "ANGULAR_RES_Y = 14;\n",
    "ANGULAR_RES_TARGET = 8*8\n",
    "IMG_WIDTH = 3584\n",
    "IMG_HEIGHT = 2688\n",
    "SPATIAL_HEIGHT = int(IMG_HEIGHT / ANGULAR_RES_Y)\n",
    "SPATIAL_WIDTH = int(IMG_WIDTH / ANGULAR_RES_X)\n",
    "CH_INPUT = 3\n",
    "CH_OUTPUT = 3\n",
    "SHIFT_VALUE = 1.0\n",
    "\n",
    "#Training parameter\n",
    "BATCH_SIZE = 1\n",
    "TRAIN_SIZE = 1.0\n",
    "LR_G =  0.001 # 0.001 0.0005 0.00146 0.0002\n",
    "EPOCH = 180000\n",
    "DECAY_STEP = 5000\n",
    "LAMBDA_L1 = 100.0\n",
    "LAMBDA_PIXEL = 50.0\n",
    "LAMBDA_TV = 1e-7\n",
    "\n",
    "\n",
    "#LF INDEX\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 0 | 8  | 16 | 24 | 32 | 40 | 48 | 56 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 1 | 9  | 17 | 25 | 33 | 41 | 49 | 57 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 2 | 10 | 18 | 26 | 34 | 42 | 50 | 58 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 3 | 11 | 19 | 27 | 35 | 43 | 51 | 59 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 4 | 12 | 20 | 28 | 36 | 44 | 52 | 60 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 5 | 13 | 21 | 29 | 37 | 45 | 53 | 61 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 6 | 14 | 22 | 30 | 38 | 46 | 54 | 62 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 7 | 15 | 23 | 31 | 39 | 47 | 55 | 63 |\n",
    "# +---+----+----+----+----+----+----+----+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift pixels\n",
    "def tf_image_translate(images, tx, ty, interpolation='BILINEAR'):\n",
    "    # got these parameters from solving the equations for pixel translations\n",
    "    # on https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform\n",
    "    \n",
    "    #+tx -> shift to left +ty ->shift up\n",
    "    transforms = [1, 0, tx, 0, 1, ty, 0, 0]\n",
    "    return tf.contrib.image.transform(images, transforms, interpolation)\n",
    "    \n",
    "    #+tx -> shift to right +ty ->shift down\n",
    "    #translate = [-tx, -ty]\n",
    "    #return tf.contrib.image.translate(images, translate, interpolation)\n",
    "\n",
    "def preprocess(image):\n",
    "    with tf.name_scope(\"preprocess\"):\n",
    "        # [0, 1] => [-1, 1]\n",
    "        return image * 2 - 1\n",
    "    \n",
    "def deprocess(image):\n",
    "    with tf.name_scope(\"deprocess\"):\n",
    "        # [-1, 1] => [0, 1]\n",
    "        return (image + 1) / 2\n",
    "    \n",
    "#Input raw png LF, output center LF, 8x8 grid LF, and stacked LF in channel axis\n",
    "def process_LF(lf):    \n",
    "    full_LF_crop = np.zeros((SPATIAL_HEIGHT, SPATIAL_WIDTH, 3, ANGULAR_RES_Y, ANGULAR_RES_X))\n",
    "    for ax in range(ANGULAR_RES_X):\n",
    "        for ay in range(ANGULAR_RES_Y):\n",
    "            resized = lf[ay::ANGULAR_RES_Y, ax::ANGULAR_RES_X, :]\n",
    "            resized2 = cv2.resize(resized, dsize=(SPATIAL_WIDTH, SPATIAL_HEIGHT), interpolation=cv2.INTER_LINEAR)\n",
    "            full_LF_crop[:, :, :, ay, ax] = resized2\n",
    "            \n",
    "    #Take 8x8 LF on the middle, since the side part suffer from vignetting\n",
    "    middle_LF = full_LF_crop[:, :, :, 3:11, 3:11] # Take 8x8 LF in 5D\n",
    "    \n",
    "    #To visualize the 8x8 LF\n",
    "    for ax in range(8):\n",
    "        for ay in range(8):\n",
    "            if ay == 0:\n",
    "                y_img = middle_LF[:,:,:,ay,ax]\n",
    "            else:\n",
    "                y_img = np.concatenate((y_img, middle_LF[:,:,:,ay,ax]), 0)\n",
    "            \n",
    "            if ax == 0 and ay ==0:\n",
    "                LF_stack = middle_LF[:,:,:,0,0]\n",
    "            else:\n",
    "                LF_stack = np.concatenate((LF_stack, middle_LF[:,:,:,ay,ax]), 2)\n",
    "        if ax == 0:\n",
    "            LF_grid = y_img\n",
    "        else:\n",
    "            LF_grid = np.concatenate((LF_grid, y_img), 1)\n",
    "        y_img = middle_LF[:,:,:,ay,ax]\n",
    "    \n",
    "    center_view = middle_LF[:,:,:,3,3]\n",
    "    return center_view, LF_stack, LF_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Input_Pipeline'):\n",
    "    #Augment input\n",
    "    \n",
    "    #TRAIN CASE\n",
    "    gamma_val = tf.random_uniform(shape=[], minval=0.4, maxval=1.0) \n",
    "    #TEST CASE\n",
    "    #gamma_val = tf.random_uniform(shape=[], minval=0.4, maxval=0.5)  \n",
    "    \n",
    "    #X Single RGB image\n",
    "    tf_x = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT], name='Input')\n",
    "    tf_x = tf.image.adjust_gamma(tf_x, gamma_val)\n",
    "    view_image = tf.summary.image('input', tf.reshape(tf_x, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT]), 1)\n",
    "    image = tf.reshape(tf_x, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT], name='img_x')# (batch, height, width, channel)\n",
    "    image_min = preprocess(image) #-1..1\n",
    "    \n",
    "    #LF GT in grid style for visualization purpose only\n",
    "    tf_grid = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT], name='Grids')\n",
    "    tf_grid = tf.image.adjust_gamma(tf_grid, gamma_val)\n",
    "    label_image = tf.summary.image('GT', tf.reshape(tf_grid, [-1, SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT]), 1)\n",
    "    \n",
    "    #Y LF GT stacked in channel direction for loss\n",
    "    tf_y = tf.placeholder(tf.float32, [None, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_OUTPUT*64], name='Target')\n",
    "    tf_y = tf.image.adjust_gamma(tf_y, gamma_val)\n",
    "    color_norm = tf.reshape(tf_y, [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_OUTPUT*64], name='img_y')# (batch, height, width, channel)\n",
    "    color_norm_min = preprocess(color_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper function\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def load_image(addr):\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.imread(addr)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    center_view, GT, grid = process_LF(img)\n",
    "    \n",
    "    center_view = np.uint8(center_view)\n",
    "    grid = np.uint8(grid)\n",
    "    GT = np.uint8(GT)\n",
    "    \n",
    "    return center_view, GT, grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataRecord(out_filename, addrs):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(out_filename)\n",
    "    for i in range(len(addrs)):\n",
    "        # print how many images are loaded every # images\n",
    "        if not i % 10:\n",
    "            print('Train data: {}/{} images'.format(i, len(addrs)))\n",
    "            sys.stdout.flush()\n",
    "        # Load the image\n",
    "        img, label, grid = load_image(addrs[i]) \n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        if label is None:\n",
    "            continue\n",
    "            \n",
    "        if grid is None:\n",
    "            continue\n",
    "\n",
    "        # Create a feature\n",
    "        feature = {\n",
    "            'image_raw': _bytes_feature(img.tostring()),\n",
    "            'label': _bytes_feature(label.tostring()),\n",
    "            'grid': _bytes_feature(grid.tostring())\n",
    "        }\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with tf.name_scope('Data_Folder_Read'):\n",
    "#     input_path = INPUT_PATH\n",
    "#     addrs = sorted(glob.glob(input_path))\n",
    "    \n",
    "# with tf.name_scope('Shuffle_Data'):\n",
    "#     # to shuffle data\n",
    "#     c = list(addrs)\n",
    "#     shuffle(c)\n",
    "#     addrs = c\n",
    "\n",
    "# with tf.name_scope('Create_Datarecord_Train'):\n",
    "#     # Divide the data into % train and % test\n",
    "#     #train_addrs = addrs[0:int(TRAIN_SIZE*len(addrs))]\n",
    "#     #createDataRecord('train.tfrecords', train_addrs)\n",
    "    \n",
    "#     train_addrs = addrs[0:int(TRAIN_SIZE*len(addrs))]\n",
    "#     createDataRecord('train.tfrecords', train_addrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK STRUCTURE [SYNTHESIS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return shifting value based on the angular coordinate\n",
    "def shift_value(i):\n",
    "    if i<=7:\n",
    "        tx = 3*SHIFT_VALUE\n",
    "    elif i>7 and i<=15:\n",
    "        tx = 2*SHIFT_VALUE\n",
    "    elif i>15 and i<=23:\n",
    "        tx = 1*SHIFT_VALUE\n",
    "    elif i>23 and i<=31:\n",
    "        tx = 0\n",
    "    elif i>31 and i<=39:\n",
    "        tx = -1*SHIFT_VALUE\n",
    "    elif i>39 and i<=47:\n",
    "        tx = -2*SHIFT_VALUE\n",
    "    elif i>47 and i<=55:\n",
    "        tx = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        tx = -4*SHIFT_VALUE\n",
    "    \n",
    "    if i==0 or (i%8==0 and i>7):\n",
    "        ty = 3*SHIFT_VALUE\n",
    "    elif i == 1 or (i-1)%8==0:\n",
    "        ty = 2*SHIFT_VALUE\n",
    "    elif i == 2 or (i-2)%8==0:\n",
    "        ty = 1*SHIFT_VALUE\n",
    "    elif i == 3 or (i-3)%8==0:\n",
    "        ty = 0\n",
    "    elif i == 4 or (i-4)%8==0:\n",
    "        ty = -1*SHIFT_VALUE\n",
    "    elif i == 5 or (i-5)%8==0:\n",
    "        ty = -2*SHIFT_VALUE\n",
    "    elif i == 6 or (i-6)%8==0:\n",
    "        ty = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        ty = -4*SHIFT_VALUE\n",
    "        \n",
    "    return tx, ty\n",
    "\n",
    "def add_layer(input_=None, rate=1):\n",
    "    c = tf.nn.relu(input_)\n",
    "    c = tf.layers.conv2d(c, 12, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal(), dilation_rate=rate)\n",
    "    return tf.concat([input_, c], -1)\n",
    "\n",
    "def transition(input_=None):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    filters = shape[-1]\n",
    "    c = tf.nn.relu(input_)\n",
    "    c = tf.layers.conv2d(c, filters, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "    #No average pooling\n",
    "    return c\n",
    "\n",
    "def flow_layer(input_=None):\n",
    "    shape = input_.get_shape().as_list()\n",
    "    filters = shape[-1]\n",
    "    c = tf.nn.relu(input_)\n",
    "    c = tf.layers.conv2d(c, filters, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "    c = tf.layers.conv2d(c, filters, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())    \n",
    "    c = tf.layers.conv2d(c, (ANGULAR_RES_TARGET)*2, 3, padding='SAME', activation=None, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "    return c\n",
    "    \n",
    "def LF_Synthesis(input_=None):\n",
    "    with tf.name_scope('Initial_Conv'):\n",
    "        conv = tf.layers.conv2d(input_, 8, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal(), name='INITIAL_CONV_1')\n",
    "        conv = tf.layers.conv2d(conv, 16, 3, padding='SAME', activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal(), name='INITIAL_CONV_3')\n",
    "        conv_prob = conv\n",
    "        \n",
    "    with tf.name_scope('Flow_Generator'): #Dense Net\n",
    "        with tf.name_scope('Block_1'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv, 2)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Block_2'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv, 4)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Block_3'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv, 8)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Block_4'):\n",
    "            for i in range(3):\n",
    "                conv = add_layer(conv,16)\n",
    "            conv = transition(conv)\n",
    "\n",
    "        with tf.name_scope('Flow'):\n",
    "            flow_LF = flow_layer(conv)\n",
    "        \n",
    "    ###################################################################################################\n",
    "\n",
    "    #Synthesize LF by element wise multiplication with flow\n",
    "    with tf.name_scope('Estimation_Layer'):\n",
    "        yuv = tf.image.rgb_to_yuv(image)\n",
    "        y = yuv[:,:,:,0:1]\n",
    "        y = preprocess(y)\n",
    "        for i in range(ANGULAR_RES_TARGET):\n",
    "         \n",
    "            tx, ty = shift_value(i)\n",
    "            image_shift = tf_image_translate(image_min, tx, ty)\n",
    "            y_shift = tf_image_translate(y, tx, ty)\n",
    "            \n",
    "            if i==0:\n",
    "                pred_LF = bilinear_sampler(image_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "                \n",
    "                pred_LF_loss = bilinear_sampler(y_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "            elif i==27: #Input\n",
    "                pred_LF = tf.concat((pred_LF, image_min), -1)\n",
    "                \n",
    "                pred_LF_loss = tf.concat((pred_LF_loss, y), -1)\n",
    "            else:\n",
    "                trans_image = bilinear_sampler(image_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "                pred_LF = tf.concat((pred_LF, trans_image), -1)\n",
    "                \n",
    "                trans_image = bilinear_sampler(y_shift, flow_LF[:, :, :, i*2:(i*2)+2])\n",
    "                pred_LF_loss = tf.concat((pred_LF_loss, trans_image), -1)  \n",
    "                \n",
    "    print('pred_LF',pred_LF.shape)           \n",
    "    print('pred_LF_loss',pred_LF_loss.shape) \n",
    "    return pred_LF, pred_LF_loss, flow_LF\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_LF (?, 192, 256, 192)\n",
      "pred_LF_loss (?, 192, 256, 64)\n",
      "pred_LF_loss_H (?, 192, 256, 64)\n",
      "y_GT_H (?, 192, 256, 64)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('View_Synthesis'):\n",
    "    with tf.name_scope('Main_Network'):\n",
    "        #image_norm = tf.divide(image, 255)\n",
    "        yuv = tf.image.rgb_to_yuv(image)\n",
    "        Y = tf.summary.image('Y', tf.reshape(yuv[:,:,:,0:1], [-1, SPATIAL_HEIGHT, SPATIAL_WIDTH, 1]), 1)\n",
    "        y = preprocess(yuv[:,:,:,0:1])\n",
    "        pred_LF, pred_LF_loss, flow_LF = LF_Synthesis(y)\n",
    "        pred_LF_norm = deprocess(pred_LF)\n",
    "    #####################################################################################\n",
    "    with tf.name_scope('EPI_Slicing'):\n",
    "        \n",
    "        #Convert GT LF into Luma GT\n",
    "        for i in range(ANGULAR_RES_TARGET):  \n",
    "            temp = tf.image.rgb_to_yuv(color_norm[:,:,:,i*3:(i*3)+3])\n",
    "            if i == 0:\n",
    "                y_GT = temp[:,:,:,0:1]\n",
    "            else:\n",
    "                y_GT = tf.concat([y_GT, temp[:,:,:,0:1]], -1)\n",
    "        y_GT = preprocess(y_GT)    \n",
    "        \n",
    "        #Cross spatial EPI slice\n",
    "        center_width = int(SPATIAL_WIDTH/2)\n",
    "        center_height = int(SPATIAL_HEIGHT/2)\n",
    "\n",
    "        slice_epi_H = pred_LF_loss[:, center_height:center_height+1, :, :]\n",
    "        slice_epi_GT_H = y_GT[:, center_height:center_height+1, :, :]\n",
    "\n",
    "        slice_epi_V = pred_LF_loss[:, :, center_width:center_width+1, :]\n",
    "        slice_epi_GT_V = y_GT[:, :, center_width:center_width+1, :]\n",
    "\n",
    "        #Because of the stack is in row order for horizontal EPI it cannot be directly reshaped\n",
    "        for j in range(8):\n",
    "            for i in range(8):\n",
    "                temp = slice_epi_H[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                temp2 = slice_epi_GT_H[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                temp3 = pred_LF_loss[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                temp4 = y_GT[:, :, :, (i*8)+(j):(i*8)+(j)+1]\n",
    "                \n",
    "                if i==0 and j==0:\n",
    "                    epi_synth_H = temp\n",
    "                    epi_GT_H = temp2\n",
    "                    pred_LF_loss_H = temp3\n",
    "                    y_GT_H = temp4\n",
    "\n",
    "                else:\n",
    "                    epi_synth_H = tf.concat([epi_synth_H,temp], 1)\n",
    "                    epi_GT_H = tf.concat([epi_GT_H,temp2], 1)\n",
    "                    pred_LF_loss_H = tf.concat([pred_LF_loss_H,temp3], -1)\n",
    "                    y_GT_H = tf.concat([y_GT_H,temp4], -1)\n",
    "\n",
    "        \n",
    "        #Vertical EPI fit the image stack row order and can be directly obtained with just reshape\n",
    "        epi_synth_V = tf.reshape(slice_epi_V, [-1,SPATIAL_HEIGHT, 64, 1])\n",
    "        epi_GT_V = tf.reshape(slice_epi_GT_V, [-1,SPATIAL_HEIGHT, 64, 1])\n",
    "        \n",
    "        print('pred_LF_loss_H', pred_LF_loss_H.shape)\n",
    "        print('y_GT_H', y_GT_H.shape)\n",
    "        #####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "with tf.name_scope('Pixel_Based_Loss'):\n",
    "    #EPI based loss in horizontal and vertical direction sampled every 8 angular images\n",
    "    with tf.name_scope('L_Loss'):\n",
    "        pixel_loss_V = pixel_loss_H = 0\n",
    "        for i in range(8):  \n",
    "            temp1 = tf.reduce_sum(y_GT[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            temp2 = tf.reduce_sum(pred_LF_loss[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            pixel_loss_V += tf.losses.absolute_difference(temp1, temp2)\n",
    "            \n",
    "            temp3 = tf.reduce_sum(y_GT_H[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            temp4 = tf.reduce_sum(pred_LF_loss_H[:,:,:,(i*8):(i*8)+8], axis=-1)\n",
    "            pixel_loss_H += tf.losses.absolute_difference(temp3, temp4)\n",
    "            \n",
    "        tf.summary.scalar('pixel_loss_V', pixel_loss_V)\n",
    "        tf.summary.scalar('pixel_loss_H', pixel_loss_H)\n",
    "        \n",
    "        pixel_wise_loss = tf.losses.mean_squared_error(y_GT, pred_LF_loss)\n",
    "        tf.summary.scalar('pixel_wise_loss', pixel_wise_loss)\n",
    "    # Total variation loss for flow to surpress amount of artifact and smooth flow\n",
    "    with tf.name_scope('Total_Variation_Loss'):    \n",
    "        tv_loss_x = tf.reduce_mean(tf.image.total_variation(flow_LF[:,:,:,0::2]))\n",
    "        tv_loss_y = tf.reduce_mean(tf.image.total_variation(flow_LF[:,:,:,1::2]))\n",
    "        tv_loss = tf.reduce_mean(tv_loss_x + tv_loss_y)\n",
    "        tf.summary.scalar('TV_loss', tv_loss)\n",
    "\n",
    "    #Cross EPI loss. TODO: Can be removed redundant with EPI based loss\n",
    "#     with tf.name_scope('EPI_Loss'): \n",
    "#         epi_loss_H = tf.losses.absolute_difference(epi_GT_H, epi_synth_H)\n",
    "#         epi_loss_V = tf.losses.absolute_difference(epi_GT_V, epi_synth_V)\n",
    "#         epi_loss_total = epi_loss_H + epi_loss_V\n",
    "#         tf.summary.scalar('EPI_loss', epi_loss_total)\n",
    "        \n",
    "    \n",
    "with tf.name_scope('Total_Loss'):\n",
    "    Total_Loss = (LAMBDA_L1 * pixel_loss_V) + (LAMBDA_L1 * pixel_loss_H) \\\n",
    "                + (LAMBDA_TV * tv_loss) + (LAMBDA_PIXEL * pixel_wise_loss)\n",
    "    tf.summary.scalar('Total_Loss', Total_Loss)\n",
    "    y_img = pred_LF[:,:,:,0:3]\n",
    "    \n",
    "    \n",
    "    #Reshape the output into a grid LF\n",
    "    for i in range(1,ANGULAR_RES_TARGET):\n",
    "        if i==8:\n",
    "            grid_LF = y_img\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "                \n",
    "        elif i%8==0 and i>8:\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "\n",
    "        elif i == 63:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "\n",
    "        else:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "\n",
    "###################################################################################### \n",
    "\n",
    "with tf.name_scope('Evaluation'):\n",
    "    psnr = tf.image.psnr(color_norm, pred_LF_norm, max_val=1.0)\n",
    "    tf.summary.scalar('PSNR', psnr[0])\n",
    "    \n",
    "    ssim = tf.image.ssim(color_norm, pred_LF_norm, max_val=1.0)\n",
    "    tf.summary.scalar('SSIM', ssim[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Train'):\n",
    "    global_step_G = tf.Variable(0, dtype=tf.float32)\n",
    "    learning_rate_G = tf.train.exponential_decay(\n",
    "                      LR_G,                  # Base learning rate.\n",
    "                      global_step_G,         # Current index into the dataset.\n",
    "                      DECAY_STEP,            # Decay step.\n",
    "                      0.90,                  # Decay rate.\n",
    "                      staircase=True)\n",
    "    tf.summary.scalar('LR_G', learning_rate_G)\n",
    "    train_G = tf.train.AdamOptimizer(learning_rate=learning_rate_G, name='optimizer_G').minimize(Total_Loss, global_step=global_step_G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Visualization'):     \n",
    "    #Open the predicted LF into grid for EPI visualization\n",
    "    grid_LF = tf.zeros_like(image)\n",
    "    y_img = pred_LF[:,:,:,0:3]\n",
    "    \n",
    "    for i in range(1,ANGULAR_RES_TARGET):\n",
    "        if i==8:\n",
    "            grid_LF = y_img\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "\n",
    "                  \n",
    "        elif i%8==0 and i>8:\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "            y_img = pred_LF[:,:,:,i*3:(i*3)+3]\n",
    "            \n",
    "        elif i == 63:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "            grid_LF = tf.concat([grid_LF, y_img], 2)\n",
    "        \n",
    "        else:\n",
    "            y_img = tf.concat([y_img, pred_LF[:,:,:,i*3:(i*3)+3]], 1)\n",
    "            \n",
    "    ######################################################################################\n",
    "    \n",
    "    #TF Summary image\n",
    "    grid_LF_show = deprocess(grid_LF)\n",
    "    output_image = tf.summary.image('Synthesized_LF', tf.cast(tf.reshape(grid_LF_show*255, \n",
    "                            [-1, SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT]), tf.uint8) , 1)\n",
    "    \n",
    "    #EPI VISUALIZATION\n",
    "    with tf.name_scope('EPI'): \n",
    "        epi_synth_H = deprocess(epi_synth_H)\n",
    "        epi_GT_H = deprocess(epi_GT_H)\n",
    "        epi_synth_V = deprocess(epi_synth_V)\n",
    "        epi_GT_V = deprocess(epi_GT_V)\n",
    "        epi_horizontal = tf.summary.image('epi_horizontal', tf.cast(tf.reshape(epi_synth_H*255, \n",
    "                                [-1, 64, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        epi_horizontal_GT = tf.summary.image('epi_horizontal_GT', tf.cast(tf.reshape(epi_GT_H*255, \n",
    "                                [-1, 64, SPATIAL_WIDTH, 1]), tf.uint8) , 1)\n",
    "        epi_vertical = tf.summary.image('epi_vertical', tf.cast(tf.reshape(epi_synth_V*255, \n",
    "                                [-1, SPATIAL_HEIGHT, 64, 1]), tf.uint8) , 1)\n",
    "        epi_vertical_GT = tf.summary.image('epi_vertical_GT', tf.cast(tf.reshape(epi_GT_V*255, \n",
    "                                [-1, SPATIAL_HEIGHT, 64, 1]), tf.uint8) , 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SLICE another EPI in the LF to make sure not only cross EPI is correct but all EPI is correct\n",
    "with tf.name_scope('VALIDATION'): \n",
    "    center_width = tf.random_uniform(shape=[], minval=10, maxval=SPATIAL_WIDTH-10, dtype=tf.int32)\n",
    "    center_height = tf.random_uniform(shape=[], minval=10, maxval=SPATIAL_HEIGHT-10, dtype=tf.int32)\n",
    "\n",
    "    slice_epi_H2 = pred_LF_norm[:, center_height:center_height+1, :, :]\n",
    "    slice_epi_V2 = pred_LF_norm[:, :, center_width:center_width+1, :]\n",
    "    \n",
    "    slice_epi_GT_H2 = color_norm[:, center_height:center_height+1, :, :]\n",
    "    slice_epi_GT_V2 = color_norm[:, :, center_width:center_width+1, :]\n",
    "        \n",
    "\n",
    "    #Because of the stack is in row order for horizontal EPI it cannot be directly reshaped\n",
    "    for j in range(8):\n",
    "        for i in range(8):\n",
    "            temp = slice_epi_H2[:, :, :, (i*8*3)+(j*3):(i*8*3)+(j*3)+3]\n",
    "            temp2 = slice_epi_GT_H2[:, :, :, (i*8*3)+(j*3):(i*8*3)+(j*3)+3]\n",
    "            if i==0 and j==0:\n",
    "                epi_synth_H2 = temp\n",
    "                epi_GT_H2 = temp2\n",
    "            else:\n",
    "                epi_synth_H2 = tf.concat([epi_synth_H2,temp], 1)\n",
    "                epi_GT_H2 = tf.concat([epi_GT_H2,temp2], 1)\n",
    "\n",
    "    epi_synth_V2 = tf.reshape(slice_epi_V2, [-1,SPATIAL_HEIGHT, 64, 3])\n",
    "    epi_GT_V2 = tf.reshape(slice_epi_GT_V2, [-1,SPATIAL_HEIGHT, 64, 3])\n",
    "\n",
    "    EPI_H2 = tf.summary.image('epi_horizontal2', tf.cast(tf.reshape(epi_synth_H2*255, \n",
    "                            [-1, 64, SPATIAL_WIDTH, 3]), tf.uint8) , 1)\n",
    "    epi_horizontal_GT2 = tf.summary.image('epi_horizontal_GT2', tf.cast(tf.reshape(epi_GT_H2*255, \n",
    "                                [-1, 64, SPATIAL_WIDTH, 3]), tf.uint8) , 1)\n",
    "    EPI_V2 = tf.summary.image('epi_vertical2', tf.cast(tf.reshape(epi_synth_V2*255, \n",
    "                            [-1, SPATIAL_HEIGHT, 64, 3]), tf.uint8) , 1)\n",
    "    epi_vertical_GT2 = tf.summary.image('epi_vertical_GT2', tf.cast(tf.reshape(epi_GT_V2*255, \n",
    "                                [-1, SPATIAL_HEIGHT, 64, 3]), tf.uint8) , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get one record and parse it to get the label and image out\n",
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\":     tf.FixedLenFeature([], tf.string),\n",
    "        \"grid\":     tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    #Read one record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    #Take the image and bytes\n",
    "    image = tf.decode_raw(parsed[\"image_raw\"], tf.uint8)\n",
    "    label = tf.decode_raw(parsed[\"label\"], tf.uint8)\n",
    "    grid = tf.decode_raw(parsed[\"grid\"], tf.uint8)\n",
    "    #Cast to float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    grid = tf.cast(grid, tf.float32)\n",
    "    \n",
    "    image = tf.reshape(image, shape=[SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_INPUT])\n",
    "    label = tf.reshape(label, shape=[SPATIAL_HEIGHT, SPATIAL_WIDTH, CH_OUTPUT*64])\n",
    "    grid = tf.reshape(grid, shape=[SPATIAL_HEIGHT*8, SPATIAL_WIDTH*8, CH_OUTPUT])\n",
    "    #Normalize the input and label into [0...1]\n",
    "    image = tf.divide(image, 255)\n",
    "    label = tf.divide(label, 255)\n",
    "\n",
    "    return {'image': image}, {'label': label}, {'grid': grid}\n",
    "\n",
    "def input_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=1)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=1)\n",
    "    dataset = dataset.shuffle(50).repeat().batch(BATCH_SIZE)\n",
    "    #dataset = dataset.prefetch(buffer_size=2)\n",
    "    return dataset\n",
    "\n",
    "def test_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=1)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=1)\n",
    "    dataset = dataset.batch(10)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(filenames=[\"train.tfrecords\"])\n",
    "\n",
    "def test_input_fn():\n",
    "    return test_fn(filenames=[\"test.tfrecords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Create_Training_Set'):\n",
    "    train_dataset = train_input_fn()\n",
    "    iterator = train_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | loss:892.48090 | PSNR:18.587 | SSIM:0.745\n",
      "Model saved in path: saver/Synthesis/model0.ckpt\n",
      "Step: 300 | loss:440.47540 | PSNR:25.621 | SSIM:0.810\n",
      "Step: 600 | loss:215.62901 | PSNR:31.108 | SSIM:0.896\n",
      "Step: 900 | loss:381.49469 | PSNR:27.221 | SSIM:0.798\n",
      "Step: 1200 | loss:401.80212 | PSNR:26.232 | SSIM:0.822\n",
      "Step: 1500 | loss:139.62825 | PSNR:34.678 | SSIM:0.943\n",
      "Step: 1800 | loss:204.91272 | PSNR:30.058 | SSIM:0.909\n",
      "Step: 2100 | loss:512.47223 | PSNR:23.856 | SSIM:0.793\n",
      "Step: 2400 | loss:170.21962 | PSNR:34.024 | SSIM:0.901\n",
      "Step: 2700 | loss:286.08249 | PSNR:28.743 | SSIM:0.869\n",
      "Step: 3000 | loss:201.32086 | PSNR:33.309 | SSIM:0.903\n",
      "Step: 3300 | loss:394.19278 | PSNR:27.725 | SSIM:0.743\n",
      "Step: 3600 | loss:237.38304 | PSNR:30.965 | SSIM:0.871\n",
      "Step: 3900 | loss:116.07413 | PSNR:34.180 | SSIM:0.955\n",
      "Step: 4200 | loss:229.27771 | PSNR:32.823 | SSIM:0.886\n",
      "Step: 4500 | loss:85.70263 | PSNR:37.616 | SSIM:0.962\n",
      "Step: 4800 | loss:389.35004 | PSNR:27.348 | SSIM:0.821\n",
      "Step: 5100 | loss:283.82327 | PSNR:28.591 | SSIM:0.902\n",
      "Step: 5400 | loss:407.56448 | PSNR:26.028 | SSIM:0.843\n",
      "Step: 5700 | loss:274.98608 | PSNR:30.638 | SSIM:0.844\n",
      "Step: 6000 | loss:437.84634 | PSNR:25.307 | SSIM:0.823\n",
      "Step: 6300 | loss:168.18207 | PSNR:33.757 | SSIM:0.918\n",
      "Step: 6600 | loss:258.79642 | PSNR:28.637 | SSIM:0.917\n",
      "Step: 6900 | loss:274.44696 | PSNR:27.889 | SSIM:0.882\n",
      "Step: 7200 | loss:129.62891 | PSNR:37.050 | SSIM:0.941\n",
      "Step: 7500 | loss:311.46213 | PSNR:29.233 | SSIM:0.823\n",
      "Step: 7800 | loss:304.78482 | PSNR:28.465 | SSIM:0.846\n",
      "Step: 8100 | loss:148.99506 | PSNR:33.819 | SSIM:0.933\n",
      "Step: 8400 | loss:166.04852 | PSNR:34.276 | SSIM:0.920\n",
      "Step: 8700 | loss:342.06552 | PSNR:28.110 | SSIM:0.832\n",
      "Step: 9000 | loss:251.56564 | PSNR:32.290 | SSIM:0.859\n",
      "Step: 9300 | loss:126.58910 | PSNR:34.647 | SSIM:0.943\n",
      "Step: 9600 | loss:123.74358 | PSNR:35.227 | SSIM:0.948\n",
      "Step: 9900 | loss:452.86301 | PSNR:26.459 | SSIM:0.814\n",
      "Step: 10200 | loss:316.54056 | PSNR:25.959 | SSIM:0.894\n",
      "Step: 10500 | loss:123.09048 | PSNR:31.440 | SSIM:0.964\n",
      "Step: 10800 | loss:278.01993 | PSNR:27.803 | SSIM:0.919\n",
      "Step: 11100 | loss:296.69775 | PSNR:27.944 | SSIM:0.881\n",
      "Step: 11400 | loss:149.67172 | PSNR:32.159 | SSIM:0.951\n",
      "Step: 11700 | loss:117.68761 | PSNR:35.607 | SSIM:0.948\n",
      "Step: 12000 | loss:170.67435 | PSNR:31.503 | SSIM:0.935\n",
      "Step: 12300 | loss:327.93134 | PSNR:26.357 | SSIM:0.858\n",
      "Step: 12600 | loss:287.08176 | PSNR:27.324 | SSIM:0.897\n",
      "Step: 12900 | loss:208.45528 | PSNR:32.048 | SSIM:0.920\n",
      "Step: 13200 | loss:110.13429 | PSNR:37.332 | SSIM:0.962\n",
      "Step: 13500 | loss:106.98351 | PSNR:37.530 | SSIM:0.962\n",
      "Step: 13800 | loss:105.23714 | PSNR:36.005 | SSIM:0.961\n",
      "Step: 14100 | loss:171.32962 | PSNR:34.636 | SSIM:0.916\n",
      "Step: 14400 | loss:159.91954 | PSNR:32.504 | SSIM:0.942\n",
      "Step: 14700 | loss:101.46393 | PSNR:38.226 | SSIM:0.963\n",
      "Step: 15000 | loss:271.45605 | PSNR:28.245 | SSIM:0.896\n",
      "Step: 15300 | loss:231.02235 | PSNR:30.729 | SSIM:0.905\n",
      "Step: 15600 | loss:199.31389 | PSNR:32.475 | SSIM:0.930\n",
      "Step: 15900 | loss:101.31195 | PSNR:36.792 | SSIM:0.960\n",
      "Step: 16200 | loss:290.39249 | PSNR:30.166 | SSIM:0.841\n",
      "Step: 16500 | loss:120.16104 | PSNR:36.846 | SSIM:0.954\n",
      "Step: 16800 | loss:146.22066 | PSNR:35.028 | SSIM:0.942\n",
      "Step: 17100 | loss:211.08536 | PSNR:28.189 | SSIM:0.935\n",
      "Step: 17400 | loss:182.49101 | PSNR:33.381 | SSIM:0.930\n",
      "Step: 17700 | loss:178.92363 | PSNR:30.738 | SSIM:0.950\n",
      "Step: 18000 | loss:198.00909 | PSNR:30.400 | SSIM:0.928\n",
      "Step: 18300 | loss:145.50568 | PSNR:32.511 | SSIM:0.946\n",
      "Step: 18600 | loss:85.45091 | PSNR:38.460 | SSIM:0.971\n",
      "Step: 18900 | loss:232.92467 | PSNR:29.695 | SSIM:0.898\n",
      "Step: 19200 | loss:321.13699 | PSNR:28.674 | SSIM:0.812\n",
      "Step: 19500 | loss:135.94539 | PSNR:34.798 | SSIM:0.957\n",
      "Step: 19800 | loss:233.80150 | PSNR:31.203 | SSIM:0.874\n",
      "Model saved in path: saver/Synthesis/model20000.ckpt\n",
      "Step: 20100 | loss:213.03769 | PSNR:31.604 | SSIM:0.914\n",
      "Step: 20400 | loss:483.65936 | PSNR:23.974 | SSIM:0.848\n",
      "Step: 20700 | loss:158.92094 | PSNR:32.232 | SSIM:0.944\n",
      "Step: 21000 | loss:305.16858 | PSNR:28.232 | SSIM:0.869\n",
      "Step: 21300 | loss:126.85633 | PSNR:37.104 | SSIM:0.948\n",
      "Step: 21600 | loss:211.22243 | PSNR:32.136 | SSIM:0.890\n",
      "Step: 21900 | loss:154.53630 | PSNR:34.049 | SSIM:0.940\n",
      "Step: 22200 | loss:113.58696 | PSNR:37.007 | SSIM:0.953\n",
      "Step: 22500 | loss:139.40308 | PSNR:34.879 | SSIM:0.956\n",
      "Step: 22800 | loss:110.22096 | PSNR:36.991 | SSIM:0.964\n",
      "Step: 23100 | loss:131.09851 | PSNR:36.158 | SSIM:0.952\n",
      "Step: 23400 | loss:119.51323 | PSNR:35.922 | SSIM:0.953\n",
      "Step: 23700 | loss:234.05164 | PSNR:30.433 | SSIM:0.909\n",
      "Step: 24000 | loss:236.78493 | PSNR:27.460 | SSIM:0.945\n",
      "Step: 24300 | loss:170.47940 | PSNR:33.232 | SSIM:0.936\n",
      "Step: 24600 | loss:153.63397 | PSNR:34.396 | SSIM:0.932\n",
      "Step: 24900 | loss:80.22989 | PSNR:38.134 | SSIM:0.967\n",
      "Step: 25200 | loss:169.11235 | PSNR:33.723 | SSIM:0.922\n",
      "Step: 25500 | loss:266.76523 | PSNR:29.873 | SSIM:0.849\n",
      "Step: 25800 | loss:312.90692 | PSNR:30.147 | SSIM:0.841\n",
      "Step: 26100 | loss:146.52222 | PSNR:34.565 | SSIM:0.958\n",
      "Step: 26400 | loss:190.88924 | PSNR:33.712 | SSIM:0.930\n",
      "Step: 26700 | loss:223.23933 | PSNR:31.636 | SSIM:0.898\n",
      "Step: 27000 | loss:233.60789 | PSNR:30.828 | SSIM:0.891\n",
      "Step: 27300 | loss:185.72801 | PSNR:32.803 | SSIM:0.914\n",
      "Step: 27600 | loss:113.90381 | PSNR:36.445 | SSIM:0.960\n",
      "Step: 27900 | loss:170.02438 | PSNR:31.858 | SSIM:0.961\n",
      "Step: 28200 | loss:118.18345 | PSNR:36.916 | SSIM:0.937\n",
      "Step: 28500 | loss:313.38150 | PSNR:29.173 | SSIM:0.871\n",
      "Step: 28800 | loss:110.31860 | PSNR:34.082 | SSIM:0.968\n",
      "Step: 29100 | loss:257.65005 | PSNR:29.850 | SSIM:0.916\n",
      "Step: 29400 | loss:215.53398 | PSNR:30.514 | SSIM:0.937\n",
      "Step: 29700 | loss:90.09704 | PSNR:37.931 | SSIM:0.969\n",
      "Step: 30000 | loss:212.78432 | PSNR:31.215 | SSIM:0.904\n",
      "Step: 30300 | loss:260.02094 | PSNR:29.904 | SSIM:0.922\n",
      "Step: 30600 | loss:139.21899 | PSNR:34.297 | SSIM:0.953\n",
      "Step: 30900 | loss:133.66260 | PSNR:35.252 | SSIM:0.943\n",
      "Step: 31200 | loss:135.02852 | PSNR:35.508 | SSIM:0.949\n",
      "Step: 31500 | loss:104.29642 | PSNR:37.426 | SSIM:0.964\n",
      "Step: 31800 | loss:257.85052 | PSNR:28.995 | SSIM:0.916\n",
      "Step: 32100 | loss:198.20241 | PSNR:30.597 | SSIM:0.946\n",
      "Step: 32400 | loss:226.15135 | PSNR:29.496 | SSIM:0.927\n",
      "Step: 32700 | loss:134.47066 | PSNR:32.010 | SSIM:0.967\n",
      "Step: 33000 | loss:146.77852 | PSNR:34.565 | SSIM:0.938\n",
      "Step: 33300 | loss:109.09405 | PSNR:37.237 | SSIM:0.959\n",
      "Step: 33600 | loss:135.53712 | PSNR:33.656 | SSIM:0.972\n",
      "Step: 33900 | loss:150.63795 | PSNR:34.255 | SSIM:0.944\n",
      "Step: 34200 | loss:167.85909 | PSNR:33.244 | SSIM:0.924\n",
      "Step: 34500 | loss:124.61698 | PSNR:36.016 | SSIM:0.955\n",
      "Step: 34800 | loss:216.95187 | PSNR:31.733 | SSIM:0.932\n",
      "Step: 35100 | loss:179.58495 | PSNR:31.743 | SSIM:0.952\n",
      "Step: 35400 | loss:198.60010 | PSNR:33.426 | SSIM:0.904\n",
      "Step: 35700 | loss:327.90485 | PSNR:26.264 | SSIM:0.892\n",
      "Step: 36000 | loss:181.86525 | PSNR:32.154 | SSIM:0.935\n",
      "Step: 36300 | loss:104.92422 | PSNR:36.218 | SSIM:0.971\n",
      "Step: 36600 | loss:177.33231 | PSNR:30.231 | SSIM:0.965\n",
      "Step: 36900 | loss:133.09674 | PSNR:35.569 | SSIM:0.958\n",
      "Step: 37200 | loss:122.27847 | PSNR:34.560 | SSIM:0.965\n",
      "Step: 37500 | loss:232.77538 | PSNR:29.687 | SSIM:0.931\n",
      "Step: 37800 | loss:85.50813 | PSNR:37.997 | SSIM:0.963\n",
      "Step: 38100 | loss:254.96228 | PSNR:27.053 | SSIM:0.934\n",
      "Step: 38400 | loss:121.45573 | PSNR:36.893 | SSIM:0.963\n",
      "Step: 38700 | loss:115.47270 | PSNR:37.393 | SSIM:0.923\n",
      "Step: 39000 | loss:95.98714 | PSNR:37.028 | SSIM:0.964\n",
      "Step: 39300 | loss:181.65559 | PSNR:30.998 | SSIM:0.945\n",
      "Step: 39600 | loss:329.57971 | PSNR:26.470 | SSIM:0.889\n",
      "Step: 39900 | loss:249.52835 | PSNR:31.211 | SSIM:0.788\n",
      "Model saved in path: saver/Synthesis/model40000.ckpt\n",
      "Step: 40200 | loss:161.17126 | PSNR:34.234 | SSIM:0.934\n",
      "Step: 40500 | loss:222.91328 | PSNR:28.431 | SSIM:0.953\n",
      "Step: 40800 | loss:127.51934 | PSNR:35.709 | SSIM:0.952\n",
      "Step: 41100 | loss:91.74582 | PSNR:38.393 | SSIM:0.973\n",
      "Step: 41400 | loss:223.17157 | PSNR:29.784 | SSIM:0.930\n",
      "Step: 41700 | loss:178.58179 | PSNR:33.231 | SSIM:0.926\n",
      "Step: 42000 | loss:235.72514 | PSNR:30.372 | SSIM:0.893\n",
      "Step: 42300 | loss:138.15883 | PSNR:35.043 | SSIM:0.949\n",
      "Step: 42600 | loss:116.32423 | PSNR:35.889 | SSIM:0.956\n",
      "Step: 42900 | loss:163.52315 | PSNR:32.895 | SSIM:0.947\n",
      "Step: 43200 | loss:185.35350 | PSNR:29.420 | SSIM:0.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 43500 | loss:228.27841 | PSNR:27.352 | SSIM:0.933\n",
      "Step: 43800 | loss:200.59691 | PSNR:30.171 | SSIM:0.945\n",
      "Step: 44100 | loss:205.93430 | PSNR:33.024 | SSIM:0.916\n",
      "Step: 44400 | loss:119.82607 | PSNR:36.074 | SSIM:0.965\n",
      "Step: 44700 | loss:126.33183 | PSNR:33.807 | SSIM:0.956\n",
      "Step: 45000 | loss:103.90488 | PSNR:36.946 | SSIM:0.971\n",
      "Step: 45300 | loss:165.84773 | PSNR:32.655 | SSIM:0.954\n",
      "Step: 45600 | loss:365.13190 | PSNR:27.875 | SSIM:0.890\n",
      "Step: 45900 | loss:207.92690 | PSNR:30.498 | SSIM:0.931\n",
      "Step: 46200 | loss:172.07497 | PSNR:33.671 | SSIM:0.928\n",
      "Step: 46500 | loss:392.53528 | PSNR:24.623 | SSIM:0.888\n",
      "Step: 46800 | loss:225.60959 | PSNR:30.262 | SSIM:0.917\n",
      "Step: 47100 | loss:208.84998 | PSNR:31.436 | SSIM:0.940\n",
      "Step: 47400 | loss:105.61834 | PSNR:37.096 | SSIM:0.965\n",
      "Step: 47700 | loss:187.36946 | PSNR:33.377 | SSIM:0.922\n",
      "Step: 48000 | loss:125.13520 | PSNR:36.791 | SSIM:0.966\n",
      "Step: 48300 | loss:136.31500 | PSNR:35.480 | SSIM:0.948\n",
      "Step: 48600 | loss:135.92682 | PSNR:34.507 | SSIM:0.953\n",
      "Step: 48900 | loss:129.73169 | PSNR:34.218 | SSIM:0.964\n",
      "Step: 49200 | loss:161.90771 | PSNR:34.639 | SSIM:0.943\n",
      "Step: 49500 | loss:84.72415 | PSNR:39.260 | SSIM:0.968\n",
      "Step: 49800 | loss:192.16022 | PSNR:32.760 | SSIM:0.906\n",
      "Step: 50100 | loss:189.11798 | PSNR:31.553 | SSIM:0.928\n",
      "Step: 50400 | loss:105.33298 | PSNR:36.855 | SSIM:0.965\n",
      "Step: 50700 | loss:112.94008 | PSNR:36.601 | SSIM:0.965\n",
      "Step: 51000 | loss:168.75266 | PSNR:32.129 | SSIM:0.947\n",
      "Step: 51300 | loss:95.77668 | PSNR:39.716 | SSIM:0.957\n",
      "Step: 51600 | loss:202.09969 | PSNR:31.641 | SSIM:0.941\n",
      "Step: 51900 | loss:193.85754 | PSNR:33.139 | SSIM:0.890\n",
      "Step: 52200 | loss:279.76205 | PSNR:30.603 | SSIM:0.888\n",
      "Step: 52500 | loss:181.03979 | PSNR:34.083 | SSIM:0.935\n",
      "Step: 52800 | loss:381.32230 | PSNR:24.758 | SSIM:0.892\n",
      "Step: 53100 | loss:87.63846 | PSNR:35.347 | SSIM:0.973\n",
      "Step: 53400 | loss:100.15038 | PSNR:34.131 | SSIM:0.977\n",
      "Step: 53700 | loss:120.83681 | PSNR:36.528 | SSIM:0.950\n",
      "Step: 54000 | loss:116.74009 | PSNR:35.136 | SSIM:0.957\n",
      "Step: 54300 | loss:138.01160 | PSNR:35.079 | SSIM:0.959\n",
      "Step: 54600 | loss:62.12839 | PSNR:41.195 | SSIM:0.981\n",
      "Step: 54900 | loss:121.66195 | PSNR:35.880 | SSIM:0.965\n",
      "Step: 55200 | loss:136.93390 | PSNR:31.260 | SSIM:0.972\n",
      "Step: 55500 | loss:118.15467 | PSNR:34.829 | SSIM:0.964\n",
      "Step: 55800 | loss:342.21826 | PSNR:25.229 | SSIM:0.890\n",
      "Step: 56100 | loss:118.37076 | PSNR:36.899 | SSIM:0.954\n",
      "Step: 56400 | loss:164.45546 | PSNR:32.953 | SSIM:0.934\n",
      "Step: 56700 | loss:148.80331 | PSNR:34.788 | SSIM:0.930\n",
      "Step: 57000 | loss:168.57709 | PSNR:32.127 | SSIM:0.964\n",
      "Step: 57300 | loss:119.74036 | PSNR:35.637 | SSIM:0.968\n",
      "Step: 57600 | loss:138.44232 | PSNR:35.152 | SSIM:0.946\n",
      "Step: 57900 | loss:166.53038 | PSNR:33.515 | SSIM:0.941\n",
      "Step: 58200 | loss:132.90526 | PSNR:33.477 | SSIM:0.958\n",
      "Step: 58500 | loss:153.16995 | PSNR:33.505 | SSIM:0.945\n",
      "Step: 58800 | loss:178.37022 | PSNR:33.294 | SSIM:0.931\n",
      "Step: 59100 | loss:191.65448 | PSNR:32.842 | SSIM:0.893\n",
      "Step: 59400 | loss:348.37805 | PSNR:28.750 | SSIM:0.775\n",
      "Step: 59700 | loss:86.11137 | PSNR:35.135 | SSIM:0.980\n",
      "Step: 60000 | loss:262.66180 | PSNR:30.760 | SSIM:0.916\n",
      "Model saved in path: saver/Synthesis/model60000.ckpt\n",
      "Step: 60300 | loss:127.32607 | PSNR:34.036 | SSIM:0.960\n",
      "Step: 60600 | loss:239.58852 | PSNR:30.118 | SSIM:0.908\n",
      "Step: 60900 | loss:156.31984 | PSNR:32.987 | SSIM:0.945\n",
      "Step: 61200 | loss:202.60168 | PSNR:31.410 | SSIM:0.940\n",
      "Step: 61500 | loss:231.38737 | PSNR:28.224 | SSIM:0.940\n",
      "Step: 61800 | loss:201.01381 | PSNR:30.001 | SSIM:0.935\n",
      "Step: 62100 | loss:120.06099 | PSNR:36.922 | SSIM:0.959\n",
      "Step: 62400 | loss:198.66704 | PSNR:33.278 | SSIM:0.915\n",
      "Step: 62700 | loss:134.13939 | PSNR:35.558 | SSIM:0.947\n",
      "Step: 63000 | loss:224.56767 | PSNR:30.164 | SSIM:0.922\n",
      "Step: 63300 | loss:110.02427 | PSNR:37.460 | SSIM:0.957\n",
      "Step: 63600 | loss:133.15227 | PSNR:35.743 | SSIM:0.956\n",
      "Step: 63900 | loss:133.80254 | PSNR:35.006 | SSIM:0.954\n",
      "Step: 64200 | loss:178.03075 | PSNR:31.184 | SSIM:0.933\n",
      "Step: 64500 | loss:184.92889 | PSNR:31.636 | SSIM:0.922\n",
      "Step: 64800 | loss:86.92271 | PSNR:38.490 | SSIM:0.977\n",
      "Step: 65100 | loss:86.63088 | PSNR:39.123 | SSIM:0.971\n",
      "Step: 65400 | loss:127.71682 | PSNR:36.241 | SSIM:0.954\n",
      "Step: 65700 | loss:222.72978 | PSNR:27.487 | SSIM:0.950\n",
      "Step: 66000 | loss:184.69910 | PSNR:30.612 | SSIM:0.949\n",
      "Step: 66300 | loss:148.55391 | PSNR:33.743 | SSIM:0.948\n",
      "Step: 66600 | loss:91.94895 | PSNR:38.431 | SSIM:0.974\n",
      "Step: 66900 | loss:210.71191 | PSNR:32.404 | SSIM:0.897\n",
      "Step: 67200 | loss:90.01531 | PSNR:38.606 | SSIM:0.973\n",
      "Step: 67500 | loss:113.80529 | PSNR:36.687 | SSIM:0.967\n",
      "Step: 67800 | loss:87.19758 | PSNR:38.826 | SSIM:0.965\n",
      "Step: 68100 | loss:330.09467 | PSNR:29.369 | SSIM:0.791\n",
      "Step: 68400 | loss:134.11449 | PSNR:35.515 | SSIM:0.941\n",
      "Step: 68700 | loss:168.75073 | PSNR:32.376 | SSIM:0.951\n",
      "Step: 69000 | loss:91.10703 | PSNR:38.488 | SSIM:0.972\n",
      "Step: 69300 | loss:189.86345 | PSNR:33.307 | SSIM:0.925\n",
      "Step: 69600 | loss:89.25094 | PSNR:36.848 | SSIM:0.974\n",
      "Step: 69900 | loss:116.63553 | PSNR:34.790 | SSIM:0.960\n",
      "Step: 70200 | loss:59.16630 | PSNR:42.590 | SSIM:0.981\n",
      "Step: 70500 | loss:110.13934 | PSNR:37.353 | SSIM:0.956\n",
      "Step: 70800 | loss:178.44766 | PSNR:33.071 | SSIM:0.935\n",
      "Step: 71100 | loss:126.55199 | PSNR:35.369 | SSIM:0.958\n",
      "Step: 71400 | loss:86.26077 | PSNR:40.863 | SSIM:0.958\n",
      "Step: 71700 | loss:263.69312 | PSNR:29.864 | SSIM:0.929\n",
      "Step: 72000 | loss:99.79317 | PSNR:36.396 | SSIM:0.973\n",
      "Step: 72300 | loss:132.81203 | PSNR:32.234 | SSIM:0.965\n",
      "Step: 72600 | loss:99.93217 | PSNR:37.351 | SSIM:0.970\n",
      "Step: 72900 | loss:186.44431 | PSNR:31.700 | SSIM:0.946\n",
      "Step: 73200 | loss:161.86160 | PSNR:32.345 | SSIM:0.951\n",
      "Step: 73500 | loss:106.23661 | PSNR:36.516 | SSIM:0.965\n",
      "Step: 73800 | loss:172.00108 | PSNR:33.741 | SSIM:0.933\n",
      "Step: 74100 | loss:88.72715 | PSNR:38.332 | SSIM:0.969\n",
      "Step: 74400 | loss:126.01765 | PSNR:36.349 | SSIM:0.955\n",
      "Step: 74700 | loss:131.15164 | PSNR:36.319 | SSIM:0.954\n",
      "Step: 75000 | loss:127.21889 | PSNR:34.215 | SSIM:0.974\n",
      "Step: 75300 | loss:184.51845 | PSNR:33.175 | SSIM:0.940\n",
      "Step: 75600 | loss:153.15091 | PSNR:35.095 | SSIM:0.951\n",
      "Step: 75900 | loss:250.76282 | PSNR:31.163 | SSIM:0.784\n",
      "Step: 76200 | loss:116.61245 | PSNR:35.217 | SSIM:0.965\n",
      "Step: 76500 | loss:191.17838 | PSNR:32.676 | SSIM:0.920\n",
      "Step: 76800 | loss:160.11363 | PSNR:33.643 | SSIM:0.943\n",
      "Step: 77100 | loss:200.73576 | PSNR:29.965 | SSIM:0.934\n",
      "Step: 77400 | loss:122.70181 | PSNR:35.865 | SSIM:0.965\n",
      "Step: 77700 | loss:215.27759 | PSNR:29.110 | SSIM:0.931\n",
      "Step: 78000 | loss:75.64704 | PSNR:40.483 | SSIM:0.975\n",
      "Step: 78300 | loss:139.33742 | PSNR:31.886 | SSIM:0.963\n",
      "Step: 78600 | loss:176.41267 | PSNR:31.941 | SSIM:0.946\n",
      "Step: 78900 | loss:107.30469 | PSNR:37.532 | SSIM:0.964\n",
      "Step: 79200 | loss:235.16948 | PSNR:28.280 | SSIM:0.934\n",
      "Step: 79500 | loss:123.41206 | PSNR:36.268 | SSIM:0.959\n",
      "Step: 79800 | loss:129.56693 | PSNR:35.278 | SSIM:0.956\n",
      "Model saved in path: saver/Synthesis/model80000.ckpt\n",
      "Step: 80100 | loss:225.71829 | PSNR:31.320 | SSIM:0.740\n",
      "Step: 80400 | loss:134.99901 | PSNR:35.981 | SSIM:0.961\n",
      "Step: 80700 | loss:104.87914 | PSNR:38.502 | SSIM:0.971\n",
      "Step: 81000 | loss:239.40538 | PSNR:28.496 | SSIM:0.924\n",
      "Step: 81300 | loss:145.96378 | PSNR:35.973 | SSIM:0.939\n",
      "Step: 81600 | loss:145.60254 | PSNR:34.555 | SSIM:0.942\n",
      "Step: 81900 | loss:91.99689 | PSNR:38.687 | SSIM:0.973\n",
      "Step: 82200 | loss:145.23206 | PSNR:32.554 | SSIM:0.968\n",
      "Step: 82500 | loss:82.74242 | PSNR:38.852 | SSIM:0.967\n",
      "Step: 82800 | loss:110.37941 | PSNR:36.719 | SSIM:0.963\n",
      "Step: 83100 | loss:100.74382 | PSNR:36.798 | SSIM:0.969\n",
      "Step: 83400 | loss:152.11282 | PSNR:34.318 | SSIM:0.954\n",
      "Step: 83700 | loss:164.24030 | PSNR:34.689 | SSIM:0.934\n",
      "Step: 84000 | loss:143.98708 | PSNR:32.650 | SSIM:0.960\n",
      "Step: 84300 | loss:89.51094 | PSNR:39.016 | SSIM:0.964\n",
      "Step: 84600 | loss:104.06776 | PSNR:38.511 | SSIM:0.958\n",
      "Step: 84900 | loss:94.51147 | PSNR:38.032 | SSIM:0.963\n",
      "Step: 85200 | loss:153.31509 | PSNR:32.971 | SSIM:0.944\n",
      "Step: 85500 | loss:120.78328 | PSNR:36.331 | SSIM:0.966\n",
      "Step: 85800 | loss:99.60249 | PSNR:38.503 | SSIM:0.958\n",
      "Step: 86100 | loss:177.97478 | PSNR:32.112 | SSIM:0.950\n",
      "Step: 86400 | loss:177.07120 | PSNR:33.704 | SSIM:0.924\n",
      "Step: 86700 | loss:89.01134 | PSNR:38.102 | SSIM:0.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 87000 | loss:126.42300 | PSNR:33.068 | SSIM:0.967\n",
      "Step: 87300 | loss:114.91788 | PSNR:35.569 | SSIM:0.963\n",
      "Step: 87600 | loss:171.35657 | PSNR:32.707 | SSIM:0.937\n",
      "Step: 87900 | loss:102.74484 | PSNR:35.307 | SSIM:0.969\n",
      "Step: 88200 | loss:112.69872 | PSNR:36.503 | SSIM:0.961\n",
      "Step: 88500 | loss:110.20403 | PSNR:37.664 | SSIM:0.967\n",
      "Step: 88800 | loss:119.30759 | PSNR:36.053 | SSIM:0.967\n",
      "Step: 89100 | loss:119.60025 | PSNR:33.782 | SSIM:0.973\n",
      "Step: 89400 | loss:84.58283 | PSNR:39.018 | SSIM:0.968\n",
      "Step: 89700 | loss:101.39545 | PSNR:36.879 | SSIM:0.966\n",
      "Step: 90000 | loss:115.58080 | PSNR:37.130 | SSIM:0.952\n",
      "Step: 90300 | loss:246.66005 | PSNR:30.918 | SSIM:0.800\n",
      "Step: 90600 | loss:84.51998 | PSNR:39.764 | SSIM:0.965\n",
      "Step: 90900 | loss:123.80022 | PSNR:36.341 | SSIM:0.950\n",
      "Step: 91200 | loss:153.62689 | PSNR:33.709 | SSIM:0.963\n",
      "Step: 91500 | loss:92.91564 | PSNR:38.231 | SSIM:0.971\n",
      "Step: 91800 | loss:110.58170 | PSNR:36.632 | SSIM:0.971\n",
      "Step: 92100 | loss:96.20409 | PSNR:35.944 | SSIM:0.969\n",
      "Step: 92400 | loss:201.16324 | PSNR:33.425 | SSIM:0.918\n",
      "Step: 92700 | loss:184.03214 | PSNR:32.810 | SSIM:0.861\n",
      "Step: 93000 | loss:153.82233 | PSNR:32.364 | SSIM:0.954\n",
      "Step: 93300 | loss:284.05771 | PSNR:28.803 | SSIM:0.850\n",
      "Step: 93600 | loss:136.09511 | PSNR:35.452 | SSIM:0.947\n",
      "Step: 93900 | loss:143.53831 | PSNR:35.139 | SSIM:0.937\n",
      "Step: 94200 | loss:140.02768 | PSNR:35.716 | SSIM:0.953\n",
      "Step: 94500 | loss:133.60841 | PSNR:31.300 | SSIM:0.959\n",
      "Step: 94800 | loss:195.20244 | PSNR:31.687 | SSIM:0.943\n",
      "Step: 95100 | loss:113.90021 | PSNR:34.909 | SSIM:0.962\n",
      "Step: 95400 | loss:209.90787 | PSNR:30.155 | SSIM:0.928\n",
      "Step: 95700 | loss:209.45767 | PSNR:31.094 | SSIM:0.947\n",
      "Step: 96000 | loss:85.22211 | PSNR:38.638 | SSIM:0.973\n",
      "Step: 96300 | loss:138.19214 | PSNR:35.035 | SSIM:0.947\n",
      "Step: 96600 | loss:137.86885 | PSNR:36.087 | SSIM:0.940\n",
      "Step: 96900 | loss:266.41672 | PSNR:29.895 | SSIM:0.867\n",
      "Step: 97200 | loss:123.60839 | PSNR:36.152 | SSIM:0.952\n",
      "Step: 97500 | loss:158.08400 | PSNR:34.512 | SSIM:0.928\n",
      "Step: 97800 | loss:171.31062 | PSNR:33.754 | SSIM:0.923\n",
      "Step: 98100 | loss:163.63187 | PSNR:33.954 | SSIM:0.952\n",
      "Step: 98400 | loss:62.80344 | PSNR:42.216 | SSIM:0.980\n",
      "Step: 98700 | loss:193.43855 | PSNR:31.852 | SSIM:0.919\n",
      "Step: 99000 | loss:284.33325 | PSNR:27.880 | SSIM:0.936\n",
      "Step: 99300 | loss:117.08349 | PSNR:36.882 | SSIM:0.954\n",
      "Step: 99600 | loss:166.38896 | PSNR:34.795 | SSIM:0.936\n",
      "Step: 99900 | loss:149.03987 | PSNR:32.040 | SSIM:0.960\n",
      "Model saved in path: saver/Synthesis/model100000.ckpt\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(tf.group(tf.global_variables_initializer(), iterator.initializer))\n",
    "writer = tf.summary.FileWriter('log/Synthesis/DENSE_GAN',sess.graph)\n",
    "\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True, trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "for step in range(EPOCH+1):\n",
    "    train_x, train_y, train_grid = sess.run(next_batch)                       \n",
    "    \n",
    "    _, G_loss_, psnr_, ssim_ = sess.run([train_G, Total_Loss, psnr, ssim], \n",
    "    {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']})\n",
    "   \n",
    "    if step%300 == 0:\n",
    "        #writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "        summary_ = sess.run(merged, {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']}\n",
    "                           , options=run_options, run_metadata=run_metadata)\n",
    "        writer.add_summary(summary_, step)     \n",
    "        print('Step:', step, '| loss:%.5f' %G_loss_, '| PSNR:%.3f' %psnr_[0], '| SSIM:%.3f' %ssim_[0])\n",
    "        \n",
    "    if step%20000==0:\n",
    "        save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "        print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN RESTORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged = tf.summary.merge_all()\n",
    "# saver = tf.train.Saver()\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "# sess=tf.Session(config=config)\n",
    "# sess.run(iterator.initializer)\n",
    "# writer = tf.summary.FileWriter('log/Synthesis/Restore',sess.graph)\n",
    "\n",
    "# run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True, trace_level=tf.RunOptions.FULL_TRACE)\n",
    "# run_metadata = tf.RunMetadata()\n",
    "# saver.restore(sess, \"saver/Synthesis/model1.ckpt\")\n",
    "\n",
    "# for step in range(EPOCH+1):\n",
    "#     train_x, train_y, train_grid = sess.run(next_batch)    \n",
    "\n",
    "# #     _, G_loss_, psnr_ = sess.run([train_op, total_loss, psnr], \n",
    "# #         {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']}, options=run_options, run_metadata=run_metadata)\n",
    "    \n",
    "#     if step%1 == 0:\n",
    "#         _, G_loss_, psnr_ = sess.run([train_G, G_Adv_loss, psnr], \n",
    "#         {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']})\n",
    "#     if step%1 == 0:\n",
    "#         _, D_loss_ = sess.run([train_D, D_Total_Loss], \n",
    "#         {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']})\n",
    "   \n",
    "#     if step%150 == 0:\n",
    "#         #writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "#         summary_ = sess.run(merged, {tf_x:train_x['image'], tf_y:train_y['label'], tf_grid:train_grid['grid']}\n",
    "#                            , options=run_options, run_metadata=run_metadata)\n",
    "#         writer.add_summary(summary_, step)     \n",
    "#         print('Step:', step, '| G loss:%.5f' %G_loss_, '| D loss:%.5f' %D_loss_, '| PSNR[0]:%.3f' %psnr_[0])\n",
    "        \n",
    "#     if step%15000==0:\n",
    "#         save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "#         print(\"Model saved in path: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('Test_Folder_Read'):\n",
    "#     label_path = TEST_PATH\n",
    "#     addrs = sorted(glob.glob(label_path))\n",
    "    \n",
    "# with tf.name_scope('Create_Datarecord_Test'):\n",
    "#     test_addrs = addrs[:]\n",
    "#     createDataRecord('test.tfrecords', test_addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "with tf.name_scope('Create_Test_Set'):\n",
    "    test_dataset = test_input_fn()\n",
    "    iterator = test_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "sess.run(iterator.initializer)\n",
    "writer = tf.summary.FileWriter('log/Synthesis/Test',sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "%%time\n",
    "saver.restore(sess, \"saver/Synthesis/model120000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_x, test_y, test_grid = sess.run(next_batch)\n",
    "output_, grid_, epi_H_, epi_V_, epi_GT_H_, epi_GT_V_, summary_ = sess.run(\n",
    "    [pred_LF_norm, grid_LF_show, epi_synth_H2, epi_synth_V2, epi_GT_H2, epi_GT_V2, merged], \n",
    "      {tf_x:test_x['image'], tf_y:test_y['label'], tf_grid:test_grid['grid']}, options=run_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     save = cv2.cvtColor(test_grid['grid'][i], cv2.COLOR_BGR2RGB)\n",
    "#     cv2.imwrite('GT%i.png'%i, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "temp = grid_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('Output.png', temp)\n",
    "\n",
    "save = cv2.cvtColor(test_grid['grid'][i], cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('GT.png', save)\n",
    "\n",
    "temp = epi_H_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_H.png', temp)\n",
    "temp = epi_V_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_V.png', temp)\n",
    "\n",
    "temp = epi_GT_H_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_GT_H.png', temp)\n",
    "temp = epi_GT_V_[i]*255\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('EPI_GT_V.png', temp)\n",
    "\n",
    "GT= []\n",
    "Output = []\n",
    "Error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test_y['label'][i]*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    temp = temp1[:,:,(n*3):(n*3)+3]\n",
    "    save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"LF_Synthesized/GT/output%i.png\" %(n), save)\n",
    "    temp = np.uint8(temp)\n",
    "    GT.append(temp)\n",
    "\n",
    "temp2 = output_[i,:]*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    temp = temp2[:,:,(n*3):(n*3)+3]\n",
    "    save = cv2.cvtColor(temp2[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"LF_Synthesized/Output/output%i.png\" %(n), save)\n",
    "    temp = np.uint8(temp)\n",
    "    Output.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test_y['label'][i]*255\n",
    "temp2 = output_[i,:]*255\n",
    "for n in range(ANGULAR_RES_TARGET):\n",
    "    save1 = cv2.cvtColor(temp1[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    save2 = cv2.cvtColor(temp2[:,:,(n*3):(n*3)+3], cv2.COLOR_BGR2RGB)\n",
    "    save = np.absolute(save1-save2)*1.2\n",
    "    save = np.uint8(save)\n",
    "    save = cv2.applyColorMap(save, cv2.COLORMAP_JET)\n",
    "    cv2.imwrite(\"LF_Synthesized/Error/output%i.png\" %(n), save)\n",
    "    save = cv2.cvtColor(save, cv2.COLOR_RGB2BGR)\n",
    "    Error.append(save)\n",
    "    \n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        save1 = temp1[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save2 = temp2[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save = np.absolute(save1-save2)*1.2\n",
    "        save = np.uint8(save)\n",
    "        save = cv2.applyColorMap(save, cv2.COLORMAP_JET)\n",
    "        save = cv2.cvtColor(save, cv2.COLOR_RGB2BGR)\n",
    "        Error.append(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        temp = temp1[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(\"LF_Synthesized/Horizontal_GT/output%i.png\" %(c), save)\n",
    "        temp = np.uint8(temp)\n",
    "        GT.append(temp)\n",
    "        \n",
    "        temp = temp2[:,:,(x*8*3)+(y*3):(x*8*3)+(y*3)+3]\n",
    "        save = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(\"LF_Synthesized/Horizontal_Output/output%i.png\" %(c), save)\n",
    "        temp = np.uint8(temp)\n",
    "        Output.append(temp)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "imageio.mimsave('GT.gif', GT, duration=0.05)\n",
    "imageio.mimsave('Output.gif', Output, duration=0.05)\n",
    "imageio.mimsave('Error.gif', Error, duration=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "original = cv2.imread(\"GT.png\")\n",
    "contrast = cv2.imread(\"Output.png\")\n",
    "PSNR=psnr(original,contrast)\n",
    "print(PSNR)\n",
    "print(\"#########################################\")\n",
    "\n",
    "SSIM = ssim(original, contrast, multichannel=True,\n",
    "              data_range=contrast.max() - contrast.min())\n",
    "print(SSIM)\n",
    "print(\"#########################################\")\n",
    "\n",
    "f= open(\"eval.txt\",\"w+\")\n",
    " \n",
    "f.write(\"PSNR: %f\\r\" % PSNR)\n",
    "f.write(\"SSIM: %f\\r\\n\" % SSIM)\n",
    " \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = cv2.imread(\"test.png\")\n",
    "temp = lf[:, :, :]\n",
    "temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "imgplots = plt.imshow((temp).astype('uint8'))\n",
    "plt.show()\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numImgsX = 14;\n",
    "numImgsY = 14;\n",
    "\n",
    "h,w,c = temp.shape\n",
    "h_angular = h / numImgsY; \n",
    "w_angular = w / numImgsX;\n",
    "fullLF = np.zeros((int(h_angular), int(w_angular), 3, numImgsY, numImgsX));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in range(numImgsX):\n",
    "    for ay in range(numImgsY):\n",
    "        fullLF[:, :, :, ay, ax] = temp[ay::numImgsY, ax::numImgsX, :]\n",
    "        \n",
    "padded_LF = np.pad(fullLF, ((1,0),(0,0),(0,0),(0,0),(0,0)), 'constant', constant_values=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middleLF = fullLF[:, :, :, 3:11, 3:11]\n",
    "middleLF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_img = []\n",
    "i = 1\n",
    "for ax in range(8):\n",
    "    for ay in range(8):\n",
    "        if ay == 0:\n",
    "            y_img = middleLF[:,:,:,ay,ax]\n",
    "        else:\n",
    "            y_img = np.concatenate((y_img, middleLF[:,:,:,ay,ax]), 0)\n",
    "        list_img.append(middleLF[:,:,:,ay,ax])     \n",
    "    if ax == 0:\n",
    "        full_img = y_img\n",
    "    else:\n",
    "        full_img = np.concatenate((full_img, y_img), 1)\n",
    "    y_img = fullLF[:,:,:,ay,ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fullLF[:,:,:,7,7]\n",
    "imgplots = plt.imshow((temp).astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplots = plt.imshow((full_img).astype('uint8'))\n",
    "plt.show()\n",
    "cv2.imwrite(\"Grid.png\", full_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(100):\n",
    "    plt.figure(d)\n",
    "    temp = list_img[d]\n",
    "    imgplot = plt.imshow((temp).astype('uint8'))\n",
    "    #plt.savefig(\"Stack%i.png\" %d, dpi=100, bbox_inches='tight', frameon=False)\n",
    "    plt.show()\n",
    "    temp = np.uint8(temp)\n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"Stack%i.png\" %d, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list_img[0]\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "original = cv2.imread(\"GT.png\")\n",
    "contrast = cv2.imread(\"Output.png\")\n",
    "d=psnr(original,contrast)\n",
    "print(d)\n",
    "print(\"#########################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "\n",
    "original = cv2.imread(\"GT.png\")\n",
    "contrast = cv2.imread(\"Output.png\")\n",
    "ssim_noise = ssim(original, contrast, multichannel=True,\n",
    "              data_range=contrast.max() - contrast.min())\n",
    "print(ssim_noise)\n",
    "print(\"#########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_3d = np.ones((5,5,5))\n",
    "weight_3d = np.ones((3,3,3))\n",
    "strides_3d = [1, 1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_3d = tf.constant(weight_3d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "in_depth = int(in_3d.shape[2])\n",
    "\n",
    "filter_width = int(filter_3d.shape[0])\n",
    "filter_height = int(filter_3d.shape[1])\n",
    "filter_depth = int(filter_3d.shape[2])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_depth, in_height, in_depth, 1])\n",
    "kernel_3d = tf.reshape(filter_3d, [filter_depth, filter_height, filter_width, 1, 1])\n",
    "\n",
    "temp = tf.nn.conv3d(input_3d, kernel_3d, strides=strides_3d, padding='SAME')\n",
    "output_3d = tf.squeeze(temp)\n",
    "sess=tf.Session()\n",
    "sess.run(output_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LF INDEX\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 0 | 8  | 16 | 24 | 32 | 40 | 48 | 56 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 1 | 9  | 17 | 25 | 33 | 41 | 49 | 57 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 2 | 10 | 18 | 26 | 34 | 42 | 50 | 58 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 3 | 11 | 19 | 27 | 35 | 43 | 51 | 59 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 4 | 12 | 20 | 28 | 36 | 44 | 52 | 60 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 5 | 13 | 21 | 29 | 37 | 45 | 53 | 61 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 6 | 14 | 22 | 30 | 38 | 46 | 54 | 62 |\n",
    "# +---+----+----+----+----+----+----+----+\n",
    "# | 7 | 15 | 23 | 31 | 39 | 47 | 55 | 63 |\n",
    "# +---+----+----+----+----+----+----+----+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_VALUE = 1\n",
    "for i in range(64):\n",
    "    if i==0 or (i%8==0 and i>7):\n",
    "        ty = 3*SHIFT_VALUE\n",
    "    elif i == 1 or (i-1)%8==0:\n",
    "        ty = 2*SHIFT_VALUE\n",
    "    elif i == 2 or (i-2)%8==0:\n",
    "        ty = 1*SHIFT_VALUE\n",
    "    elif i == 3 or (i-3)%8==0:\n",
    "        ty = 0\n",
    "    elif i == 4 or (i-4)%8==0:\n",
    "        ty = -1*SHIFT_VALUE\n",
    "    elif i == 5 or (i-5)%8==0:\n",
    "        ty = -2*SHIFT_VALUE\n",
    "    elif i == 6 or (i-6)%8==0:\n",
    "        ty = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        ty = -4*SHIFT_VALUE\n",
    "    print('i: ',i, 'ty: ',ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_VALUE = 1\n",
    "for i in range(64):\n",
    "    if i<=7:\n",
    "        tx = 3*SHIFT_VALUE\n",
    "    elif i>7 and i<=15:\n",
    "        tx = 2*SHIFT_VALUE\n",
    "    elif i>15 and i<=23:\n",
    "        tx = 1*SHIFT_VALUE\n",
    "    elif i>23 and i<=31:\n",
    "        tx = 0\n",
    "    elif i>31 and i<=39:\n",
    "        tx = -1*SHIFT_VALUE\n",
    "    elif i>39 and i<=47:\n",
    "        tx = -2*SHIFT_VALUE\n",
    "    elif i>47 and i<=55:\n",
    "        tx = -3*SHIFT_VALUE\n",
    "    else:\n",
    "        tx = -4*SHIFT_VALUE\n",
    "    print('i: ',i, 'tx: ',tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "image_shift = tf_image_translate(c, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "result = sess.run(image_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(['test.png']) #  list of files to read\n",
    "\n",
    "reader = tf.WholeFileReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "my_img = tf.image.decode_png(value) # use png or jpg decoder based on your files.\n",
    "my_img = tf.to_float(my_img)\n",
    "my_img2 = tf.expand_dims(my_img, 0)\n",
    "print(my_img2.shape)\n",
    "sobel = tf.image.sobel_edges(my_img2)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Start populating the filename queue.\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(1): #length of your filename list\n",
    "        image = sobel.eval() #here is your image Tensor :) \n",
    "\n",
    "    print(image.shape)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = temp[:,:,:,0]\n",
    "temp2 = temp[:,:,:,1]\n",
    "edge = np.sqrt(temp1**2 + temp2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow((temp1).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow((temp2).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow((edge).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

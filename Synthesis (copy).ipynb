{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from random import shuffle\n",
    "import cv2\n",
    "from skimage import color\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "#Input parameter\n",
    "CH_INPUT = 3\n",
    "CH_OUTPUT = 3\n",
    "IMG_WIDTH = 384\n",
    "IMG_HEIGHT = 128\n",
    "DISP_RANGE = 33\n",
    "\n",
    "#Image path\n",
    "INPUT_PATH = 'kitti/left/*.png'\n",
    "GT_PATH = 'kitti/right/*.png' \n",
    "\n",
    "TEST_PATH = 'kitti/left_test/*.png'\n",
    "GT_TEST_PATH = 'kitti/right_test/*.png' \n",
    "\n",
    "#Training parameter\n",
    "BATCH_SIZE = 2\n",
    "BATCH_TEST = 20\n",
    "TRAIN_SIZE = 0.3\n",
    "LAMBDA_L1 = 100.0\n",
    "LR =  0.0002 # 0.001  0.0005 0.00146\n",
    "LR_D =  0.0002\n",
    "EPOCH = 100000\n",
    "DECAY_STEP = EPOCH/4\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift pixels\n",
    "def tf_image_translate(images, tx, ty, interpolation='NEAREST'):\n",
    "    # got these parameters from solving the equations for pixel translations\n",
    "    # on https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform\n",
    "    \n",
    "    #+tx -> shift to left +ty ->shift up\n",
    "    #transforms = [1, 0, tx, 0, 1, ty, 0, 0]\n",
    "    #translate = [BATCH_SIZE, -tx, ty]\n",
    "    translate = [-tx, ty, BATCH_SIZE]\n",
    "    return tf.contrib.image.translate(images, translate, interpolation)\n",
    "\n",
    "def preprocess(image):\n",
    "    with tf.name_scope(\"preprocess\"):\n",
    "        # [0, 1] => [-1, 1]\n",
    "        return image * 2 - 1\n",
    "    \n",
    "def deprocess(image):\n",
    "    with tf.name_scope(\"deprocess\"):\n",
    "        # [-1, 1] => [0, 1]\n",
    "        return (image + 1) / 2\n",
    "    \n",
    "def batchnorm(inputs):\n",
    "    return tf.layers.batch_normalization(inputs, \n",
    "                                         axis=3, \n",
    "                                         epsilon=1e-5, \n",
    "                                         momentum=0.1, \n",
    "                                         training=True, \n",
    "                                         gamma_initializer=tf.random_normal_initializer(1.0, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Input_Pipeline'):\n",
    "    #X\n",
    "    tf_x = tf.placeholder(tf.float32, [None, IMG_HEIGHT, IMG_WIDTH, CH_INPUT], name='Input')\n",
    "    view_image = tf.summary.image('input', tf.reshape(tf_x, [-1, IMG_HEIGHT, IMG_WIDTH, CH_INPUT]), 1)\n",
    "    image = tf.reshape(tf_x, [-1, IMG_HEIGHT, IMG_WIDTH, CH_INPUT], name='img_x')# (batch, height, width, channel)\n",
    "    #image = preprocess(image)\n",
    "\n",
    "    #Y\n",
    "    tf_y = tf.placeholder(tf.float32, [None, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT], name='Target')\n",
    "    label_image = tf.summary.image('GT', tf.reshape(tf_y, [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), 1)\n",
    "    color_norm = tf.reshape(tf_y, [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT], name='img_y')# (batch, height, width, channel)\n",
    "    #color_norm = preprocess(color_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper function\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def load_image(addr):\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.imread(addr)\n",
    "    if img is None:\n",
    "        return None\n",
    "    #img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "#Load the image using OpenCV in grayscale\n",
    "def load_image_gray(addr):\n",
    "    img = cv2.imread(addr, 0)\n",
    "    if img is None:\n",
    "        return None\n",
    "    #img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataRecord(out_filename, addrs, labels):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(out_filename)\n",
    "    for i in range(len(addrs)):\n",
    "        # print how many images are loaded every # images\n",
    "        if not i % 300:\n",
    "            print('Train data: {}/{} images'.format(i, len(addrs)))\n",
    "            sys.stdout.flush()\n",
    "        # Load the image\n",
    "        if CH_INPUT == 1:\n",
    "            img = load_image_gray(addrs[i])\n",
    "        else:\n",
    "            img = load_image(addrs[i]) \n",
    "        \n",
    "        if CH_OUTPUT == 1:\n",
    "            label = load_image_gray(labels[i])\n",
    "        else: \n",
    "            label = load_image(labels[i])\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        if label is None:\n",
    "            continue\n",
    "            \n",
    "        # Create a feature\n",
    "        feature = {\n",
    "            'image_raw': _bytes_feature(img.tostring()),\n",
    "            'label': _bytes_feature(label.tostring())\n",
    "        }\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0/3678 images\n",
      "Train data: 300/3678 images\n",
      "Train data: 600/3678 images\n",
      "Train data: 900/3678 images\n",
      "Train data: 1200/3678 images\n",
      "Train data: 1500/3678 images\n",
      "Train data: 1800/3678 images\n",
      "Train data: 2100/3678 images\n",
      "Train data: 2400/3678 images\n",
      "Train data: 2700/3678 images\n",
      "Train data: 3000/3678 images\n",
      "Train data: 3300/3678 images\n",
      "Train data: 3600/3678 images\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Data_Folder_Read'):\n",
    "    input_path = INPUT_PATH\n",
    "    label_path = GT_PATH\n",
    "    addrs = sorted(glob.glob(input_path))\n",
    "    labels = sorted(glob.glob(label_path))\n",
    "    \n",
    "with tf.name_scope('Shuffle_Data'):\n",
    "    # to shuffle data\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c,)\n",
    "    addrs, labels = zip(*c)\n",
    "    \n",
    "with tf.name_scope('Create_Datarecord_Train'):\n",
    "    # Divide the data into % train and % test\n",
    "    train_addrs = addrs[0:int(TRAIN_SIZE*len(addrs))]\n",
    "    train_labels = labels[0:int(TRAIN_SIZE*len(labels))]\n",
    "    createDataRecord('train.tfrecords', train_addrs, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK STRUCTURE [SYNTHESIS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16:\n",
    "    \"\"\"\n",
    "    A trainable version VGG16.\n",
    "    \"\"\"\n",
    "    def __init__(self, vgg16_npy_path=None, trainable=True, dropout=0.5, output_dim=15360, retrain=\"semi\"):\n",
    "        if vgg16_npy_path is not None:\n",
    "            self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        else:\n",
    "            self.data_dict = None\n",
    "\n",
    "        self.var_dict = {}\n",
    "        self.trainable = trainable\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.output_dim=output_dim\n",
    "        self.retrain=retrain\n",
    "\n",
    "    def build(self, rgb, train_mode=None):\n",
    "        \"\"\"\n",
    "        load variable from npy to build the VGG\n",
    "        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n",
    "        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n",
    "        \"\"\"\n",
    "\n",
    "        rgb_scaled = rgb * 255.0\n",
    "        \n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n",
    "        assert red.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        assert green.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        assert blue.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ])\n",
    "        \n",
    "        assert bgr.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 3]\n",
    "\n",
    "        #1st block\n",
    "        self.conv1_1 = self.conv_layer(bgr, 3, 64, \"conv1_1\")\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, 64, 64, \"conv1_2\")\n",
    "        self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "        \n",
    "        #2nd block\n",
    "        self.conv2_1 = self.conv_layer(self.pool1, 64, 128, \"conv2_1\")\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, 128, 128, \"conv2_2\")\n",
    "        self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "        \n",
    "        #3rd block\n",
    "        self.conv3_1 = self.conv_layer(self.pool2, 128, 256, \"conv3_1\")\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, 256, 256, \"conv3_2\")\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, 256, 256, \"conv3_3\")\n",
    "        self.pool3 = self.max_pool(self.conv3_3, 'pool3')\n",
    "        \n",
    "        #4th block\n",
    "        self.conv4_1 = self.conv_layer(self.pool3, 256, 512, \"conv4_1\")\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, 512, 512, \"conv4_2\")\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, 512, 512, \"conv4_3\")\n",
    "        self.pool4 = self.max_pool(self.conv4_3, 'pool4')\n",
    "        \n",
    "        #5th block\n",
    "        self.conv5_1 = self.conv_layer(self.pool4, 512, 512, \"conv5_1\")\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, 512, 512, \"conv5_2\")\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, 512, 512, \"conv5_3\")\n",
    "        self.pool5 = self.max_pool(self.conv5_3, 'pool5')\n",
    "        \n",
    "        #6th block (FC)\n",
    "        self.fc6 = tf.layers.flatten(self.pool5)\n",
    "        #self.fc6 = tf.layers.dense(self.fc6, 4096, bias_initializer=tf.random_normal_initializer(stddev=0.01), name=\"fc6-custom\")\n",
    "        self.fc6 = tf.layers.dense(self.fc6, 4096, name=\"fc6-custom\", bias_initializer=tf.constant_initializer(0.0))\n",
    "        self.relu6 = tf.nn.relu(self.fc6)\n",
    "        if train_mode is not None:\n",
    "            self.relu6 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu6, self.dropout), lambda: self.relu6)\n",
    "        elif self.trainable:\n",
    "            self.relu6 = tf.nn.dropout(self.relu6, self.dropout)\n",
    "        \n",
    "        #7th block (FC)\n",
    "        #self.fc7 = tf.layers.dense(self.relu6, 4096, bias_initializer=tf.random_normal_initializer(stddev=0.01), name=\"fc7-custom\")\n",
    "        self.fc7 = tf.layers.dense(self.relu6, 4096, name=\"fc7-custom\", bias_initializer=tf.constant_initializer(0.0))\n",
    "        self.relu7 = tf.nn.relu(self.fc7)\n",
    "        if train_mode is not None:\n",
    "            self.relu7 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu7, self.dropout), lambda: self.relu7)\n",
    "        elif self.trainable:\n",
    "            self.relu7 = tf.nn.dropout(self.relu7, self.dropout)\n",
    "        \n",
    "        #8th block (FC)\n",
    "        #self.fc8 = tf.layers.dense(self.relu7, 6144, bias_initializer=tf.random_normal_initializer(stddev=0.01), name=\"fc8-custom\")\n",
    "        self.fc8 = tf.layers.dense(self.relu7, 6144, name=\"fc8-custom\", bias_initializer=tf.constant_initializer(0.0))\n",
    "        self.fc8 = tf.reshape(self.fc8, [-1, 4, 12, 128]) \n",
    "        self.relu_bn5 = tf.nn.relu(self.fc8)\n",
    "        self.conv_bn5 = self.conv_only(self.relu_bn5, 128, 3, \"conv_bn5\")\n",
    "       \n",
    "        ######################################################################################\n",
    "        \n",
    "        #1st disp probability\n",
    "        #self.pool1 = batchnorm(self.pool1)\n",
    "        self.conv_bn1 = self.conv_bn(self.pool1, 3, \"conv_bn1\")\n",
    "        self.conv_bn1_ = self.conv_bn(self.conv_bn1, 3, \"conv_bn1_\")     \n",
    "        self.deconv_bn1 = self.deconv_layer(self.conv_bn1_, 1, 1, \"deconv_bn1\")\n",
    "        \n",
    "        #2nd disp probability\n",
    "        #self.pool2 = batchnorm(self.pool2)\n",
    "        self.conv_bn2 = self.conv_bn(self.pool2, 3, \"conv_bn2\")   \n",
    "        self.conv_bn2_ = self.conv_bn(self.conv_bn2, 3, \"conv_bn2_\") \n",
    "        self.deconv_bn2 = self.deconv_layer(self.conv_bn2_, 4, 2, \"deconv_bn2\")\n",
    "        \n",
    "        #3rd disp probability\n",
    "        #self.pool3 = batchnorm(self.pool3)\n",
    "        self.conv_bn3 = self.conv_bn(self.pool3, 3, \"conv_bn3\")     \n",
    "        self.conv_bn3_ = self.conv_bn(self.conv_bn3, 3, \"conv_bn3_\") \n",
    "        self.deconv_bn3 = self.deconv_layer(self.conv_bn3_, 8, 4, \"deconv_bn3\")\n",
    "        \n",
    "        #4th disp probability\n",
    "        #self.pool4 = batchnorm(self.pool4)\n",
    "        self.conv_bn4 = self.conv_bn(self.pool4, 3, \"conv_bn4\")     \n",
    "        self.conv_bn4_ = self.conv_bn(self.conv_bn4, 3, \"conv_bn4_\") \n",
    "        self.deconv_bn4 = self.deconv_layer(self.conv_bn4_, 16, 8, \"deconv_bn4\")\n",
    "        \n",
    "        #5th disp probability\n",
    "        self.deconv_bn5 = self.deconv_layer(self.conv_bn5, 32, 16, \"deconv_bn5\")\n",
    "        \n",
    "        ######################################################################################\n",
    "   \n",
    "        #SUM (save memory?)\n",
    "        self.summation = tf.add(self.deconv_bn1, self.deconv_bn2)\n",
    "        self.summation = tf.add(self.summation, self.deconv_bn3)\n",
    "        self.summation = tf.add(self.summation, self.deconv_bn4)\n",
    "        self.summation = tf.add(self.summation, self.deconv_bn5)\n",
    "        \n",
    "        self.relu_sum = tf.nn.relu(self.summation)\n",
    "        \n",
    "        #Deconv sum\n",
    "        self.deconv_sum = self.deconv_layer(self.relu_sum, 4, 2, \"deconv_sum\")\n",
    "        self.deconv_sum = tf.nn.relu(self.deconv_sum)\n",
    "        \n",
    "        self.conv_sum_ = tf.layers.conv2d(self.deconv_sum, 128, 3, padding='SAME', activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01), name=\"conv_sum_\")\n",
    "        \n",
    "        self.conv_sum = self.conv_only(self.conv_sum_, DISP_RANGE, 3, \"conv_sum\")\n",
    "\n",
    "        #Final softmax disp probability\n",
    "        self.prob = tf.nn.softmax(self.conv_sum)\n",
    "        \n",
    "        ######################################################################################\n",
    "        \n",
    "        #Slice and multiply\n",
    "        #Shifted input\n",
    "        self.image_stack = image\n",
    "        for i in range(DISP_RANGE-1):\n",
    "            trans_image = tf_image_translate(image, tx=i+1, ty=0)\n",
    "            self.image_stack = tf.concat([self.image_stack, trans_image], -1)\n",
    "        \n",
    "        #Multiply prob and shifted input\n",
    "        self.pred_right = tf.zeros_like(image)\n",
    "        for i in range(DISP_RANGE):\n",
    "            self.mult_prob = tf.multiply(self.prob[:, :, :, i:i+1], self.image_stack[:, :, :, i*3:(i*3)+3]) \n",
    "            self.pred_right = tf.add(self.pred_right, self.mult_prob)\n",
    " \n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, in_channels, out_channels, name):\n",
    "        with tf.variable_scope(name):\n",
    "            filt, conv_biases = self.get_conv_var(3, in_channels, out_channels, name)\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "            relu = tf.nn.relu(bias)\n",
    "\n",
    "            return relu  \n",
    "        \n",
    "    def conv_only(self, inputs, filters, kernel, name):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = tf.layers.conv2d(inputs, filters, kernel, padding='SAME',\n",
    "                                    kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "\n",
    "            return conv \n",
    "        \n",
    "    def conv_bn(self, inputs, kernel, name):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = tf.layers.conv2d(inputs, 128, kernel, padding='SAME', activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "            return conv\n",
    "        \n",
    "    def deconv_layer(self, inputs, kernel, stride, name):\n",
    "        with tf.variable_scope(name):\n",
    "            deconv = tf.layers.conv2d_transpose(inputs, 128,  kernel, (stride,stride), padding='SAME')\n",
    "            return deconv\n",
    "\n",
    "    def get_conv_var(self, filter_size, in_channels, out_channels, name):\n",
    "        initial_value = tf.truncated_normal([filter_size, filter_size, in_channels, out_channels], 0.0, 0.001)\n",
    "\n",
    "        if self.retrain == 'complete':\n",
    "            rt = True\n",
    "        elif self.retrain == 'semi':\n",
    "            if 'conv1' in name or 'conv2' in name:\n",
    "                rt = True\n",
    "            else:\n",
    "                rt = False\n",
    "        else:\n",
    "            rt = False\n",
    "\n",
    "        filters = self.get_var(initial_value, name, 0, name + \"_filters\", retrain=rt)\n",
    "        initial_value = tf.truncated_normal([out_channels], .0, .001)\n",
    "        biases = self.get_var(initial_value, name, 1, name + \"_biases\", retrain=rt)\n",
    "\n",
    "        return filters, biases\n",
    "\n",
    "    def get_var(self, initial_value, name, idx, var_name, retrain=True):\n",
    "        if self.data_dict is not None and name in self.data_dict:\n",
    "            value = self.data_dict[name][idx]\n",
    "        else:\n",
    "            value = initial_value\n",
    "\n",
    "        if self.trainable and retrain:\n",
    "            var = tf.Variable(value, name=var_name)\n",
    "        else:\n",
    "            var = tf.constant(value, dtype=tf.float32, name=var_name)\n",
    "\n",
    "        self.var_dict[(name, idx)] = var\n",
    "\n",
    "        # print var_name, var.get_shape().as_list()\n",
    "        assert var.get_shape() == initial_value.get_shape()\n",
    "\n",
    "        return var\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATCH GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "def patch_GAN(input_=None, filters_=64, name_=None, reuse_=None):\n",
    "    with tf.variable_scope('Patch_GAN'):\n",
    "        if reuse_:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        input_ += tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "        with tf.name_scope('D_1st_Block'):\n",
    "            conv1 = tf.layers.conv2d(inputs=input_, \n",
    "                                     filters=filters_, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None,\n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_1st_Block')\n",
    "\n",
    "            conv1 = batchnorm(conv1)\n",
    "            conv1 = tf.nn.leaky_relu(conv1)\n",
    "        \n",
    "        with tf.name_scope('D_2nd_Block'):\n",
    "            conv2 = tf.layers.conv2d(inputs=conv1, \n",
    "                                     filters=filters_*2, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_2nd_Block')\n",
    "\n",
    "            conv2 = batchnorm(conv2)\n",
    "            conv2 = tf.nn.leaky_relu(conv2)\n",
    "        \n",
    "        with tf.name_scope('D_3rd_Block'):\n",
    "            conv3 = tf.layers.conv2d(inputs=conv2, \n",
    "                                     filters=filters_*4, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_3rd_Block_conv_3')\n",
    "\n",
    "            conv3 = batchnorm(conv3)\n",
    "            conv3 = tf.nn.leaky_relu(conv3)\n",
    "        \n",
    "        with tf.name_scope('D_4th_Block'):\n",
    "            conv4 = tf.layers.conv2d(inputs=conv3, \n",
    "                                     filters=filters_*8, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_4th_Block_conv_4')\n",
    "\n",
    "            conv4 = batchnorm(conv4)\n",
    "            conv4 = tf.nn.leaky_relu(conv4)\n",
    "        \n",
    "        with tf.name_scope('D_5th_Block'):\n",
    "            conv5 = tf.layers.conv2d(inputs=conv4, \n",
    "                                     filters=1, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=1, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_5th_Block_conv_5')    \n",
    "            \n",
    "        return tf.nn.sigmoid(conv5), conv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANILA GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanila_GAN(input_=None, filters_=64, name_=None, reuse_=None):\n",
    "    with tf.variable_scope('Vanila_GAN'):\n",
    "        if reuse_:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        input_ += tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "        with tf.name_scope('D_1st_Block'):\n",
    "            conv1 = tf.layers.conv2d(inputs=input_, \n",
    "                                     filters=filters_, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None,\n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_1st_Block')\n",
    "\n",
    "            conv1 = batchnorm(conv1)\n",
    "            conv1 = tf.nn.leaky_relu(conv1)\n",
    "        \n",
    "        with tf.name_scope('D_2nd_Block'):\n",
    "            conv2 = tf.layers.conv2d(inputs=conv1, \n",
    "                                     filters=filters_*2, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_2nd_Block')\n",
    "\n",
    "            conv2 = batchnorm(conv2)\n",
    "            conv2 = tf.nn.leaky_relu(conv2)\n",
    "        \n",
    "        with tf.name_scope('D_3rd_Block'):\n",
    "            conv3 = tf.layers.conv2d(inputs=conv2, \n",
    "                                     filters=filters_*4, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_3rd_Block_conv_3')\n",
    "\n",
    "            conv3 = batchnorm(conv3)\n",
    "            conv3 = tf.nn.leaky_relu(conv3)\n",
    "        \n",
    "        with tf.name_scope('D_4th_Block'):\n",
    "            conv4 = tf.layers.conv2d(inputs=conv3, \n",
    "                                     filters=filters_*8, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_4th_Block_conv_4')\n",
    "\n",
    "            conv4 = batchnorm(conv4)\n",
    "            conv4 = tf.nn.leaky_relu(conv4)\n",
    "        \n",
    "        with tf.name_scope('D_5th_Block'):\n",
    "            conv5 = tf.layers.conv2d(inputs=conv4, \n",
    "                                     filters=filters_*8, \n",
    "                                     kernel_size=4, \n",
    "                                     strides=2, \n",
    "                                     padding='SAME', \n",
    "                                     activation=None, \n",
    "                                     kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                     bias_initializer=tf.constant_initializer(0.0),\n",
    "                                     name='D_5th_Block_conv_5')   \n",
    "            conv5 = batchnorm(conv5)\n",
    "            conv5 = tf.nn.leaky_relu(conv5)\n",
    "            \n",
    "        with tf.name_scope('D_6th_Block'):\n",
    "            flat1 = tf.layers.flatten(conv5)\n",
    "            dense1 = tf.layers.dense(flat1, 1024)\n",
    "            dense1 = tf.nn.leaky_relu(dense1)\n",
    "            dense1 = tf.layers.batch_normalization(dense1,\n",
    "                                         epsilon=1e-5, \n",
    "                                         momentum=0.1, \n",
    "                                         training=True, \n",
    "                                         gamma_initializer=tf.random_normal_initializer(1.0, 0.01))\n",
    "            out = tf.layers.dense(dense1, 1)\n",
    "            \n",
    "        return tf.nn.sigmoid(out), out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('View_Synthesis'):\n",
    "    with tf.name_scope('Generator'):\n",
    "        vgg = Vgg16(vgg16_npy_path= 'vgg16.npy', output_dim = 15360, retrain=\"complete\")\n",
    "        train_mode = tf.placeholder(tf.bool)\n",
    "        input_vgg = tf.divide(image, 255)\n",
    "        vgg.build(input_vgg, train_mode)\n",
    "        \n",
    "    with tf.name_scope('Discriminator_Patch'):\n",
    "        #Concat A and real B\n",
    "        #real_input = tf.concat([vgg.prob, color_norm], 3)\n",
    "        #Concat A and fake B\n",
    "        #fake_input = tf.concat([vgg.prob, vgg.pred_right], 3)\n",
    "        \n",
    "        with tf.name_scope('Discriminator_Real'):\n",
    "            sigmoid_real, real_logits = patch_GAN(color_norm, 64, 'D_real', False)\n",
    "        with tf.name_scope('Discriminator_Fake'):\n",
    "            sigmoid_fake, fake_logits = patch_GAN(vgg.pred_right, 64, 'D_fake', True)\n",
    "            \n",
    "#     with tf.name_scope('Discriminator_Vanila'):      \n",
    "#         with tf.name_scope('Discriminator_Real'):\n",
    "#             sigmoid_real, real_logits = vanila_GAN(color_norm, 64, 'D_real', False)\n",
    "#         with tf.name_scope('Discriminator_Fake'):\n",
    "#             sigmoid_fake, fake_logits = vanila_GAN(vgg.pred_right, 64, 'D_fake', True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy_with_logits(x, y):\n",
    "    try:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=y)\n",
    "    except:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, targets=y)\n",
    "\n",
    "with tf.name_scope('Loss'): \n",
    "    output_image = tf.summary.image('Target', tf.cast(tf.reshape(vgg.pred_right, \n",
    "                            [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), tf.uint8) , 1)\n",
    "    \n",
    "    #Label smoothing\n",
    "    zero_smooth = tf.random_uniform(tf.shape(sigmoid_fake), minval=0.0, maxval=0.2)\n",
    "    one_smooth = tf.random_uniform(tf.shape(sigmoid_fake), minval=0.0, maxval=-0.2)\n",
    "    \n",
    "    l1_loss = tf.reduce_mean(tf.losses.absolute_difference(color_norm, vgg.pred_right))\n",
    "    tf.summary.scalar('L1_loss', l1_loss)\n",
    "    \n",
    "    G_Adv_loss = tf.reduce_mean(\n",
    "            sigmoid_cross_entropy_with_logits(fake_logits, tf.ones_like(sigmoid_fake)+one_smooth), name='G_adv_loss')\n",
    "        \n",
    "    G_Adv_loss = tf.reduce_mean(sigmoid_real)\n",
    "    \n",
    "    G_Total_Loss = tf.add(G_Adv_loss, (LAMBDA_L1 * l1_loss), name='G_total_loss')\n",
    "    \n",
    "    tf.summary.scalar('Generator_Adv_Loss', G_Adv_loss)\n",
    "    tf.summary.scalar('Generator_Total_Loss', G_Total_Loss)\n",
    "    \n",
    "    ###################################################################################################\n",
    "    D_Adv_Real = tf.reduce_mean(\n",
    "        sigmoid_cross_entropy_with_logits(real_logits, tf.ones_like(sigmoid_real)+one_smooth), name='D_real_adv_loss')\n",
    "\n",
    "    D_Adv_Fake = tf.reduce_mean(\n",
    "        sigmoid_cross_entropy_with_logits(fake_logits, tf.zeros_like(sigmoid_fake)+zero_smooth), name='D_fake_adv_loss')\n",
    "    D_Total_Loss = tf.add(D_Adv_Real, D_Adv_Fake, name='D_total_loss')\n",
    "        \n",
    "    tf.summary.scalar('Discriminator_Real', D_Adv_Real)\n",
    "    tf.summary.scalar('Discriminator_Fake', D_Adv_Fake)\n",
    "    tf.summary.scalar('Discriminator_Total_Loss', D_Total_Loss)\n",
    "    \n",
    "#     shift_image = tf.summary.image('Shift', tf.cast(tf.reshape(image_stack[:, :, :, (DISP_RANGE*3)-3:DISP_RANGE*3],\n",
    "#                                     [-1, IMG_WIDTH, IMG_HEIGHT, CH_OUTPUT]), tf.uint8) , 1)\n",
    "  \n",
    "    disp_image = tf.summary.image('Z', tf.cast(tf.reshape(vgg.prob[:, :, :, 3:4]*255, \n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, 1]), tf.uint8) , 1)\n",
    "    \n",
    "    disp_image2 = tf.summary.image('Z2', tf.cast(tf.reshape(vgg.prob[:, :, :, 14:15]*255, \n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, 1]), tf.uint8) , 1)\n",
    "    \n",
    "    disp_image3 = tf.summary.image('Z3', tf.cast(tf.reshape(vgg.prob[:, :, :, 27:28]*255, \n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, 1]), tf.uint8) , 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Train'):\n",
    "    batch = tf.Variable(0, dtype=tf.float32)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                      LR,                    # Base learning rate.\n",
    "                      batch,      # Current index into the dataset.\n",
    "                      DECAY_STEP,       # Decay step.\n",
    "                      0.97,       # Decay rate.\n",
    "                      staircase=True)\n",
    "    learning_rate_D = tf.train.exponential_decay(\n",
    "                      LR_D,                    # Base learning rate.\n",
    "                      batch,      # Current index into the dataset.\n",
    "                      DECAY_STEP,       # Decay step.\n",
    "                      0.97,       # Decay rate.\n",
    "                      staircase=True)\n",
    "    #train_op = tf.train.AdamOptimizer(learning_rate=learning_rate, name='optimizer_adam').minimize(l1_loss)\n",
    "    train_G = tf.train.AdamOptimizer(learning_rate=learning_rate, name='optimizer_G').minimize(G_Total_Loss)\n",
    "    train_D = tf.train.AdamOptimizer(learning_rate=learning_rate_D, name='optimizer_D').minimize(D_Total_Loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get one record and parse it to get the label and image out\n",
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\":     tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    #Read one record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    #Take the image and bytes\n",
    "    image = tf.decode_raw(parsed[\"image_raw\"], tf.uint8)\n",
    "    label = tf.decode_raw(parsed[\"label\"], tf.uint8)\n",
    "    #Cast to float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    image = tf.reshape(image, shape=[IMG_HEIGHT, IMG_WIDTH, CH_INPUT])\n",
    "    label = tf.reshape(label, shape=[IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT])\n",
    "    #Normalize the input and label into [0...1]\n",
    "    #image = tf.divide(image, 255)\n",
    "    #label = tf.divide(label, 255)\n",
    "\n",
    "    return {'image': image}, {'label': label}\n",
    "\n",
    "def input_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=1000)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=1000)\n",
    "    dataset = dataset.shuffle(500).repeat().batch(BATCH_SIZE)\n",
    "    #dataset = dataset.prefetch(buffer_size=2)\n",
    "    return dataset\n",
    "\n",
    "def test_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=100)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=100)\n",
    "    dataset = dataset.batch(BATCH_TEST)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(filenames=[\"train.tfrecords\"])\n",
    "\n",
    "def test_input_fn():\n",
    "    return test_fn(filenames=[\"test.tfrecords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Data_Folder_Read'):\n",
    "    input_path = INPUT_PATH\n",
    "    label_path = GT_PATH\n",
    "    addrs = sorted(glob.glob(input_path))\n",
    "    labels = sorted(glob.glob(label_path))\n",
    "    \n",
    "with tf.name_scope('Create_Training_Set'):\n",
    "    train_dataset = train_input_fn()\n",
    "    iterator = train_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | G loss:0.5791 | D loss:2.5322\n",
      "Step: 30 | G loss:0.2240 | D loss:2.3825\n",
      "Step: 60 | G loss:0.2564 | D loss:2.1606\n",
      "Step: 90 | G loss:0.2412 | D loss:2.1278\n",
      "Step: 120 | G loss:0.2753 | D loss:1.9879\n",
      "Step: 150 | G loss:0.2373 | D loss:2.0484\n",
      "Step: 180 | G loss:0.1955 | D loss:2.2356\n",
      "Step: 210 | G loss:0.2306 | D loss:2.0410\n",
      "Step: 240 | G loss:0.2512 | D loss:1.9617\n",
      "Step: 270 | G loss:0.2170 | D loss:2.0616\n",
      "Step: 300 | G loss:0.2389 | D loss:1.9927\n",
      "Step: 330 | G loss:0.2350 | D loss:2.0040\n",
      "Step: 360 | G loss:0.2160 | D loss:2.0999\n",
      "Step: 390 | G loss:0.2193 | D loss:2.0322\n",
      "Step: 420 | G loss:0.2330 | D loss:1.9802\n",
      "Step: 450 | G loss:0.2321 | D loss:1.9766\n",
      "Step: 480 | G loss:0.2152 | D loss:2.0056\n",
      "Step: 510 | G loss:0.2142 | D loss:2.0272\n",
      "Step: 540 | G loss:0.2151 | D loss:2.0114\n",
      "Step: 570 | G loss:0.2396 | D loss:1.9640\n",
      "Step: 600 | G loss:0.1985 | D loss:2.0586\n",
      "Step: 630 | G loss:0.2135 | D loss:2.0085\n",
      "Step: 660 | G loss:0.2149 | D loss:2.1239\n",
      "Step: 690 | G loss:0.2144 | D loss:2.0078\n",
      "Step: 720 | G loss:0.2362 | D loss:2.0071\n",
      "Step: 750 | G loss:0.2015 | D loss:2.0463\n",
      "Step: 780 | G loss:0.2131 | D loss:2.0264\n",
      "Step: 810 | G loss:0.2423 | D loss:1.8487\n",
      "Step: 840 | G loss:0.2044 | D loss:2.0319\n",
      "Step: 870 | G loss:0.2258 | D loss:1.9128\n",
      "Step: 900 | G loss:0.1981 | D loss:2.0634\n",
      "Step: 930 | G loss:0.2222 | D loss:1.9810\n",
      "Step: 960 | G loss:0.2115 | D loss:1.9914\n",
      "Step: 990 | G loss:0.2027 | D loss:2.0400\n",
      "Model saved in path: saver/Synthesis/model1000.ckpt\n",
      "Step: 1020 | G loss:0.2402 | D loss:1.9255\n",
      "Step: 1050 | G loss:0.2113 | D loss:2.0355\n",
      "Step: 1080 | G loss:0.2126 | D loss:1.9768\n",
      "Step: 1110 | G loss:0.2191 | D loss:1.9487\n",
      "Step: 1140 | G loss:0.1979 | D loss:2.0360\n",
      "Step: 1170 | G loss:0.2024 | D loss:2.0394\n",
      "Step: 1200 | G loss:0.1918 | D loss:2.1218\n",
      "Step: 1230 | G loss:0.2189 | D loss:1.9774\n",
      "Step: 1260 | G loss:0.2207 | D loss:1.9419\n",
      "Step: 1290 | G loss:0.2020 | D loss:2.0218\n",
      "Step: 1320 | G loss:0.2155 | D loss:1.9861\n",
      "Step: 1350 | G loss:0.2498 | D loss:1.7991\n",
      "Step: 1380 | G loss:0.2014 | D loss:2.0274\n",
      "Step: 1410 | G loss:0.2333 | D loss:1.8433\n",
      "Step: 1440 | G loss:0.2415 | D loss:1.8355\n",
      "Step: 1470 | G loss:0.2257 | D loss:1.9297\n",
      "Step: 1500 | G loss:0.2520 | D loss:1.7974\n",
      "Step: 1530 | G loss:0.2089 | D loss:1.9593\n",
      "Step: 1560 | G loss:0.2093 | D loss:1.9895\n",
      "Step: 1590 | G loss:0.2162 | D loss:1.9684\n",
      "Step: 1620 | G loss:0.2032 | D loss:2.0413\n",
      "Step: 1650 | G loss:0.2222 | D loss:1.9004\n",
      "Step: 1680 | G loss:0.2195 | D loss:1.9432\n",
      "Step: 1710 | G loss:0.2120 | D loss:1.9405\n",
      "Step: 1740 | G loss:0.2249 | D loss:1.8866\n",
      "Step: 1770 | G loss:0.2262 | D loss:1.8739\n",
      "Step: 1800 | G loss:0.2418 | D loss:1.8170\n",
      "Step: 1830 | G loss:0.2481 | D loss:1.7939\n",
      "Step: 1860 | G loss:0.2322 | D loss:1.8548\n",
      "Step: 1890 | G loss:0.2706 | D loss:1.8587\n",
      "Step: 1920 | G loss:0.2469 | D loss:1.8064\n",
      "Step: 1950 | G loss:0.2121 | D loss:1.9870\n",
      "Step: 1980 | G loss:0.2334 | D loss:1.8449\n",
      "Step: 2010 | G loss:0.2443 | D loss:1.7894\n",
      "Step: 2040 | G loss:0.1970 | D loss:2.0553\n",
      "Step: 2070 | G loss:0.2296 | D loss:1.9129\n",
      "Step: 2100 | G loss:0.2446 | D loss:1.7781\n",
      "Step: 2130 | G loss:0.1872 | D loss:2.1158\n",
      "Step: 2160 | G loss:0.2355 | D loss:1.9200\n",
      "Step: 2190 | G loss:0.2201 | D loss:1.9655\n",
      "Step: 2220 | G loss:0.2389 | D loss:1.8071\n",
      "Step: 2250 | G loss:0.2182 | D loss:1.9167\n",
      "Step: 2280 | G loss:0.2257 | D loss:1.8701\n",
      "Step: 2310 | G loss:0.2329 | D loss:1.8543\n",
      "Step: 2340 | G loss:0.2382 | D loss:1.7901\n",
      "Step: 2370 | G loss:0.2359 | D loss:1.9254\n",
      "Step: 2400 | G loss:0.2134 | D loss:1.9414\n",
      "Step: 2430 | G loss:0.2467 | D loss:1.7927\n",
      "Step: 2460 | G loss:0.2406 | D loss:1.7854\n",
      "Step: 2490 | G loss:0.2266 | D loss:1.8639\n",
      "Step: 2520 | G loss:0.2399 | D loss:1.8395\n",
      "Step: 2550 | G loss:0.2208 | D loss:1.9457\n",
      "Step: 2580 | G loss:0.2336 | D loss:1.8597\n",
      "Step: 2610 | G loss:0.2222 | D loss:1.8615\n",
      "Step: 2640 | G loss:0.2209 | D loss:1.8873\n",
      "Step: 2670 | G loss:0.2157 | D loss:1.9090\n",
      "Step: 2700 | G loss:0.2064 | D loss:1.9660\n",
      "Step: 2730 | G loss:0.2282 | D loss:1.8656\n",
      "Step: 2760 | G loss:0.2452 | D loss:1.7749\n",
      "Step: 2790 | G loss:0.2368 | D loss:1.7901\n",
      "Step: 2820 | G loss:0.2330 | D loss:1.8077\n",
      "Step: 2850 | G loss:0.2217 | D loss:1.8926\n",
      "Step: 2880 | G loss:0.2184 | D loss:1.9022\n",
      "Step: 2910 | G loss:0.2387 | D loss:1.7853\n",
      "Step: 2940 | G loss:0.2432 | D loss:1.7712\n",
      "Step: 2970 | G loss:0.2296 | D loss:1.8934\n",
      "Step: 3000 | G loss:0.2385 | D loss:1.9024\n",
      "Step: 3030 | G loss:0.2180 | D loss:1.8955\n",
      "Step: 3060 | G loss:0.2442 | D loss:1.7651\n",
      "Step: 3090 | G loss:0.2172 | D loss:1.9209\n",
      "Step: 3120 | G loss:0.2239 | D loss:1.8981\n",
      "Step: 3150 | G loss:0.2370 | D loss:1.7952\n",
      "Step: 3180 | G loss:0.2344 | D loss:1.7889\n",
      "Step: 3210 | G loss:0.2414 | D loss:1.7759\n",
      "Step: 3240 | G loss:0.2428 | D loss:1.7669\n",
      "Step: 3270 | G loss:0.2392 | D loss:1.8003\n",
      "Step: 3300 | G loss:0.2326 | D loss:1.8450\n",
      "Step: 3330 | G loss:0.2472 | D loss:1.8080\n",
      "Step: 3360 | G loss:0.2177 | D loss:1.9145\n",
      "Step: 3390 | G loss:0.2159 | D loss:1.9195\n",
      "Step: 3420 | G loss:0.2360 | D loss:1.8702\n",
      "Step: 3450 | G loss:0.2186 | D loss:1.8740\n",
      "Step: 3480 | G loss:0.2541 | D loss:1.7159\n",
      "Step: 3510 | G loss:0.2475 | D loss:1.7470\n",
      "Step: 3540 | G loss:0.2457 | D loss:1.7421\n",
      "Step: 3570 | G loss:0.2246 | D loss:1.8483\n",
      "Step: 3600 | G loss:0.2357 | D loss:1.8927\n",
      "Step: 3630 | G loss:0.2337 | D loss:1.7921\n",
      "Step: 3660 | G loss:0.2528 | D loss:1.7133\n",
      "Step: 3690 | G loss:0.2406 | D loss:1.7780\n",
      "Step: 3720 | G loss:0.2114 | D loss:1.9537\n",
      "Step: 3750 | G loss:0.2196 | D loss:1.8832\n",
      "Step: 3780 | G loss:0.2343 | D loss:1.8536\n",
      "Step: 3810 | G loss:0.2261 | D loss:1.8988\n",
      "Step: 3840 | G loss:0.2174 | D loss:1.8922\n",
      "Step: 3870 | G loss:0.2304 | D loss:1.8149\n",
      "Step: 3900 | G loss:0.2433 | D loss:1.7436\n",
      "Step: 3930 | G loss:0.2220 | D loss:1.9161\n",
      "Step: 3960 | G loss:0.2179 | D loss:1.8793\n",
      "Step: 3990 | G loss:0.2104 | D loss:1.9485\n",
      "Step: 4020 | G loss:0.2394 | D loss:1.7567\n",
      "Step: 4050 | G loss:0.2429 | D loss:1.9496\n",
      "Step: 4080 | G loss:0.2300 | D loss:1.8853\n",
      "Step: 4110 | G loss:0.2545 | D loss:1.7296\n",
      "Step: 4140 | G loss:0.2133 | D loss:1.9009\n",
      "Step: 4170 | G loss:0.2189 | D loss:1.9017\n",
      "Step: 4200 | G loss:0.2161 | D loss:1.9220\n",
      "Step: 4230 | G loss:0.2356 | D loss:1.8337\n",
      "Step: 4260 | G loss:0.2401 | D loss:1.8470\n",
      "Step: 4290 | G loss:0.2261 | D loss:1.8277\n",
      "Step: 4320 | G loss:0.2318 | D loss:1.8713\n",
      "Step: 4350 | G loss:0.2200 | D loss:1.8672\n",
      "Step: 4380 | G loss:0.2271 | D loss:1.8613\n",
      "Step: 4410 | G loss:0.2496 | D loss:1.7263\n",
      "Step: 4440 | G loss:0.1976 | D loss:2.0348\n",
      "Step: 4470 | G loss:0.2440 | D loss:1.7534\n",
      "Step: 4500 | G loss:0.2292 | D loss:1.8146\n",
      "Step: 4530 | G loss:0.2213 | D loss:1.8470\n",
      "Step: 4560 | G loss:0.2483 | D loss:1.7157\n",
      "Step: 4590 | G loss:0.2167 | D loss:1.9019\n",
      "Step: 4620 | G loss:0.2474 | D loss:1.7248\n",
      "Step: 4650 | G loss:0.2161 | D loss:1.8893\n",
      "Step: 4680 | G loss:0.2342 | D loss:1.8981\n",
      "Step: 4710 | G loss:0.2528 | D loss:1.7460\n",
      "Step: 4740 | G loss:0.2326 | D loss:1.7903\n",
      "Step: 4770 | G loss:0.2168 | D loss:1.9220\n",
      "Step: 4800 | G loss:0.2137 | D loss:1.9164\n",
      "Step: 4830 | G loss:0.2348 | D loss:1.8241\n",
      "Step: 4860 | G loss:0.2604 | D loss:1.7558\n",
      "Step: 4890 | G loss:0.2529 | D loss:1.7201\n",
      "Step: 4920 | G loss:0.2170 | D loss:1.9186\n",
      "Step: 4950 | G loss:0.2359 | D loss:1.8535\n",
      "Step: 4980 | G loss:0.2400 | D loss:1.7665\n",
      "Step: 5010 | G loss:0.2097 | D loss:1.9361\n",
      "Step: 5040 | G loss:0.2251 | D loss:1.8521\n",
      "Step: 5070 | G loss:0.2381 | D loss:1.9353\n",
      "Step: 5100 | G loss:0.2180 | D loss:1.9134\n",
      "Step: 5130 | G loss:0.2560 | D loss:1.7042\n",
      "Step: 5160 | G loss:0.2002 | D loss:1.9772\n",
      "Step: 5190 | G loss:0.2392 | D loss:1.8095\n",
      "Step: 5220 | G loss:0.2363 | D loss:1.7757\n",
      "Step: 5250 | G loss:0.2231 | D loss:1.8738\n",
      "Step: 5280 | G loss:0.2175 | D loss:1.8783\n",
      "Step: 5310 | G loss:0.2181 | D loss:1.8827\n",
      "Step: 5340 | G loss:0.2118 | D loss:1.9242\n",
      "Step: 5370 | G loss:0.2183 | D loss:1.8562\n",
      "Step: 5400 | G loss:0.2275 | D loss:1.8293\n",
      "Step: 5430 | G loss:0.2478 | D loss:1.7754\n",
      "Step: 5460 | G loss:0.2244 | D loss:1.8926\n",
      "Step: 5490 | G loss:0.2404 | D loss:1.7709\n",
      "Step: 5520 | G loss:0.2518 | D loss:1.7794\n",
      "Step: 5550 | G loss:0.2178 | D loss:1.9114\n",
      "Step: 5580 | G loss:0.2195 | D loss:1.8972\n",
      "Step: 5610 | G loss:0.2199 | D loss:1.8668\n",
      "Step: 5640 | G loss:0.2277 | D loss:1.8317\n",
      "Step: 5670 | G loss:0.2456 | D loss:1.7774\n",
      "Step: 5700 | G loss:0.2428 | D loss:1.7412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5730 | G loss:0.2292 | D loss:1.8124\n",
      "Step: 5760 | G loss:0.2334 | D loss:1.7855\n",
      "Step: 5790 | G loss:0.2253 | D loss:1.8241\n",
      "Step: 5820 | G loss:0.2196 | D loss:1.8496\n",
      "Step: 5850 | G loss:0.2449 | D loss:1.8149\n",
      "Step: 5880 | G loss:0.2375 | D loss:1.7801\n",
      "Step: 5910 | G loss:0.2437 | D loss:1.7584\n",
      "Step: 5940 | G loss:0.2242 | D loss:1.8242\n",
      "Step: 5970 | G loss:0.2358 | D loss:1.7757\n",
      "Step: 6000 | G loss:0.2385 | D loss:1.7578\n",
      "Step: 6030 | G loss:0.2472 | D loss:1.7103\n",
      "Step: 6060 | G loss:0.2442 | D loss:1.7439\n",
      "Step: 6090 | G loss:0.2195 | D loss:1.8592\n",
      "Step: 6120 | G loss:0.2431 | D loss:1.7234\n",
      "Step: 6150 | G loss:0.2454 | D loss:1.8042\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(tf.group(tf.global_variables_initializer(), \n",
    "                  iterator.initializer)\n",
    "                 )\n",
    "#saver.restore(sess, \"saver/Synthesis/model15000.ckpt\")\n",
    "writer = tf.summary.FileWriter('log/Synthesis',sess.graph)\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True, trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()\n",
    "for step in range(EPOCH+1):\n",
    "    train_x, train_y = sess.run(next_batch)\n",
    "    \n",
    "    #_, l1_loss_, output_, summary_ = sess.run([train_op, l1_loss, vgg.pred_right, merged], {tf_x:train_x['image'], tf_y:train_y['label'], train_mode:True}, options=run_options, run_metadata=run_metadata)\n",
    "    if step%1 == 0:\n",
    "        _, G_loss_, output_, summary_ = sess.run([train_G, G_Adv_loss, vgg.pred_right, merged], {tf_x:train_x['image'], tf_y:train_y['label'], train_mode:True}, options=run_options, run_metadata=run_metadata)\n",
    "    if step%1 == 0:\n",
    "        _, D_loss_ = sess.run([train_D, D_Total_Loss], {tf_x:train_x['image'], tf_y:train_y['label'], train_mode:True}, options=run_options, run_metadata=run_metadata)\n",
    "   \n",
    "    if step %2000 == 0:\n",
    "        save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "     \n",
    "    if step == 15000:\n",
    "        save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "        \n",
    "    if step%30 == 0:\n",
    "        #writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "        writer.add_summary(summary_, step)     \n",
    "        #print('Step:', step, '| L_1 loss:%.4f' %l1_loss_)\n",
    "        print('Step:', step, '| G loss:%.4f' %G_loss_, '| D loss:%.4f' %D_loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Test_Folder_Read'):\n",
    "    input_path = TEST_PATH\n",
    "    label_path = GT_TEST_PATH\n",
    "    addrs = sorted(glob.glob(input_path))\n",
    "    labels = sorted(glob.glob(label_path))\n",
    "    \n",
    "with tf.name_scope('Create_Datarecord_Test'):\n",
    "    # Divide the data into % train and % test\n",
    "    test_addrs = addrs[:BATCH_TEST]\n",
    "    test_labels = labels[:BATCH_TEST]\n",
    "    createDataRecord('test.tfrecords', test_addrs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Create_Test_Set'):\n",
    "    test_dataset = test_input_fn()\n",
    "    iterator = test_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "sess.run(iterator.initializer)\n",
    "saver = tf.train.Saver()\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "%timeit\n",
    "saver.restore(sess, \"saver/Synthesis/model30000.ckpt\")\n",
    "test_x, test_y = sess.run(next_batch)\n",
    "l1_loss_, output_, depth_ = sess.run([l1_loss, vgg.pred_right, vgg.prob], {tf_x:test_x['image'], tf_y:test_y['label'], train_mode:False}, options=run_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(BATCH_TEST):\n",
    "    plt.figure(i)\n",
    "    temp = output_[i,:,:,:]\n",
    "    #color = np.reshape(output_[0], [256,256,3])\n",
    "    imgplots = plt.imshow((temp).astype('uint8'))\n",
    "    plt.show()\n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"outputGD%i.png\" %i, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(DISP_RANGE):\n",
    "    plt.figure(d)\n",
    "    temp = depth_[6,:,:,d:d+1]*255\n",
    "    temp  = np.squeeze(temp, 2)\n",
    "    imgplot = plt.imshow((temp).astype('uint8'), cmap='gray')\n",
    "    plt.show()\n",
    "    cv2.imwrite(\"output%i.png\" %d, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "original = cv2.imread(\"GT7.png\")\n",
    "contrast = cv2.imread(\"output7.png\")\n",
    "\n",
    "d=psnr(original,contrast)\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

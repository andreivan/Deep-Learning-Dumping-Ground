{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from random import shuffle\n",
    "import cv2\n",
    "from skimage import color\n",
    "from scipy import ndimage as ndi\n",
    "from bilinear_sampler import bilinear_sampler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "#Input parameter\n",
    "CH_INPUT = 3\n",
    "CH_OUTPUT = 3\n",
    "IMG_WIDTH = 384\n",
    "IMG_HEIGHT = 128\n",
    "DISP_RANGE = 33\n",
    "\n",
    "#Image path\n",
    "INPUT_PATH = 'kitti/left/*.png'\n",
    "GT_PATH = 'kitti/right/*.png' \n",
    "\n",
    "TEST_PATH = 'kitti/left_test/*.png'\n",
    "GT_TEST_PATH = 'kitti/right_test/*.png' \n",
    "\n",
    "#Training parameter\n",
    "BATCH_SIZE = 2\n",
    "BATCH_TEST = 20\n",
    "TRAIN_SIZE = 0.01\n",
    "LAMBDA_L1 = 100.0\n",
    "LR =  0.0002 # 0.001  0.0005 0.00146\n",
    "LR_D =  0.0002\n",
    "EPOCH = 150000\n",
    "DECAY_STEP = EPOCH/5\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "identity = np.array([[1., 0., 0.],\n",
    "                    [0., 1., 0.]]) \n",
    "identity = identity.flatten()\n",
    "theta = tf.Variable(initial_value=identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift pixels\n",
    "def tf_image_translate(images, tx, ty, interpolation='NEAREST'):\n",
    "    # got these parameters from solving the equations for pixel translations\n",
    "    # on https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform\n",
    "    \n",
    "    #+tx -> shift to left +ty ->shift up\n",
    "    #transforms = [1, 0, tx, 0, 1, ty, 0, 0]\n",
    "    #return tf.contrib.image.transform(images, transforms, interpolation)\n",
    "    translate = [-tx, ty, BATCH_SIZE]\n",
    "    return tf.contrib.image.translate(images, translate, interpolation)\n",
    "\n",
    "def preprocess(image):\n",
    "    with tf.name_scope(\"preprocess\"):\n",
    "        # [0, 1] => [-1, 1]\n",
    "        return image * 2 - 1\n",
    "    \n",
    "def deprocess(image):\n",
    "    with tf.name_scope(\"deprocess\"):\n",
    "        # [-1, 1] => [0, 1]\n",
    "        return (image + 1) / 2\n",
    "    \n",
    "def batchnorm(inputs):\n",
    "    return tf.layers.batch_normalization(inputs, \n",
    "                                         axis=3, \n",
    "                                         epsilon=1e-5, \n",
    "                                         momentum=0.1, \n",
    "                                         training=True, \n",
    "                                         gamma_initializer=tf.random_normal_initializer(1.0, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Input_Pipeline'):\n",
    "    #X\n",
    "    tf_x = tf.placeholder(tf.float32, [None, IMG_HEIGHT, IMG_WIDTH, CH_INPUT], name='Input')\n",
    "    view_image = tf.summary.image('input', tf.reshape(tf_x, [-1, IMG_HEIGHT, IMG_WIDTH, CH_INPUT]), 1)\n",
    "    image = tf.reshape(tf_x, [-1, IMG_HEIGHT, IMG_WIDTH, CH_INPUT], name='img_x')# (batch, height, width, channel)\n",
    "    #image = preprocess(image)\n",
    "\n",
    "    #Y\n",
    "    tf_y = tf.placeholder(tf.float32, [None, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT], name='Target')\n",
    "    label_image = tf.summary.image('GT', tf.reshape(tf_y, [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), 1)\n",
    "    color_norm = tf.reshape(tf_y, [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT], name='img_y')# (batch, height, width, channel)\n",
    "    #color_norm = preprocess(color_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper function\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def load_image(addr):\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.imread(addr)\n",
    "    if img is None:\n",
    "        return None\n",
    "    #img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "#Load the image using OpenCV in grayscale\n",
    "def load_image_gray(addr):\n",
    "    img = cv2.imread(addr, 0)\n",
    "    if img is None:\n",
    "        return None\n",
    "    #img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataRecord(out_filename, addrs, labels):\n",
    "    # open the TFRecords file\n",
    "    writer = tf.python_io.TFRecordWriter(out_filename)\n",
    "    for i in range(len(addrs)):\n",
    "        # print how many images are loaded every # images\n",
    "        if not i % 500:\n",
    "            print('Train data: {}/{} images'.format(i, len(addrs)))\n",
    "            sys.stdout.flush()\n",
    "        # Load the image\n",
    "        if CH_INPUT == 1:\n",
    "            img = load_image_gray(addrs[i])\n",
    "        else:\n",
    "            img = load_image(addrs[i]) \n",
    "        \n",
    "        if CH_OUTPUT == 1:\n",
    "            label = load_image_gray(labels[i])\n",
    "        else: \n",
    "            label = load_image(labels[i])\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        if label is None:\n",
    "            continue\n",
    "            \n",
    "        # Create a feature\n",
    "        feature = {\n",
    "            'image_raw': _bytes_feature(img.tostring()),\n",
    "            'label': _bytes_feature(label.tostring())\n",
    "        }\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    writer.close()\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Data_Folder_Read'):\n",
    "    input_path = INPUT_PATH\n",
    "    label_path = GT_PATH\n",
    "    addrs = sorted(glob.glob(input_path))\n",
    "    labels = sorted(glob.glob(label_path))\n",
    "    \n",
    "with tf.name_scope('Shuffle_Data'):\n",
    "    # to shuffle data\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c,)\n",
    "    addrs, labels = zip(*c)\n",
    "    \n",
    "with tf.name_scope('Create_Datarecord_Train'):\n",
    "    # Divide the data into % train and % test\n",
    "    train_addrs = addrs[0:int(TRAIN_SIZE*len(addrs))]\n",
    "    train_labels = labels[0:int(TRAIN_SIZE*len(labels))]\n",
    "    createDataRecord('train.tfrecords', train_addrs, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK STRUCTURE [SYNTHESIS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16:\n",
    "    \"\"\"\n",
    "    A trainable version VGG16.\n",
    "    \"\"\"\n",
    "    def __init__(self, vgg16_npy_path=None, trainable=True, dropout=0.5, output_dim=15360, retrain=\"semi\"):\n",
    "        if vgg16_npy_path is not None:\n",
    "            self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        else:\n",
    "            self.data_dict = None\n",
    "\n",
    "        self.var_dict = {}\n",
    "        self.trainable = trainable\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.output_dim=output_dim\n",
    "        self.retrain=retrain\n",
    "\n",
    "    def build(self, rgb, train_mode=None):\n",
    "        \"\"\"\n",
    "        load variable from npy to build the VGG\n",
    "        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n",
    "        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n",
    "        \"\"\"\n",
    "\n",
    "        rgb_scaled = rgb * 255.0\n",
    "        \n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n",
    "        assert red.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        assert green.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        assert blue.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ])\n",
    "        \n",
    "        assert bgr.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 3]\n",
    "        ######################################################################################\n",
    "        with tf.name_scope('VGG16'):\n",
    "            #1st block\n",
    "            self.conv1_1 = self.conv_layer(bgr, 3, 64, \"conv1_1\")\n",
    "            self.conv1_2 = self.conv_layer(self.conv1_1, 64, 64, \"conv1_2\")\n",
    "            self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "\n",
    "            #2nd block\n",
    "            self.conv2_1 = self.conv_layer(self.pool1, 64, 128, \"conv2_1\")\n",
    "            self.conv2_2 = self.conv_layer(self.conv2_1, 128, 128, \"conv2_2\")\n",
    "            self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "\n",
    "            #3rd block\n",
    "            self.conv3_1 = self.conv_layer(self.pool2, 128, 256, \"conv3_1\")\n",
    "            self.conv3_2 = self.conv_layer(self.conv3_1, 256, 256, \"conv3_2\")\n",
    "            self.conv3_3 = self.conv_layer(self.conv3_2, 256, 256, \"conv3_3\")\n",
    "            self.pool3 = self.max_pool(self.conv3_3, 'pool3')\n",
    "\n",
    "            #4th block\n",
    "            self.conv4_1 = self.conv_layer(self.pool3, 256, 512, \"conv4_1\")\n",
    "            self.conv4_2 = self.conv_layer(self.conv4_1, 512, 512, \"conv4_2\")\n",
    "            self.conv4_3 = self.conv_layer(self.conv4_2, 512, 512, \"conv4_3\")\n",
    "            self.pool4 = self.max_pool(self.conv4_3, 'pool4')\n",
    "\n",
    "            #5th block\n",
    "            self.conv5_1 = self.conv_layer(self.pool4, 512, 512, \"conv5_1\")\n",
    "            self.conv5_2 = self.conv_layer(self.conv5_1, 512, 512, \"conv5_2\")\n",
    "            self.conv5_3 = self.conv_layer(self.conv5_2, 512, 512, \"conv5_3\")\n",
    "            self.pool5 = self.max_pool(self.conv5_3, 'pool5')\n",
    "\n",
    "            #6th block (FC)\n",
    "            self.fc6 = tf.layers.flatten(self.pool5)\n",
    "            #self.fc6 = tf.layers.dense(self.fc6, 4096, bias_initializer=tf.random_normal_initializer(stddev=0.01), name=\"fc6-custom\")\n",
    "            self.fc6 = tf.layers.dense(self.fc6, 2048, name=\"fc6-custom\", bias_initializer=tf.constant_initializer(0.0))\n",
    "            self.relu6 = tf.nn.relu(self.fc6)\n",
    "            if train_mode is not None:\n",
    "                self.relu6 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu6, self.dropout), lambda: self.relu6)\n",
    "            elif self.trainable:\n",
    "                self.relu6 = tf.nn.dropout(self.relu6, self.dropout)\n",
    "\n",
    "            #7th block (FC)\n",
    "            #self.fc7 = tf.layers.dense(self.relu6, 4096, bias_initializer=tf.random_normal_initializer(stddev=0.01), name=\"fc7-custom\")\n",
    "            self.fc7 = tf.layers.dense(self.relu6, 4096, name=\"fc7-custom\", bias_initializer=tf.constant_initializer(0.0))\n",
    "            self.relu7 = tf.nn.relu(self.fc7)\n",
    "            if train_mode is not None:\n",
    "                self.relu7 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu7, self.dropout), lambda: self.relu7)\n",
    "            elif self.trainable:\n",
    "                self.relu7 = tf.nn.dropout(self.relu7, self.dropout)\n",
    "\n",
    "            #8th block (FC)\n",
    "            #self.fc8 = tf.layers.dense(self.relu7, 6144, bias_initializer=tf.random_normal_initializer(stddev=0.01), name=\"fc8-custom\")\n",
    "            self.fc8 = tf.layers.dense(self.relu7, 6144, name=\"fc8-custom\", bias_initializer=tf.constant_initializer(0.0))\n",
    "            self.fc8 = tf.reshape(self.fc8, [-1, 4, 12, 128]) \n",
    "            self.relu_bn5 = tf.nn.relu(self.fc8)\n",
    "            self.conv_bn5 = self.conv_only(self.relu_bn5, 128, 3, \"conv_bn5\")\n",
    "\n",
    "        ######################################################################################\n",
    "        with tf.name_scope('VGG16_UpSample'):\n",
    "            #1st disp probability\n",
    "            #self.pool1 = batchnorm(self.pool1)\n",
    "            self.conv_bn1 = self.conv_bn(self.pool1, 3, \"conv_bn1\")\n",
    "            self.conv_bn1_ = self.conv_bn(self.conv_bn1, 3, \"conv_bn1_\")     \n",
    "            self.deconv_bn1 = self.deconv_layer(self.conv_bn1_, 1, 1, \"deconv_bn1\")\n",
    "\n",
    "            #2nd disp probability\n",
    "            #self.pool2 = batchnorm(self.pool2)\n",
    "            self.conv_bn2 = self.conv_bn(self.pool2, 3, \"conv_bn2\")   \n",
    "            self.conv_bn2_ = self.conv_bn(self.conv_bn2, 3, \"conv_bn2_\") \n",
    "            self.deconv_bn2 = self.deconv_layer(self.conv_bn2_, 4, 2, \"deconv_bn2\")\n",
    "\n",
    "            #3rd disp probability\n",
    "            #self.pool3 = batchnorm(self.pool3)\n",
    "            self.conv_bn3 = self.conv_bn(self.pool3, 3, \"conv_bn3\")     \n",
    "            self.conv_bn3_ = self.conv_bn(self.conv_bn3, 3, \"conv_bn3_\") \n",
    "            self.deconv_bn3 = self.deconv_layer(self.conv_bn3_, 8, 4, \"deconv_bn3\")\n",
    "\n",
    "            #4th disp probability\n",
    "            #self.pool4 = batchnorm(self.pool4)\n",
    "            self.conv_bn4 = self.conv_bn(self.pool4, 3, \"conv_bn4\")     \n",
    "            self.conv_bn4_ = self.conv_bn(self.conv_bn4, 3, \"conv_bn4_\") \n",
    "            self.deconv_bn4 = self.deconv_layer(self.conv_bn4_, 16, 8, \"deconv_bn4\")\n",
    "\n",
    "            #5th disp probability\n",
    "            self.deconv_bn5 = self.deconv_layer(self.conv_bn5, 32, 16, \"deconv_bn5\")\n",
    "        \n",
    "        ######################################################################################\n",
    "        with tf.name_scope('Disparity_Probability'):\n",
    "            #SUM (save memory?)\n",
    "            self.summation = tf.add(self.deconv_bn1, self.deconv_bn2)\n",
    "            self.summation = tf.add(self.summation, self.deconv_bn3)\n",
    "            self.summation = tf.add(self.summation, self.deconv_bn4)\n",
    "            self.summation = tf.add(self.summation, self.deconv_bn5)\n",
    "\n",
    "            self.relu_sum = tf.nn.relu(self.summation)\n",
    "\n",
    "            #Deconv sum\n",
    "            self.deconv_sum = self.deconv_layer(self.relu_sum, 4, 2, \"deconv_sum\")\n",
    "            self.deconv_sum = tf.nn.relu(self.deconv_sum)\n",
    "\n",
    "            self.conv_sum_ = tf.layers.conv2d(self.deconv_sum, 128, 3, padding='SAME', activation=tf.nn.relu,\n",
    "                                             kernel_initializer=tf.random_normal_initializer(stddev=0.01), name=\"conv_sum_\")\n",
    "\n",
    "            self.conv_sum = self.conv_only(self.conv_sum_, DISP_RANGE, 3, \"conv_sum\")\n",
    "\n",
    "            #Final softmax disp probability\n",
    "            self.prob = tf.nn.softmax(self.conv_sum)\n",
    "        \n",
    "        ######################################################################################\n",
    "        with tf.name_scope('Flow_Generator'):\n",
    "            self.conv_flow1 = tf.layers.conv2d(inputs=bgr, \n",
    "                                         filters=64, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='conv_flow1')\n",
    "\n",
    "            self.conv_flow2 = tf.layers.conv2d(inputs=self.conv_flow1, \n",
    "                                         filters=128, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='conv_flow2')\n",
    "\n",
    "            self.conv_flow3 = tf.layers.conv2d(inputs=self.conv_flow2, \n",
    "                                         filters=256, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='conv_flow3')\n",
    "\n",
    "            self.conv_flow4 = tf.layers.conv2d(inputs=self.conv_flow3, \n",
    "                                         filters=512, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='conv_flow4')\n",
    "\n",
    "            self.conv_flow5 = tf.layers.conv2d(inputs=self.conv_flow4, \n",
    "                                         filters=512, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='conv_flow5')\n",
    "\n",
    "            self.fc_flow = tf.layers.flatten(self.conv_flow5)\n",
    "            self.fc_flow = tf.layers.dense(self.fc_flow, 6144)\n",
    "            self.fc_flow = tf.reshape(self.fc_flow, [-1, 4, 12, 128]) \n",
    "\n",
    "            self.deconv_flow5 = tf.layers.conv2d_transpose(inputs=self.fc_flow, \n",
    "                                         filters=512, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='deconv_flow5')\n",
    "\n",
    "            self.deconv_flow4 = tf.layers.conv2d_transpose(inputs=self.deconv_flow5, \n",
    "                                         filters=512, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='deconv_flow4')\n",
    "\n",
    "            self.deconv_flow3 = tf.layers.conv2d_transpose(inputs=self.deconv_flow4, \n",
    "                                         filters=256, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='deconv_flow3')\n",
    "\n",
    "            self.deconv_flow2 = tf.layers.conv2d_transpose(inputs=self.deconv_flow3, \n",
    "                                         filters=128, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='deconv_flow2')\n",
    "\n",
    "            self.deconv_flow1 = tf.layers.conv2d_transpose(inputs=self.deconv_flow2, \n",
    "                                         filters=(DISP_RANGE-1)*2, \n",
    "                                         kernel_size=5, \n",
    "                                         strides=2, \n",
    "                                         padding='SAME', \n",
    "                                         activation=tf.nn.relu,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                         bias_initializer=tf.constant_initializer(0.0),\n",
    "                                         name='deconv_flow1')\n",
    "        ######################################################################################\n",
    "        with tf.name_scope('Selection_Layer'):    \n",
    "            #Slice and multiply\n",
    "            #Shifted input\n",
    "            self.image_stack = image\n",
    "            for i in range(DISP_RANGE-1):\n",
    "#                 if (i%2==0):\n",
    "#                     trans_image = tf_image_translate(image, tx=i+1, ty=0)\n",
    "#                 else:\n",
    "#                     trans_image = bilinear_sampler(image, vgg.deconv_flow1[:, :, :, i*2:(i*2)+2])\n",
    "                trans_image = tf_image_translate(image, tx=i+1, ty=0)    \n",
    "                self.image_stack = tf.concat([self.image_stack, trans_image], -1)\n",
    "\n",
    "            #Multiply prob and shifted input\n",
    "            self.pred_right = tf.zeros_like(image)\n",
    "            for i in range(DISP_RANGE):\n",
    "                self.mult_prob = tf.multiply(self.prob[:, :, :, i:i+1], self.image_stack[:, :, :, i*3:(i*3)+3]) \n",
    "                self.pred_right = tf.add(self.pred_right, self.mult_prob)\n",
    "\n",
    "        ######################################################################################\n",
    "        \n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, in_channels, out_channels, name):\n",
    "        with tf.variable_scope(name):\n",
    "            filt, conv_biases = self.get_conv_var(3, in_channels, out_channels, name)\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "            relu = tf.nn.relu(bias)\n",
    "\n",
    "            return relu  \n",
    "        \n",
    "    def conv_only(self, inputs, filters, kernel, name):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = tf.layers.conv2d(inputs, filters, kernel, padding='SAME',\n",
    "                                    kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "\n",
    "            return conv \n",
    "        \n",
    "    def conv_bn(self, inputs, kernel, name):\n",
    "        with tf.variable_scope(name):\n",
    "            conv = tf.layers.conv2d(inputs, 128, kernel, padding='SAME', activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "            return conv\n",
    "        \n",
    "    def deconv_layer(self, inputs, kernel, stride, name):\n",
    "        with tf.variable_scope(name):\n",
    "            deconv = tf.layers.conv2d_transpose(inputs, 128,  kernel, (stride,stride), padding='SAME')\n",
    "            return deconv\n",
    "\n",
    "    def get_conv_var(self, filter_size, in_channels, out_channels, name):\n",
    "        initial_value = tf.truncated_normal([filter_size, filter_size, in_channels, out_channels], 0.0, 0.001)\n",
    "\n",
    "        if self.retrain == 'complete':\n",
    "            rt = True\n",
    "        elif self.retrain == 'semi':\n",
    "            if 'conv1' in name or 'conv2' in name:\n",
    "                rt = True\n",
    "            else:\n",
    "                rt = False\n",
    "        else:\n",
    "            rt = False\n",
    "\n",
    "        filters = self.get_var(initial_value, name, 0, name + \"_filters\", retrain=rt)\n",
    "        initial_value = tf.truncated_normal([out_channels], .0, .001)\n",
    "        biases = self.get_var(initial_value, name, 1, name + \"_biases\", retrain=rt)\n",
    "\n",
    "        return filters, biases\n",
    "\n",
    "    def get_var(self, initial_value, name, idx, var_name, retrain=True):\n",
    "        if self.data_dict is not None and name in self.data_dict:\n",
    "            value = self.data_dict[name][idx]\n",
    "        else:\n",
    "            value = initial_value\n",
    "\n",
    "        if self.trainable and retrain:\n",
    "            var = tf.Variable(value, name=var_name)\n",
    "        else:\n",
    "            var = tf.constant(value, dtype=tf.float32, name=var_name)\n",
    "\n",
    "        self.var_dict[(name, idx)] = var\n",
    "\n",
    "        # print var_name, var.get_shape().as_list()\n",
    "        assert var.get_shape() == initial_value.get_shape()\n",
    "\n",
    "        return var\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16_Perceptual:\n",
    "    def __init__(self, vgg16_npy_path=None, trainable=True, dropout=0.5, output_dim=15360, retrain=\"semi\"):\n",
    "        if vgg16_npy_path is not None:\n",
    "            self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        else:\n",
    "            self.data_dict = None\n",
    "\n",
    "        self.var_dict = {}\n",
    "        self.trainable = trainable\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.output_dim=output_dim\n",
    "        self.retrain=retrain\n",
    "\n",
    "    def build(self, rgb, train_mode=None):\n",
    "        \"\"\"\n",
    "        load variable from npy to build the VGG\n",
    "        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n",
    "        :param train_mode: a bool tensor, usually a placeholder: if True, dropout will be turned on\n",
    "        \"\"\"\n",
    "\n",
    "        rgb_scaled = rgb * 255.0\n",
    "        \n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n",
    "        assert red.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        assert green.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        assert blue.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 1]\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ])\n",
    "        \n",
    "        assert bgr.get_shape().as_list()[1:] == [IMG_HEIGHT, IMG_WIDTH, 3]\n",
    "        ######################################################################################\n",
    "        with tf.name_scope('VGG16'):\n",
    "            #1st block\n",
    "            self.conv1_1 = self.conv_layer(bgr, 3, 64, \"conv1_1\")\n",
    "            self.conv1_2 = self.conv_layer(self.conv1_1, 64, 64, \"conv1_2\")\n",
    "            self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n",
    "\n",
    "            #2nd block\n",
    "            self.conv2_1 = self.conv_layer(self.pool1, 64, 128, \"conv2_1\")\n",
    "            self.conv2_2 = self.conv_layer(self.conv2_1, 128, 128, \"conv2_2\")\n",
    "            self.pool2 = self.max_pool(self.conv2_2, 'pool2')\n",
    "            \n",
    "            #3rd block\n",
    "            self.conv3_1 = self.conv_layer(self.pool2, 128, 256, \"conv3_1\")\n",
    "            self.conv3_2 = self.conv_layer(self.conv3_1, 256, 256, \"conv3_2\")\n",
    "            self.conv3_3 = self.conv_layer(self.conv3_2, 256, 256, \"conv3_3\")\n",
    "            self.pool3 = self.max_pool(self.conv3_3, 'pool3')\n",
    "     \n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, in_channels, out_channels, name):\n",
    "        with tf.variable_scope(name):\n",
    "            filt, conv_biases = self.get_conv_var(3, in_channels, out_channels, name)\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "            relu = tf.nn.relu(bias)\n",
    "\n",
    "            return relu  \n",
    "        \n",
    "    def get_conv_var(self, filter_size, in_channels, out_channels, name):\n",
    "        initial_value = tf.truncated_normal([filter_size, filter_size, in_channels, out_channels], 0.0, 0.001)\n",
    "\n",
    "        if self.retrain == 'complete':\n",
    "            rt = True\n",
    "        elif self.retrain == 'semi':\n",
    "            if 'conv1' in name or 'conv2' in name:\n",
    "                rt = True\n",
    "            else:\n",
    "                rt = False\n",
    "        else:\n",
    "            rt = False\n",
    "\n",
    "        filters = self.get_var(initial_value, name, 0, name + \"_filters\", retrain=rt)\n",
    "        initial_value = tf.truncated_normal([out_channels], .0, .001)\n",
    "        biases = self.get_var(initial_value, name, 1, name + \"_biases\", retrain=rt)\n",
    "\n",
    "        return filters, biases\n",
    "\n",
    "    def get_var(self, initial_value, name, idx, var_name, retrain=True):\n",
    "        if self.data_dict is not None and name in self.data_dict:\n",
    "            value = self.data_dict[name][idx]\n",
    "        else:\n",
    "            value = initial_value\n",
    "\n",
    "        if self.trainable and retrain:\n",
    "            var = tf.Variable(value, name=var_name)\n",
    "        else:\n",
    "            var = tf.constant(value, dtype=tf.float32, name=var_name)\n",
    "\n",
    "        self.var_dict[(name, idx)] = var\n",
    "\n",
    "        # print var_name, var.get_shape().as_list()\n",
    "        assert var.get_shape() == initial_value.get_shape()\n",
    "\n",
    "        return var\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATCH GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "# def patch_GAN(input_=None, filters_=64, name_=None, reuse_=None):\n",
    "#     with tf.variable_scope('Patch_GAN'):\n",
    "#         if reuse_:\n",
    "#             tf.get_variable_scope().reuse_variables()\n",
    "#         input_ += tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "#         with tf.name_scope('D_1st_Block'):\n",
    "#             conv1 = tf.layers.conv2d(inputs=input_, \n",
    "#                                      filters=filters_, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None,\n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_1st_Block')\n",
    "\n",
    "#             conv1 = batchnorm(conv1)\n",
    "#             conv1 = tf.nn.leaky_relu(conv1)\n",
    "        \n",
    "#         with tf.name_scope('D_2nd_Block'):\n",
    "#             conv2 = tf.layers.conv2d(inputs=conv1, \n",
    "#                                      filters=filters_*2, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_2nd_Block')\n",
    "\n",
    "#             conv2 = batchnorm(conv2)\n",
    "#             conv2 = tf.nn.leaky_relu(conv2)\n",
    "        \n",
    "#         with tf.name_scope('D_3rd_Block'):\n",
    "#             conv3 = tf.layers.conv2d(inputs=conv2, \n",
    "#                                      filters=filters_*4, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_3rd_Block_conv_3')\n",
    "\n",
    "#             conv3 = batchnorm(conv3)\n",
    "#             conv3 = tf.nn.leaky_relu(conv3)\n",
    "        \n",
    "#         with tf.name_scope('D_4th_Block'):\n",
    "#             conv4 = tf.layers.conv2d(inputs=conv3, \n",
    "#                                      filters=filters_*8, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_4th_Block_conv_4')\n",
    "\n",
    "#             conv4 = batchnorm(conv4)\n",
    "#             conv4 = tf.nn.leaky_relu(conv4)\n",
    "        \n",
    "#         with tf.name_scope('D_5th_Block'):\n",
    "#             conv5 = tf.layers.conv2d(inputs=conv4, \n",
    "#                                      filters=1, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=1, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_5th_Block_conv_5')    \n",
    "            \n",
    "#         return tf.nn.sigmoid(conv5), conv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANILA GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# def vanila_GAN(input_=None, filters_=64, name_=None, reuse_=None):\n",
    "#     with tf.variable_scope('Vanila_GAN'):\n",
    "#         if reuse_:\n",
    "#             tf.get_variable_scope().reuse_variables()\n",
    "#         input_ += tf.random_normal(shape=tf.shape(input_), mean=0.0, stddev=0.1, dtype=tf.float32)\n",
    "#         with tf.name_scope('D_1st_Block'):\n",
    "#             conv1 = tf.layers.conv2d(inputs=input_, \n",
    "#                                      filters=filters_, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None,\n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_1st_Block')\n",
    "\n",
    "#             conv1 = batchnorm(conv1)\n",
    "#             conv1 = tf.nn.leaky_relu(conv1)\n",
    "        \n",
    "#         with tf.name_scope('D_2nd_Block'):\n",
    "#             conv2 = tf.layers.conv2d(inputs=conv1, \n",
    "#                                      filters=filters_*2, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_2nd_Block')\n",
    "\n",
    "#             conv2 = batchnorm(conv2)\n",
    "#             conv2 = tf.nn.leaky_relu(conv2)\n",
    "        \n",
    "#         with tf.name_scope('D_3rd_Block'):\n",
    "#             conv3 = tf.layers.conv2d(inputs=conv2, \n",
    "#                                      filters=filters_*4, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_3rd_Block_conv_3')\n",
    "\n",
    "#             conv3 = batchnorm(conv3)\n",
    "#             conv3 = tf.nn.leaky_relu(conv3)\n",
    "        \n",
    "#         with tf.name_scope('D_4th_Block'):\n",
    "#             conv4 = tf.layers.conv2d(inputs=conv3, \n",
    "#                                      filters=filters_*8, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_4th_Block_conv_4')\n",
    "\n",
    "#             conv4 = batchnorm(conv4)\n",
    "#             conv4 = tf.nn.leaky_relu(conv4)\n",
    "        \n",
    "#         with tf.name_scope('D_5th_Block'):\n",
    "#             conv5 = tf.layers.conv2d(inputs=conv4, \n",
    "#                                      filters=filters_*8, \n",
    "#                                      kernel_size=4, \n",
    "#                                      strides=2, \n",
    "#                                      padding='SAME', \n",
    "#                                      activation=None, \n",
    "#                                      kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "#                                      bias_initializer=tf.constant_initializer(0.0),\n",
    "#                                      name='D_5th_Block_conv_5')   \n",
    "#             conv5 = batchnorm(conv5)\n",
    "#             conv5 = tf.nn.leaky_relu(conv5)\n",
    "            \n",
    "#         with tf.name_scope('D_6th_Block'):\n",
    "#             flat1 = tf.layers.flatten(conv5)\n",
    "#             dense1 = tf.layers.dense(flat1, 1024)\n",
    "#             dense1 = tf.nn.leaky_relu(dense1)\n",
    "#             dense1 = tf.layers.batch_normalization(dense1,\n",
    "#                                          epsilon=1e-5, \n",
    "#                                          momentum=0.1, \n",
    "#                                          training=True, \n",
    "#                                          gamma_initializer=tf.random_normal_initializer(1.0, 0.01))\n",
    "#             out = tf.layers.dense(dense1, 1)\n",
    "            \n",
    "#         return tf.nn.sigmoid(out), out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('View_Synthesis'):\n",
    "    with tf.name_scope('Main_Network'):\n",
    "        vgg = Vgg16(vgg16_npy_path= 'vgg16.npy', output_dim = 15360, retrain=\"complete\")\n",
    "        train_mode = tf.placeholder(tf.bool)\n",
    "        input_vgg = tf.divide(image, 255)\n",
    "        vgg.build(input_vgg, train_mode)\n",
    "        \n",
    "with tf.name_scope('Perceptual_Loss_Network'):\n",
    "    vgg_loss = Vgg16_Perceptual(vgg16_npy_path= 'vgg16.npy', output_dim = 15360, retrain=\"no\")\n",
    "\n",
    "    input_vgg_predicted = tf.divide(vgg.pred_right, 255)\n",
    "    vgg_loss.build(input_vgg_predicted, train_mode)\n",
    "    #feature_predicted = vgg_loss.conv1_2\n",
    "    #feature_predicted2 = vgg_loss.conv2_2\n",
    "    feature_predicted3 = vgg_loss.conv3_3\n",
    "\n",
    "    input_vgg_GT = tf.divide(color_norm, 255)\n",
    "    vgg_loss.build(input_vgg_GT, train_mode)\n",
    "    #feature_GT = vgg_loss.conv1_2\n",
    "    #feature_GT2 = vgg_loss.conv2_2\n",
    "    feature_GT3 = vgg_loss.conv3_3\n",
    "\n",
    "#     with tf.name_scope('Discriminator_Patch'):\n",
    "        #Concat A and real B\n",
    "        #real_input = tf.concat([vgg.prob, color_norm], 3)\n",
    "        #Concat A and fake B\n",
    "        #fake_input = tf.concat([vgg.prob, vgg.pred_right], 3)\n",
    "        \n",
    "#         with tf.name_scope('Discriminator_Real'):\n",
    "#             sigmoid_real, real_logits = patch_GAN(color_norm, 64, 'D_real', False)\n",
    "#         with tf.name_scope('Discriminator_Fake'):\n",
    "#             sigmoid_fake, fake_logits = patch_GAN(vgg.pred_right, 64, 'D_fake', True)\n",
    "            \n",
    "#     with tf.name_scope('Discriminator_Vanila'):      \n",
    "#         with tf.name_scope('Discriminator_Real'):\n",
    "#             sigmoid_real, real_logits = vanila_GAN(color_norm, 64, 'D_real', False)\n",
    "#         with tf.name_scope('Discriminator_Fake'):\n",
    "#             sigmoid_fake, fake_logits = vanila_GAN(vgg.pred_right, 64, 'D_fake', True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy_with_logits(x, y):\n",
    "    try:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=y)\n",
    "    except:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, targets=y)\n",
    "\n",
    "with tf.name_scope('Loss'): \n",
    "    output_image = tf.summary.image('Target', tf.cast(tf.reshape(vgg.pred_right, \n",
    "                            [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), tf.uint8) , 1)\n",
    "    \n",
    "    #Label smoothing\n",
    "    #zero_smooth = tf.random_uniform(tf.shape(sigmoid_fake), minval=0.0, maxval=0.2)\n",
    "    #one_smooth = tf.random_uniform(tf.shape(sigmoid_fake), minval=0.0, maxval=-0.2)\n",
    "    \n",
    "    l1_loss = tf.reduce_mean(tf.losses.absolute_difference(color_norm, vgg.pred_right))\n",
    "    tf.summary.scalar('L1_loss', l1_loss)\n",
    "    \n",
    "    #perceptual_loss = tf.reduce_mean((feature_predicted-feature_GT)*(feature_predicted-feature_GT))\n",
    "    #perceptual_loss2 = tf.reduce_mean((feature_predicted2-feature_GT2)*(feature_predicted2-feature_GT2))\n",
    "    perceptual_loss3 = tf.reduce_mean((feature_predicted3-feature_GT3)*(feature_predicted3-feature_GT3))\n",
    "    #perceptual_loss_total = perceptual_loss + perceptual_loss2 + perceptual_loss3\n",
    "    tf.summary.scalar('Perceptual_loss', perceptual_loss3)\n",
    "    \n",
    "    total_loss = tf.add(l1_loss,perceptual_loss3)\n",
    "    \n",
    "#     G_Adv_loss = tf.reduce_mean(\n",
    "#             sigmoid_cross_entropy_with_logits(fake_logits, tf.ones_like(sigmoid_fake)+one_smooth), name='G_adv_loss')\n",
    "        \n",
    "#     G_Adv_loss = tf.reduce_mean(sigmoid_real)\n",
    "    \n",
    "#     G_Total_Loss = tf.add(G_Adv_loss, (LAMBDA_L1 * l1_loss), name='G_total_loss')\n",
    "    \n",
    "#     tf.summary.scalar('Generator_Adv_Loss', G_Adv_loss)\n",
    "#     tf.summary.scalar('Generator_Total_Loss', G_Total_Loss)\n",
    "    \n",
    "#     ###################################################################################################\n",
    "#     D_Adv_Real = tf.reduce_mean(\n",
    "#         sigmoid_cross_entropy_with_logits(real_logits, tf.ones_like(sigmoid_real)+one_smooth), name='D_real_adv_loss')\n",
    "\n",
    "#     D_Adv_Fake = tf.reduce_mean(\n",
    "#         sigmoid_cross_entropy_with_logits(fake_logits, tf.zeros_like(sigmoid_fake)+zero_smooth), name='D_fake_adv_loss')\n",
    "#     D_Total_Loss = tf.add(D_Adv_Real, D_Adv_Fake, name='D_total_loss')\n",
    "        \n",
    "#     tf.summary.scalar('Discriminator_Real', D_Adv_Real)\n",
    "#     tf.summary.scalar('Discriminator_Fake', D_Adv_Fake)\n",
    "#     tf.summary.scalar('Discriminator_Total_Loss', D_Total_Loss)\n",
    "    \n",
    "    shift_image = tf.summary.image('Shift', tf.cast(tf.reshape(vgg.image_stack[:, :, :, (DISP_RANGE*3)-3:DISP_RANGE*3],\n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), tf.uint8) , 1)\n",
    "    \n",
    "    shift_image2 = tf.summary.image('Shift2', tf.cast(tf.reshape(vgg.image_stack[:, :, :, 12:15],\n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), tf.uint8) , 1)\n",
    "    \n",
    "    shift_image3 = tf.summary.image('Shift2', tf.cast(tf.reshape(vgg.image_stack[:, :, :, 24:27],\n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT]), tf.uint8) , 1)\n",
    "  \n",
    "    disp_image = tf.summary.image('Z', tf.cast(tf.reshape(vgg.prob[:, :, :, 3:4]*255, \n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, 1]), tf.uint8) , 1)\n",
    "    \n",
    "    disp_image2 = tf.summary.image('Z2', tf.cast(tf.reshape(vgg.prob[:, :, :, 13:14]*255, \n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, 1]), tf.uint8) , 1)\n",
    "    \n",
    "    disp_image3 = tf.summary.image('Z3', tf.cast(tf.reshape(vgg.prob[:, :, :, 28:29]*255, \n",
    "                                    [-1, IMG_HEIGHT, IMG_WIDTH, 1]), tf.uint8) , 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Train'):\n",
    "    batch = tf.Variable(0, dtype=tf.float32)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                      LR,                    # Base learning rate.\n",
    "                      batch,      # Current index into the dataset.\n",
    "                      DECAY_STEP,       # Decay step.\n",
    "                      0.97,       # Decay rate.\n",
    "                      staircase=True)\n",
    "    learning_rate_D = tf.train.exponential_decay(\n",
    "                      LR_D,                    # Base learning rate.\n",
    "                      batch,      # Current index into the dataset.\n",
    "                      DECAY_STEP,       # Decay step.\n",
    "                      0.97,       # Decay rate.\n",
    "                      staircase=True)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate, name='optimizer_adam').minimize(total_loss)\n",
    "    #train_G = tf.train.AdamOptimizer(learning_rate=learning_rate, name='optimizer_G').minimize(G_Total_Loss)\n",
    "    #train_D = tf.train.AdamOptimizer(learning_rate=learning_rate_D, name='optimizer_D').minimize(D_Total_Loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get one record and parse it to get the label and image out\n",
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image_raw\": tf.FixedLenFeature([], tf.string),\n",
    "        \"label\":     tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    #Read one record\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    #Take the image and bytes\n",
    "    image = tf.decode_raw(parsed[\"image_raw\"], tf.uint8)\n",
    "    label = tf.decode_raw(parsed[\"label\"], tf.uint8)\n",
    "    #Cast to float\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    image = tf.reshape(image, shape=[IMG_HEIGHT, IMG_WIDTH, CH_INPUT])\n",
    "    label = tf.reshape(label, shape=[IMG_HEIGHT, IMG_WIDTH, CH_OUTPUT])\n",
    "    #Normalize the input and label into [0...1]\n",
    "    #image = tf.divide(image, 255)\n",
    "    #label = tf.divide(label, 255)\n",
    "\n",
    "    return {'image': image}, {'label': label}\n",
    "\n",
    "def input_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=1000)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=1000)\n",
    "    dataset = dataset.shuffle(500).repeat().batch(BATCH_SIZE)\n",
    "    #dataset = dataset.prefetch(buffer_size=2)\n",
    "    return dataset\n",
    "\n",
    "def test_fn(filenames):\n",
    "    #Create data record\n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=100)\n",
    "    dataset = dataset.map(parser, num_parallel_calls=100)\n",
    "    dataset = dataset.batch(BATCH_TEST)\n",
    "    return dataset\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(filenames=[\"train.tfrecords\"])\n",
    "\n",
    "def test_input_fn():\n",
    "    return test_fn(filenames=[\"test.tfrecords\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Data_Folder_Read'):\n",
    "    input_path = INPUT_PATH\n",
    "    label_path = GT_PATH\n",
    "    addrs = sorted(glob.glob(input_path))\n",
    "    labels = sorted(glob.glob(label_path))\n",
    "    \n",
    "with tf.name_scope('Create_Training_Set'):\n",
    "    train_dataset = train_input_fn()\n",
    "    iterator = train_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess=tf.Session(config=config)\n",
    "sess.run(tf.group(tf.global_variables_initializer(), \n",
    "                  iterator.initializer)\n",
    "                 )\n",
    "#saver.restore(sess, \"saver/Synthesis/model100000.ckpt\")\n",
    "writer = tf.summary.FileWriter('log/Synthesis',sess.graph)\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True, trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()\n",
    "for step in range(EPOCH+1):\n",
    "    train_x, train_y = sess.run(next_batch)\n",
    "    \n",
    "    _, l1_loss_, output_, summary_ = sess.run([train_op, l1_loss, vgg.pred_right, merged], {tf_x:train_x['image'], tf_y:train_y['label'], train_mode:True}, options=run_options, run_metadata=run_metadata)\n",
    "#     if step%1 == 0:\n",
    "#         _, G_loss_, output_, summary_ = sess.run([train_G, G_Adv_loss, vgg.pred_right, merged], {tf_x:train_x['image'], tf_y:train_y['label'], train_mode:True}, options=run_options, run_metadata=run_metadata)\n",
    "#     if step%1 == 0:\n",
    "#         _, D_loss_ = sess.run([train_D, D_Total_Loss], {tf_x:train_x['image'], tf_y:train_y['label'], train_mode:True}, options=run_options, run_metadata=run_metadata)\n",
    "   \n",
    "    if step ==20000:\n",
    "        save_path = saver.save(sess, \"saver/Synthesis/model%i.ckpt\" %step)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "        writer.add_summary(summary_, step)     \n",
    "        print('Step:', step, '| L_1 loss:%.4f' %l1_loss_)\n",
    "        #print('Step:', step, '| G loss:%.4f' %G_loss_, '| D loss:%.4f' %D_loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Test_Folder_Read'):\n",
    "    input_path = TEST_PATH\n",
    "    label_path = GT_TEST_PATH\n",
    "    addrs = sorted(glob.glob(input_path))\n",
    "    labels = sorted(glob.glob(label_path))\n",
    "    \n",
    "with tf.name_scope('Create_Datarecord_Test'):\n",
    "    # Divide the data into % train and % test\n",
    "    test_addrs = addrs[:BATCH_TEST]\n",
    "    test_labels = labels[:BATCH_TEST]\n",
    "    createDataRecord('test.tfrecords', test_addrs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Create_Test_Set'):\n",
    "    test_dataset = test_input_fn()\n",
    "    iterator = test_dataset.make_initializable_iterator()\n",
    "    next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "sess.run(iterator.initializer)\n",
    "saver = tf.train.Saver()\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "%timeit\n",
    "saver.restore(sess, \"saver/Synthesis/model100000.ckpt\")\n",
    "test_x, test_y = sess.run(next_batch)\n",
    "l1_loss_, output_, depth_, stack_ = sess.run([l1_loss, vgg.pred_right, vgg.prob, vgg.image_stack], {tf_x:test_x['image'], tf_y:test_y['label'], train_mode:False}, options=run_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(BATCH_TEST):\n",
    "    plt.figure(i)\n",
    "    temp = output_[i,:,:,:]\n",
    "    #color = np.reshape(output_[0], [256,256,3])\n",
    "    imgplots = plt.imshow((temp).astype('uint8'))\n",
    "    plt.show()\n",
    "    temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"outputB%i.png\" %(i), temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(DISP_RANGE):\n",
    "    plt.figure(d)\n",
    "    temp = depth_[6,:,:,d:d+1]*255\n",
    "    temp  = np.squeeze(temp, 2)\n",
    "    imgplot = plt.imshow((temp).astype('uint8'), cmap='gray')\n",
    "    plt.show()\n",
    "    cv2.imwrite(\"prob%i.png\" %d, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in range(DISP_RANGE):\n",
    "#     plt.figure(d)\n",
    "#     temp = stack_[7,:,:,d*3:(d*3)+3]\n",
    "#     imgplot = plt.imshow((temp).astype('uint8'))\n",
    "#     plt.show()\n",
    "#     cv2.imwrite(\"bilinear%i.png\" %d, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "for i in range(14):\n",
    "    original = cv2.imread(\"GT%i.png\"%(i+1))\n",
    "    contrast = cv2.imread(\"output%i.png\"%i)\n",
    "    contrast2 = cv2.imread(\"outputB%i.png\"%i)\n",
    "    d=psnr(original,contrast)\n",
    "    d2=psnr(original,contrast2)\n",
    "    print(d)\n",
    "    print(d2)\n",
    "    print(\"#########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.measure import compare_ssim as ssim\n",
    "\n",
    "# for i in range(14):\n",
    "#     original = cv2.imread(\"GT%i.png\"%(i+1))\n",
    "#     contrast = cv2.imread(\"output%i.png\"%i)\n",
    "#     contrast2 = cv2.imread(\"outputGD%i.png\"%i)\n",
    "#     ssim_noise = ssim(original, contrast, multichannel=True,\n",
    "#                   data_range=contrast.max() - contrast.min())\n",
    "    \n",
    "#     ssim_noise2 = ssim(original, contrast2, multichannel=True,\n",
    "#                   data_range=contrast2.max() - contrast2.min())\n",
    "#     print(ssim_noise)\n",
    "#     print(ssim_noise2)\n",
    "#     print(\"#########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
